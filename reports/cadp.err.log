Traceback (most recent call last):
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/jupyter_cache/executors/utils.py", line 58, in single_nb_execution
    executenb(
    ~~~~~~~~~^
        nb,
        ^^^
    ...<4 lines>...
        **kwargs,
        ^^^^^^^^^
    )
    ^
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/nbclient/client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/base_events.py", line 721, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
        cell, index, execution_count=self.code_cells_executed + 1
    )
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/nbclient/client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/Users/pierre-luc.bacon/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/nbclient/client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
import numpy as np

def sample_from_discounted_visitation(
   alpha, 
   policy, 
   transition_model, 
   gamma, 
   n_samples=1000
):
   """Sample states from the discounted visitation distribution.
   
   Args:
       alpha: Initial state distribution (vector of probabilities)
       policy: Function (state -> action probabilities)
       transition_model: Function (state, action -> next state probabilities)
       gamma: Discount factor
       n_samples: Number of states to sample
   
   Returns:
       Array of sampled states
   """
   samples = []
   n_states = len(alpha)
   
   for _ in range(n_samples):
       # With probability (1-gamma): reset
       if np.random.random() > gamma:
           current_state = np.random.choice(n_states, p=alpha)
       # With probability gamma: continue
       else:
           # Sample action from policy
           action_probs = policy(current_state)
           action = np.random.choice(len(action_probs), p=action_probs)
           
           # Sample next state from transition model
           next_state_probs = transition_model(current_state, action)
           current_state = np.random.choice(n_states, p=next_state_probs)
           
       samples.append(current_state)
   
   return np.array(samples)

# Example usage for a simple 2-state MDP
alpha = np.array([0.7, 0.3])  # Initial distribution
policy = lambda s: np.array([0.8, 0.2])  # Dummy policy
transition_model = lambda s, a: np.array([0.9, 0.1])  # Dummy transitions
gamma = 0.9

samples = sample_from_discounted_visitation(alpha, policy, transition_model, gamma)
------------------


[0;31m---------------------------------------------------------------------------[0m
[0;31mUnboundLocalError[0m                         Traceback (most recent call last)
Cell [0;32mIn[2], line 49[0m
[1;32m     46[0m transition_model [38;5;241m=[39m [38;5;28;01mlambda[39;00m s, a: np[38;5;241m.[39marray([[38;5;241m0.9[39m, [38;5;241m0.1[39m])  [38;5;66;03m# Dummy transitions[39;00m
[1;32m     47[0m gamma [38;5;241m=[39m [38;5;241m0.9[39m
[0;32m---> 49[0m samples [38;5;241m=[39m [43msample_from_discounted_visitation[49m[43m([49m[43malpha[49m[43m,[49m[43m [49m[43mpolicy[49m[43m,[49m[43m [49m[43mtransition_model[49m[43m,[49m[43m [49m[43mgamma[49m[43m)[49m

Cell [0;32mIn[2], line 32[0m, in [0;36msample_from_discounted_visitation[0;34m(alpha, policy, transition_model, gamma, n_samples)[0m
[1;32m     28[0m     current_state [38;5;241m=[39m np[38;5;241m.[39mrandom[38;5;241m.[39mchoice(n_states, p[38;5;241m=[39malpha)
[1;32m     29[0m [38;5;66;03m# With probability gamma: continue[39;00m
[1;32m     30[0m [38;5;28;01melse[39;00m:
[1;32m     31[0m     [38;5;66;03m# Sample action from policy[39;00m
[0;32m---> 32[0m     action_probs [38;5;241m=[39m policy([43mcurrent_state[49m)
[1;32m     33[0m     action [38;5;241m=[39m np[38;5;241m.[39mrandom[38;5;241m.[39mchoice([38;5;28mlen[39m(action_probs), p[38;5;241m=[39maction_probs)
[1;32m     35[0m     [38;5;66;03m# Sample next state from transition model[39;00m

[0;31mUnboundLocalError[0m: cannot access local variable 'current_state' where it is not associated with a value

