---
---

@article{Hall1968,
  title = {Optimal Timing of Irrigation},
  volume = {94},
  ISSN = {2690-3296},
  url = {http://dx.doi.org/10.1061/JRCEA4.0000569},
  DOI = {10.1061/jrcea4.0000569},
  number = {2},
  journal = {Journal of the Irrigation and Drainage Division},
  publisher = {American Society of Civil Engineers (ASCE)},
  author = {Hall,  Warren A. and Butcher,  William S.},
  year = {1968},
  month = jun,
  pages = {267–275}
}

@article{kraft1988,
  title={A software package for sequential quadratic programming},
  author={Kraft, Dieter},
  journal={DFVLR Obersfaffeheim Report},
  volume={88},
  number={28},
  pages={1--20},
  year={1988}
}

@article{holland1992genetic,
  title={Genetic algorithms},
  author={Holland, John H},
  journal={Scientific american},
  volume={267},
  number={1},
  pages={66--73},
  year={1992},
  publisher={JSTOR}
}

@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt Jr, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@inproceedings{kennedy1995particle,
  title={Particle swarm optimization},
  author={Kennedy, James and Eberhart, Russell},
  booktitle={Proceedings of ICNN'95-International Conference on Neural Networks},
  volume={4},
  pages={1942--1948},
  year={1995},
  organization={IEEE}
}

@article{Iskhakov2020,
  title = {Machine learning and structural econometrics: contrasts and synergies},
  volume = {23},
  ISSN = {1368-423X},
  url = {http://dx.doi.org/10.1093/ectj/utaa019},
  DOI = {10.1093/ectj/utaa019},
  number = {3},
  journal = {The Econometrics Journal},
  publisher = {Oxford University Press (OUP)},
  author = {Iskhakov,  Fedor and Rust,  John and Schjerning,  Bertel},
  year = {2020},
  month = aug,
  pages = {S81–S124}
}

@book{ortega_rheinboldt_1970,
  author    = {J. M. Ortega and W. C. Rheinboldt},
  title     = {Iterative Solution of Nonlinear Equations in Several Variables},
  year      = {1970},
  publisher = {Academic Press},
  address   = {New York},
  series    = {Computer Science and Applied Mathematics},
}

@book{allgower_georg_1990,
  author    = {E. L. Allgower and K. Georg},
  title     = {Numerical Continuation Methods: An Introduction},
  year      = {1990},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  series    = {Springer Series in Computational Mathematics},
  volume    = {13},
}
@book{arrow1958studies,
  title={Studies in linear and non-linear programming},
  author={Arrow, Kenneth J and Hurwicz, Leonid and Uzawa, Hirofumi},
  year={1958},
  publisher={Stanford University Press}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
@book{pontryagin1962mathematical,
  title={The Mathematical Theory of Optimal Processes},
  author={Pontryagin, Lev Semyonovich and Boltyanskii, Vladimir Grigor'evich and Gamkrelidze, Revaz Valerianovich and Mishchenko, Evgenii Frolovich},
  year={1962},
  publisher={Interscience Publishers}
}

@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@book{griewank1989automatic,
  title={On automatic differentiation},
  author={Griewank, Andreas},
  year={1989},
  publisher={Mathematical Programming: Recent Developments and Applications}
}

@article{lecun1988theoretical,
  title={A theoretical framework for back-propagation},
  author={LeCun, Yann},
  journal={Proceedings of the 1988 Connectionist Models Summer School},
  pages={21--28},
  year={1988},
  publisher={Morgan Kaufmann}
}
@inproceedings{Gravdahl1997,
  title = {Compressor surge control using a close-coupled valve and backstepping},
  url = {http://dx.doi.org/10.1109/ACC.1997.609673},
  DOI = {10.1109/acc.1997.609673},
  booktitle = {Proceedings of the 1997 American Control Conference (Cat. No.97CH36041)},
  publisher = {IEEE},
  author = {Gravdahl,  J.T. and Egeland,  O.},
  year = {1997},
  pages = {982–986 vol.2}
}

@book{Grancharova2012,
  title     = "Explicit nonlinear model predictive control",
  author    = "Grancharova, Alexandra Ivanova and Johansen, Tor Arne",
  publisher = "Springer",
  series    = "Lecture notes in control and information sciences",
  edition   =  2012,
  month     =  mar,
  year      =  2012,
  address   = "Berlin, Germany",
  copyright = "https://www.springernature.com/gp/researchers/text-and-data-mining",
  language  = "en"
}
@book{fiacco1983introduction,
  title={Introduction to Sensitivity and Stability Analysis in Nonlinear Programming},
  author={Fiacco, Anthony V.},
  year={1983},
  publisher={Academic Press}
}
@article{Sawaguchi2008,
  title = {A Model-Predictive Hypnosis Control System Under Total Intravenous Anesthesia},
  volume = {55},
  ISSN = {0018-9294},
  url = {http://dx.doi.org/10.1109/tbme.2008.915670},
  DOI = {10.1109/tbme.2008.915670},
  number = {3},
  journal = {IEEE Transactions on Biomedical Engineering},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Sawaguchi,  Y. and Furutani,  E. and Shirakami,  G. and Araki,  M. and Fukuda,  K.},
  year = {2008},
  month = mar,
  pages = {874–887}
}
@article{Adams2009,
  title = {Spending on new drug development1},
  volume = {19},
  ISSN = {1099-1050},
  url = {http://dx.doi.org/10.1002/hec.1454},
  DOI = {10.1002/hec.1454},
  number = {2},
  journal = {Health Economics},
  publisher = {Wiley},
  author = {Adams,  Christopher Paul and Brantner,  Van Vu},
  year = {2009},
  month = feb,
  pages = {130–141}
}
@book{Chang2010, 
  title={Monte Carlo Simulation for the Pharmaceutical Industry: Concepts, Algorithms, and Case Studies}, 
  ISBN={9780429152382}, 
  url={http://dx.doi.org/10.1201/EBK1439835920}, 
  DOI={10.1201/ebk1439835920}, 
  publisher={CRC Press}, 
  author={Chang, Mark}, 
  year={2010}, 
  month=sep 
}
@book{Conroy2013,
  title = {Decision Making in Natural Resource Management: A Structured,  Adaptive Approach: A Structured,  Adaptive Approach},
  ISBN = {9781118506196},
  url = {http://dx.doi.org/10.1002/9781118506196},
  DOI = {10.1002/9781118506196},
  publisher = {Wiley},
  author = {Conroy,  Michael J. and Peterson,  James T.},
  year = {2013},
  month = jan 
}
@book{Puterman1994,
  author    = {Martin L. Puterman},
  title     = {Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  year      = {1994},
  publisher = {John Wiley \& Sons},
  address   = {New York},
  isbn      = {978-0-471-61977-3},
  note      = {First published in 1994},
}
@article{rust1987optimal,
    author = {John Rust},
    title = {Optimal Replacement of GMC Bus Engines: An Empirical Model of Harold Zurcher},
    journal = {Econometrica},
    volume = {55},
    number = {5},
    pages = {999-1033},
    year = {1987},
    publisher = {JSTOR}
}

@article{Keane1994,
  title = {The Solution and Estimation of Discrete Choice Dynamic Programming Models by Simulation and Interpolation: Monte Carlo Evidence},
  volume = {76},
  ISSN = {0034-6535},
  url = {http://dx.doi.org/10.2307/2109768},
  DOI = {10.2307/2109768},
  number = {4},
  journal = {The Review of Economics and Statistics},
  publisher = {JSTOR},
  author = {Keane,  Michael P. and Wolpin,  Kenneth I.},
  year = {1994},
  month = nov,
  pages = {648}
}

@inproceedings{ziebart2008maximum,
    author = {Brian D. Ziebart and Andrew L. Maas and J. Andrew Bagnell and Anind K. Dey},
    title = {Maximum Entropy Inverse Reinforcement Learning},
    booktitle = {Proceedings of the 23rd AAAI Conference on Artificial Intelligence},
    year = {2008},
    pages = {1433-1438}
}
 
@article{haarnoja2017reinforcement,
    author = {Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine},
    title = {Reinforcement Learning with Deep Energy-Based Policies},
    journal = {Proceedings of the 34th International Conference on Machine Learning},
    year = {2017},
    pages = {1352-1361},
    volume = {70},
    publisher = {PMLR}
}
@article{levine2018reinforcement,
    author = {Sergey Levine and Aviral Kumar and George Tucker and Justin Fu},
    title = {Reinforcement Learning as a Framework for Control: A Survey},
    journal = {arXiv preprint arXiv:1806.04222},
    year = {2018}
}

@InProceedings{geist2019,
  title = 	 {A Theory of Regularized {M}arkov Decision Processes},
  author =       {Geist, Matthieu and Scherrer, Bruno and Pietquin, Olivier},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {2160--2169},
  year = 	 {2019},
  editor = 	 {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/geist19a/geist19a.pdf},
  url = 	 {https://proceedings.mlr.press/v97/geist19a.html},
  abstract = 	 {Many recent successful (deep) reinforcement learning algorithms make use of regularization, generally based on entropy or Kullback-Leibler divergence. We propose a general theory of regularized Markov Decision Processes that generalizes these approaches in two directions: we consider a larger class of regularizers, and we consider the general modified policy iteration approach, encompassing both policy iteration and value iteration. The core building blocks of this theory are a notion of regularized Bellman operator and the Legendre-Fenchel transform, a classical tool of convex optimization. This approach allows for error propagation analyses of general algorithmic schemes of which (possibly variants of) classical algorithms such as Trust Region Policy Optimization, Soft Q-learning, Stochastic Actor Critic or Dynamic Policy Programming are special cases. This also draws connections to proximal convex optimization, especially to Mirror Descent.}
}
@article{Bertsekas1983,
  title = {Distributed asynchronous computation of fixed points},
  volume = {27},
  ISSN = {1436-4646},
  url = {http://dx.doi.org/10.1007/BF02591967},
  DOI = {10.1007/bf02591967},
  number = {1},
  journal = {Mathematical Programming},
  publisher = {Springer Science and Business Media LLC},
  author = {Bertsekas,  Dimitri P.},
  year = {1983},
  month = sep,
  pages = {107–120}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 35th International Conference on Machine Learning (ICML)},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@article{haarnoja2018sacapplications,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@misc{kortum1992value,
  author    = {Kortum, Samuel},
  title     = {Value Function Approximation in an Estimation Routine},
  year      = {1992},
  note      = {Manuscript, Boston University},
}
@inbook{Rust1996,
  title = {Chapter 14 Numerical dynamic programming in economics},
  ISSN = {1574-0021},
  url = {http://dx.doi.org/10.1016/S1574-0021(96)01016-7},
  DOI = {10.1016/s1574-0021(96)01016-7},
  booktitle = {Handbook of Computational Economics},
  publisher = {Elsevier},
  author = {Rust,  John},
  year = {1996},
  pages = {619–729}
}
@article{ernst2005tree,
  author    = {Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  title     = {Tree-Based Batch Mode Reinforcement Learning},
  journal   = {Journal of Machine Learning Research},
  volume    = {6},
  pages     = {503--556},
  year      = {2005},
}
@inproceedings{riedmiller2005neural,
  author    = {Riedmiller, Martin},
  title     = {Neural Fitted Q Iteration – First Experiences with a Data Efficient Neural Reinforcement Learning Method},
  booktitle = {Proceedings of the 16th European Conference on Machine Learning (ECML)},
  pages     = {317--328},
  year      = {2005},
  publisher = {Springer},
  address   = {Berlin, Heidelberg},
}
@article{Ormoneit2002,
  volume = {49},
  ISSN = {0885-6125},
  url = {http://dx.doi.org/10.1023/A:1017928328829},
  DOI = {10.1023/a:1017928328829},
  number = {2/3},
  title = {Kernel-Based Reinforcement Learning},
  journal = {Machine Learning},
  publisher = {Springer Science and Business Media LLC},
  author = {Ormoneit,  Dirk and Sen,  Śaunak},
  year = {2002},
  pages = {161–178}
}
@article{ErnstGW05,
  author       = {Damien Ernst and
                  Pierre Geurts and
                  Louis Wehenkel},
  title        = {Tree-Based Batch Mode Reinforcement Learning},
  journal      = {J. Mach. Learn. Res.},
  volume       = {6},
  pages        = {503--556},
  year         = {2005},
  url          = {https://jmlr.org/papers/v6/ernst05a.html}
}
@article{Geurts2006,
  title = {Extremely randomized trees},
  volume = {63},
  ISSN = {1573-0565},
  url = {http://dx.doi.org/10.1007/s10994-006-6226-1},
  DOI = {10.1007/s10994-006-6226-1},
  number = {1},
  journal = {Machine Learning},
  publisher = {Springer Science and Business Media LLC},
  author = {Geurts,  Pierre and Ernst,  Damien and Wehenkel,  Louis},
  year = {2006},
  month = mar,
  pages = {3–42}
}
@inproceedings{Riedmiller05,
  author       = {Martin A. Riedmiller},
  editor       = {Jo{\~{a}}o Gama and
                  Rui Camacho and
                  Pavel Brazdil and
                  Al{\'{\i}}pio Jorge and
                  Lu{\'{\i}}s Torgo},
  title        = {Neural Fitted {Q} Iteration - First Experiences with a Data Efficient
                  Neural Reinforcement Learning Method},
  booktitle    = {Machine Learning: {ECML} 2005, 16th European Conference on Machine
                  Learning, Porto, Portugal, October 3-7, 2005, Proceedings},
  series       = {Lecture Notes in Computer Science},
  volume       = {3720},
  pages        = {317--328},
  publisher    = {Springer},
  year         = {2005},
  url          = {https://doi.org/10.1007/11564096\_32},
  doi          = {10.1007/11564096\_32}
}
@inproceedings{Gordon1995,
author = {Gordon, Geoffrey J.},
title = {Stable function approximation in dynamic programming},
year = {1995},
isbn = {1558603778},
publisher = {Morgan Kaufmann Publishers Inc.},
address = {San Francisco, CA, USA},
booktitle = {Proceedings of the Twelfth International Conference on International Conference on Machine Learning},
pages = {261–268},
numpages = {8},
location = {Tahoe City, California, USA},
series = {ICML'95}
}
@article{Hafner2011,
  title = {Reinforcement learning in feedback control: Challenges and benchmarks from technical process control},
  volume = {84},
  ISSN = {1573-0565},
  url = {http://dx.doi.org/10.1007/s10994-011-5235-x},
  DOI = {10.1007/s10994-011-5235-x},
  number = {1-2},
  journal = {Machine Learning},
  publisher = {Springer Science and Business Media LLC},
  author = {Hafner, Roland and Riedmiller, Martin},
  year = {2011},
  month = {feb},
  pages = {137-169}
}
@inproceedings{mnih2013atari,
  title={Playing Atari with Deep Reinforcement Learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  booktitle={NIPS Deep Learning Workshop},
  year={2013}
}
@article{lillicrap2015continuous,
  title={Continuous Control with Deep Reinforcement Learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@inproceedings{fujimoto2018addressing,
  title={Addressing Function Approximation Error in Actor-Critic Methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1587--1596},
  year={2018}
}
@inproceedings{ash2020warm,
  title={Warm-starting and Amortization in Continual Learning},
  author={Ash, Jordan T and Adams, Ryan P},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2020}
}
@inproceedings{Doro2023,
  author       = {Pierluca D'Oro and
                  Max Schwarzer and
                  Evgenii Nikishin and
                  Pierre-Luc Bacon and
                  Marc G. Bellemare and
                  Aaron C. Courville},
  title        = {Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio
                  Barrier},
  booktitle    = {The Eleventh International Conference on Learning Representations,
                  {ICLR} 2023, Kigali, Rwanda, May 1-5, 2023},
  publisher    = {OpenReview.net},
  year         = {2023}
}
@phdthesis{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning, and teaching},
  author={Lin, Long-Ji},
  year={1992},
  school={Carnegie Mellon University},
  address={Pittsburgh, PA, USA},
  note={Technical Report, CMU-CS-92-170}
}
@article{van2016deep,
  title={Deep Reinforcement Learning with Double Q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={30},
  number={1},
  year={2016},
  publisher={AAAI Press}
}
@phdthesis{watkins1989learning,
  title     = {Learning from Delayed Rewards},
  author    = {Watkins, Christopher John Cornish Hellaby},
  year      = {1989},
  school    = {University of Cambridge},
  address   = {Cambridge, UK}
}

@article{watkins1992qlearning,
  title     = {Q-learning},
  author    = {Watkins, Christopher J. C. H. and Dayan, Peter},
  journal   = {Machine Learning},
  volume    = {8},
  number    = {3-4},
  pages     = {279--292},
  year      = {1992},
  publisher = {Springer}
}

@article{jaakkola1994convergence,
  title     = {Convergence of Stochastic Iterative Dynamic Programming Algorithms},
  author    = {Jaakkola, Tommi and Jordan, Michael I. and Singh, Satinder P.},
  journal   = {Neural Computation},
  volume    = {6},
  number    = {6},
  pages     = {1185--1201},
  year      = {1994},
  publisher = {MIT Press}
}

@article{tsitsiklis1994asynchronous,
  title     = {Asynchronous Stochastic Approximation and Q-Learning},
  author    = {Tsitsiklis, John N.},
  journal   = {Machine Learning},
  volume    = {16},
  number    = {3},
  pages     = {185--202},
  year      = {1994},
  publisher = {Springer}
}

@article{borkar2000ode,
  title     = {ODE Methods for Temporal Difference Learning},
  author    = {Borkar, Vivek S. and Meyn, Sean P.},
  journal   = {SIAM Journal on Control and Optimization},
  volume    = {38},
  number    = {2},
  pages     = {447--465},
  year      = {2000},
  publisher = {SIAM}
}

@book{kushner2003stochastic,
  title     = {Stochastic Approximation and Recursive Algorithms and Applications},
  author    = {Kushner, Harold J. and Yin, G. George},
  edition   = {2nd},
  year      = {2003},
  publisher = {Springer},
  series    = {Applications of Mathematics},
  volume    = {35}
}

@book{SuttonBarto2018,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  year      = {2018},
  edition   = {2nd},
  publisher = {MIT Press},
  isbn      = {978-0262039246},
  url       = {http://incompleteideas.net/book/the-book-2nd.html}
}
@techreport{Coffey2010,
  title        = {Reduced-Order Residential Home Modeling for Model Predictive Control},
  author       = {B. Coffey and K. Knudsen and M. Guo and E. Haves},
  institution  = {National Renewable Energy Laboratory},
  year         = {2010},
  number       = {LBNL-4064E},
  url          = {https://doi.org/10.1016/j.enbuild.2014.01.033},
  note         = {Prepared under Lawrence Berkeley National Laboratory},
}
@article{COLE201469,
title = {Reduced-order residential home modeling for model predictive control},
journal = {Energy and Buildings},
volume = {74},
pages = {69-77},
year = {2014},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2014.01.033},
url = {https://www.sciencedirect.com/science/article/pii/S0378778814000711},
author = {Wesley J. Cole and Kody M. Powell and Elaine T. Hale and Thomas F. Edgar},
keywords = {Building energy simulation, Model reduction, EnergyPlus, OpenStudio, Model predictive control, Precooling, Thermal energy storage},
abstract = {Building simulation software packages such as EnergyPlus are useful energy modeling tools. These software packages, however, are often not amenable to model-based control due to model complexity or difficulties connecting control algorithms with the software. We present a method for automatically generating input/output data from an EnergyPlus residential home model using the OpenStudio software suite. These input/output data are used to create a simple reduced-order model that can be evaluated in fractions of a second. The reduced-order model is implemented in a model predictive controller to minimize the home's electricity costs during summer months in Austin, Texas, USA. The controller optimally precools the home in the morning and turns down or off the air conditioning system in the afternoon. For this example, electricity prices were taken from actual market prices in the Austin area. The optimal precooling strategy given by the model predictive controller reduces peak energy consumption from the air conditioning unit by an average of 70% and reduces operating costs by 60%. Precooling, however, consumes more total energy versus not precooling. Reducing peak energy consumption by 1kWh results, on average, in an increase of 0.63kWh in overall energy consumption.}
}
@misc{FDA2025,
  author = {{U.S. Food and Drug Administration}},
  title = {Artificial Intelligence and Machine Learning (AI/ML)-Enabled Medical Devices},
  year = {2025},
  note = {Accessed July 2025},
  url = {https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-aiml-enabled-medical-devices}
}

@article{Kleijnen2024,
  author = {Kleijnen, J. and others},
  title = {Scoping review of prospective evaluations of AI in healthcare decision-making},
  journal = {Lancet Digital Health},
  year = {2024},
  volume = {6},
  number = {3},
  pages = {e200--e212}
}

@misc{Chen2025,
  author = {Chen, L. and others},
  title = {A Review of Real-World Deployments of Reinforcement Learning and MPC in HVAC Systems},
  year = {2025},
  note = {White paper, accessed July 2025},
  url = {https://example.com/hvac-rl-review}
}

@misc{Evans2018,
  author = {Evans, D. and DeepMind},
  title = {DeepMind AI Reduces Google Data Centre Cooling Bill by 40%},
  year = {2018},
  url = {https://www.deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill}
}

@misc{Meta2024,
  author = {{Meta AI}},
  title = {Reinforcement Learning for Sustainable Cooling in Data Centers},
  year = {2024},
  note = {Meta Engineering Blog, accessed July 2025},
  url = {https://engineering.fb.com/2024/09/10/data-center/rl-sustainable-cooling}
}

@misc{Uber2025,
  author = {{Uber AI Labs}},
  title = {Reinforcement Learning at Scale for Ride-Matching Optimization},
  year = {2025},
  note = {Uber Engineering Blog, accessed July 2025},
  url = {https://www.uber.com/blog/rl-ride-matching}
}

@misc{ANYbotics2023,
  author = {{ANYbotics}},
  title = {ANYmal: RL-Powered Autonomous Inspection},
  year = {2023},
  note = {Company product documentation},
  url = {https://www.anybotics.com/anymal-inspection}
}
@article{Savorgnan2011,
  title = {Multiple shooting for distributed systems with applications in hydro electricity production},
  volume = {21},
  ISSN = {0959-1524},
  url = {http://dx.doi.org/10.1016/j.jprocont.2011.01.011},
  DOI = {10.1016/j.jprocont.2011.01.011},
  number = {5},
  journal = {Journal of Process Control},
  publisher = {Elsevier BV},
  author = {Savorgnan,  C. and Romani,  C. and Kozma,  A. and Diehl,  M.},
  year = {2011},
  month = jun,
  pages = {738–745}
}
@article{Sun2022,
  title = {OpenAP.top: Open Flight Trajectory Optimization for Air Transport and Sustainability Research},
  volume = {9},
  ISSN = {2226-4310},
  url = {http://dx.doi.org/10.3390/aerospace9070383},
  DOI = {10.3390/aerospace9070383},
  number = {7},
  journal = {Aerospace},
  publisher = {MDPI AG},
  author = {Sun,  Junzi},
  year = {2022},
  month = jul,
  pages = {383}
}
@misc{ERA52018,
  doi = {10.24381/CDS.ADBB2D47},
  url = {https://cds.climate.copernicus.eu/doi/10.24381/cds.adbb2d47},
  author = {{C3S}},
  title = {ERA5 hourly data on single levels from 1940 to present},
  publisher = {Copernicus Climate Change Service (C3S) Climate Data Store (CDS)},
  year = {2018}
}

@article{Gargiani2022,
  author={Gargiani, M. and Zanelli, A. and Liao-McPherson, D. and Summers, T. H. and Lygeros, J.},
  journal={IEEE Control Systems Letters}, 
  title={Dynamic Programming Through the Lens of Semismooth Newton-Type Methods}, 
  year={2022},
  volume={6},
  pages={2996-3001},
  doi={10.1109/LCSYS.2022.3181213}
}

@article{Judd1992,
  title={Projection methods for solving aggregate growth models},
  author={Judd, Kenneth L.},
  journal={Journal of Economic Theory},
  volume={58},
  number={2},
  pages={410--452},
  year={1992},
  publisher={Elsevier}
}

@incollection{Judd1996,
  title={Approximation, perturbation, and projection methods in economic analysis},
  author={Judd, Kenneth L.},
  booktitle={Handbook of Computational Economics},
  volume={1},
  pages={509--585},
  year={1996},
  publisher={Elsevier},
  editor={Amman, Hans M. and Kendrick, David A. and Rust, John}
}

@article{SantosVigoAguiar1998,
  title={Analysis of a numerical dynamic programming algorithm applied to economic models},
  author={Santos, Manuel S. and Vigo-Aguiar, Jesus},
  journal={Econometrica},
  volume={66},
  number={2},
  pages={409--426},
  year={1998},
  publisher={Wiley Online Library}
}

@book{Stachurski2009,
  title={Economic Dynamics: Theory and Computation},
  author={Stachurski, John},
  year={2009},
  publisher={MIT Press},
  address={Cambridge, MA},
  isbn={9780262012775}
}

@phdthesis{Gordon1999,
  title={Approximate Solutions to Markov Decision Problems},
  author={Gordon, Geoffrey J.},
  year={1999},
  school={Carnegie Mellon University},
  address={Pittsburgh, PA},
  note={Technical Report CMU-CS-99-111}
}

@article{AtkinsonPotra1987,
  author    = {Kendall E. Atkinson and Florian A. Potra},
  title     = {Projection and Iterated Projection Methods for Nonlinear Integral Equations},
  journal   = {SIAM Journal on Numerical Analysis},
  volume    = {24},
  number    = {6},
  pages     = {1352--1373},
  year      = {1987},
  publisher = {Society for Industrial and Applied Mathematics},
  doi       = {10.1137/0724087}
}

@unpublished{McGrattan1997,
  author      = {McGrattan, Ellen R.},
  title       = {Application of Weighted Residual Methods to Dynamic Economic Models},
  note        = {Mimeo, Federal Reserve Bank of Minneapolis},
  year        = {1997}
}

@incollection{Chakraverty2019,
  author    = {Chakraverty, Snehashish and Mahato, Nisha Rani and Karunakar, Perumandla and Rao, Tharasi Dilleswar},
  title     = {Weighted Residual Methods},
  booktitle = {Advanced Numerical and Semi-Analytical Methods for Differential Equations},
  year      = {2019},
  publisher = {John Wiley \& Sons, Inc.},
  chapter   = {3},
  pages     = {25--44},
  doi       = {10.1002/9781119423461.ch3},
  isbn      = {9781119423461},
  address   = {Hoboken, NJ}
}

@unpublished{LegrandJunca2025,
  author = {Legrand, Mathilde and Junca, St{\'e}phane},
  title  = {Weighted Residual Solution Methods},
  note   = {HAL Preprint},
  year   = {2025}
}

@article{Baird1995,
  title={Residual algorithms: Reinforcement learning with function approximation},
  author={Baird, Leemon},
  journal={Proceedings of the Twelfth International Conference on Machine Learning},
  pages={30--37},
  year={1995},
  publisher={Morgan Kaufmann}
}

@article{Sirignano2018,
  title={DGM: A deep learning algorithm for solving partial differential equations},
  author={Sirignano, Justin and Spiliopoulos, Konstantinos},
  journal={Journal of Computational Physics},
  volume={375},
  pages={1339--1364},
  year={2018},
  publisher={Elsevier},
  doi={10.1016/j.jcp.2018.08.029}
}

@article{Kharazmi2019,
  title={Variational physics-informed neural networks for solving partial differential equations},
  author={Kharazmi, Ehsan and Zhang, Zhongqiang and Karniadakis, George Em},
  journal={arXiv preprint arXiv:1912.00873},
  year={2019}
}

@article{Zang2020,
  title={Weak adversarial networks for high-dimensional partial differential equations},
  author={Zang, Yaohua and Bao, Gang and Ye, Xiaojing and Zhou, Haomin},
  journal={Journal of Computational Physics},
  volume={411},
  pages={109409},
  year={2020},
  publisher={Elsevier},
  doi={10.1016/j.jcp.2020.109409}
}

@article{TauchenHussey1991,
  title={Quadrature-based methods for obtaining approximate solutions to nonlinear asset pricing models},
  author={Tauchen, George and Hussey, Robert},
  journal={Econometrica},
  volume={59},
  number={2},
  pages={371--396},
  year={1991},
  publisher={Econometric Society},
  doi={10.2307/2938261}
}

@article{farebrother2024stop,
  title={Stop Regressing: Training Value Functions via Classification for Scalable Deep RL},
  author={Farebrother, Jesse and Machado, Marlos C. and Bowling, Michael},
  journal={arXiv preprint arXiv:2403.03950},
  year={2024},
  url={https://arxiv.org/abs/2403.03950}
}

@inproceedings{bellemare2017distributional,
  title={A Distributional Perspective on Reinforcement Learning},
  author={Bellemare, Marc G. and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning},
  pages={449--458},
  year={2017},
  volume={70},
  series={Proceedings of Machine Learning Research},
  publisher={PMLR}
}

@inproceedings{lee2013bias,
  title={Bias-corrected Q-learning to control max-operator bias in Q-learning},
  author={Lee, Donghun and Defourny, Boris and Powell, Warren B.},
  booktitle={2013 IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
  pages={93--99},
  year={2013},
  month=apr,
  publisher={IEEE},
  doi={10.1109/adprl.2013.6614994},
  url={http://dx.doi.org/10.1109/ADPRL.2013.6614994}
}

@article{lee2019biascorrected,
 title = {Bias-Corrected Q-Learning With Multistate Extension},
  volume = {64},
  ISSN = {2334-3303},
  url = {http://dx.doi.org/10.1109/TAC.2019.2912443},
  DOI = {10.1109/tac.2019.2912443},
  number = {10},
  journal = {IEEE Transactions on Automatic Control},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Lee,  Donghun and Powell,  Warren B.},
  year = {2019},
  month = oct,
  pages = {4011–4023}
}

@inproceedings{deramo2016estimating,
  title={Estimating the Maximum Expected Value through Gaussian Approximation},
  author={D'Eramo, Carlo and Nuara, Alessandro and Restelli, Marcello and Nowe, Ann},
  booktitle={Proceedings of the 33rd International Conference on Machine Learning},
  pages={1032--1040},
  year={2016},
  volume={48},
  series={Proceedings of Machine Learning Research},
  publisher={PMLR}
}

@article{garg2023extreme,
  title={Extreme Q-Learning: MaxEnt RL without Entropy},
  author={Garg, Divyansh and Tang, Joey and Kahn, Gregory and Levine, Sergey and Finn, Chelsea},
  journal={International Conference on Learning Representations (ICLR)},
  year={2023},
  url={https://openreview.net/forum?id=SJ0Lde3tRL}
}

@book{ndp,
  title={Numerical Methods in Economics},
  author={Judd, Kenneth L.},
  year={1998},
  publisher={MIT Press},
  address={Cambridge, MA},
  isbn={9780262100717}
}

@inproceedings{Heess2015,
  title={Learning Continuous Control Policies by Stochastic Value Gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  volume={28},
  year={2015},
  pages={2944--2952},
  publisher={Curran Associates, Inc.}
}

@inproceedings{Nachum2017,
  title={Bridging the Gap Between Value and Policy Based Reinforcement Learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  year={2017},
  pages={2775--2785},
  publisher={Curran Associates, Inc.}
}

@inproceedings{williams2016aggressive,
  title={Aggressive Driving with Model Predictive Path Integral Control},
  author={Williams, Grady and Drews, Paul and Goldfain, Brian and Rehg, James M. and Theodorou, Evangelos A.},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={1433--1440},
  organization={IEEE},
  doi={10.1109/ICRA.2016.7487277}
}

@article{williams2017mppi,
  title={Model Predictive Path Integral Control: From Theory to Parallel Computation},
  author={Williams, Grady and Aldrich, Andrew and Theodorou, Evangelos A.},
  journal={Journal of Guidance, Control, and Dynamics},
  volume={40},
  number={2},
  pages={344--357},
  year={2017},
  publisher={American Institute of Aeronautics and Astronautics},
  doi={10.2514/1.G001921}
}

@article{williams1992reinforce,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Williams, Ronald J.},
  journal={Machine Learning},
  volume={8},
  number={3},
  pages={229--256},
  year={1992},
  publisher={Springer},
  doi={10.1007/BF00992696}
}

@inproceedings{sutton1999policy,
  title={Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  author={Sutton, Richard S. and McAllester, David and Singh, Satinder and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems},
  volume={12},
  pages={1057--1063},
  year={1999},
  publisher={MIT Press}
}

@phdthesis{konda2002thesis,
  title={Actor-Critic Algorithms},
  author={Konda, Vijay R.},
  year={2002},
  school={Massachusetts Institute of Technology},
  department={Department of Electrical Engineering and Computer Science}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A Model-Based and Data-Efficient Approach to Policy Search},
  author={Deisenroth, Marc Peter and Rasmussen, Carl Edward},
  booktitle={Proceedings of the 28th International Conference on Machine Learning (ICML)},
  pages={465--472},
  year={2011},
  publisher={Omnipress}
}

@article{hafner2019dreamer,
  title={Dream to Control: Learning Behaviors by Latent Imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}