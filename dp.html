
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Dynamic Programming &#8212; Automatic Learning and Control</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=87e54e7c" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"bm": ["{\\boldsymbol #1}", 1]}, "processEscapes": true}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'dp';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="11. Bibliography" href="bibliography.html" />
    <link rel="prev" title="5. Continuous-Time Trajectory Optimization" href="cocp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Automatic Learning and Control</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ocp.html">1. Discrete-Time Trajectory Optimization</a></li>



<li class="toctree-l1"><a class="reference internal" href="cocp.html">5. Continuous-Time Trajectory Optimization</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Dynamic Programming</a></li>



<li class="toctree-l1"><a class="reference internal" href="bibliography.html">11. Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/edit/main/dp.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/issues/new?title=Issue%20on%20page%20%2Fdp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/dp.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Dynamic Programming</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7. Dynamic Programming</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#open-loop-vs-closed-loop-control">8. Open-Loop vs Closed-Loop Control</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#closing-the-loop-by-replanning">9. Closing the Loop by Replanning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-propofol-infusion-control">9.1. Example: Propofol Infusion Control</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-efficiency-improvements">9.2. Computational Efficiency Improvements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explicit-mpc">9.2.1. Explicit MPC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-optimization-and-neural-networks">9.2.1.1. Amortized Optimization and Neural Networks</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warmstarting-and-predictor-corrector-mpc">9.2.2. Warmstarting and Predictor-Corrector MPC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#principle-of-optimality">10. Principle of Optimality</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-recursion">10.1. Backward Recursion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-optimal-harvest-in-resource-management">10.2. Example: Optimal Harvest in Resource Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discretization-and-interpolation">10.3. Discretization and Interpolation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-recursion-with-interpolation">10.3.1. Backward Recursion with Interpolation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-considerations">10.3.2. Implementation Considerations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-optimal-harvest-with-linear-interpolation">10.3.3. Example: Optimal Harvest with Linear Interpolation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-quadratic-regulator-via-dynamic-programming">10.4. Linear Quadratic Regulator via Dynamic Programming</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-dynamic-programming">10.5. Stochastic Dynamic Programming</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-stochastic-optimal-harvest-in-resource-management">10.5.1. Example: Stochastic Optimal Harvest in Resource Management</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-decision-process-formulation">10.5.2. Markov Decision Process Formulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-control-theory-to-operations-research-notation">10.6. From Control Theory to Operations Research Notation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-sample-size-determination-in-pharmaceutical-development">10.6.1. Example: Sample Size Determination in Pharmaceutical Development</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rules-and-policies">10.7. Decision Rules and Policies</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="dynamic-programming">
<h1><span class="section-number">7. </span>Dynamic Programming<a class="headerlink" href="#dynamic-programming" title="Link to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="open-loop-vs-closed-loop-control">
<h1><span class="section-number">8. </span>Open-Loop vs Closed-Loop Control<a class="headerlink" href="#open-loop-vs-closed-loop-control" title="Link to this heading">#</a></h1>
<p>The methods seen so far, whether in discrete or continuous-time, were deterministic trajectory optimization methods. Given an initial state, they provide a prescription of controls to apply as a function of time. In the collocation case, we would also obtain a state trajectory corresponding to those controls as a by-product. The control function, <span class="math notranslate nohighlight">\(\mathbf{u}[i]\)</span> (in discrete time) or <span class="math notranslate nohighlight">\(u(t)\)</span> (in continuous-time), is blind to the system’s state at any point in time. It simply reads off the values stored in memory or performs some form of interpolation in time. This approach is optimal under the assumption that our system is deterministic. We know that no matter how many times we repeat the experiment from the same initial state, we will always get the same result; hence, reapplying the same controls in the same order is sufficient.</p>
<p>However, no matter how good our model is, real-life deployment of our controller will inevitably involve prediction errors. In such cases, a simple control function that only considers the current time—an open-loop controller—won’t suffice. We must inform our controller that the real world is likely not in the state it thinks it’s in: we need to provide feedback to close the loop. Depending on the structure of the noise affecting our system, we may encounter feedback controllers that depend on the entire history (in the case of partial observability) or just the current state (under perfect observability). Dynamic programming methods will provide us with solution methods to derive such controllers. These methods exist for both the continuous-time setting (via the Hamilton-Jacobi equations) and the discrete setting through the Bellman optimality equations. It also provides us with the necessary framework to address partially observable systems (for which we can’t directly measure the state) using the POMDP framework. We will cover these solution methods in this chapter.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="closing-the-loop-by-replanning">
<h1><span class="section-number">9. </span>Closing the Loop by Replanning<a class="headerlink" href="#closing-the-loop-by-replanning" title="Link to this heading">#</a></h1>
<p>There exists a simple recipe for closing the loop: since we will likely end up in states that we haven’t planned for, we might as well recompute our solution as frequently as possible using the updated state information as initial state to our trajectory optimization procedure. This replanning or reoptimization strategy is called Model Predictive Control (MPC). Given any trajectory optimization algorithm, we can turn it into a closed-loop variant using MPC.</p>
<p>Consider a trajectory optimization problem in Bolza form,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{minimize} \quad &amp; c(\mathbf{x}(t_0 + T)) + \int_{t_0}^{t_0 + T} c(\mathbf{x}(t), \mathbf{u}(t)) \, dt \\
\text{subject to} \quad &amp; \dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) \\
&amp; \mathbf{g}(\mathbf{x}(t), \mathbf{u}(t)) \leq \mathbf{0} \\
&amp; \mathbf{u}_{\text{min}} \leq \mathbf{u}(t) \leq \mathbf{u}_{\text{max}} \\
\text{given} \quad &amp; \mathbf{x}(t_0) = \mathbf{x}_{\text{current}} \enspace .
\end{aligned}
\end{split}\]</div>
<p>MPC then proceeds as follows. At the current time <span class="math notranslate nohighlight">\( t_0 \)</span>, the MPC controller considers a prediction horizon <span class="math notranslate nohighlight">\( T \)</span> over which it optimizes the future trajectory of the system. The controller then solves the trajectory optimization problem with the initial state set to the current state <span class="math notranslate nohighlight">\( \mathbf{x}_{\text{current}} = \mathbf{x}(t_0) \)</span>. This yields an optimal control trajectory <span class="math notranslate nohighlight">\( \mathbf{u}^*(t) \)</span> for <span class="math notranslate nohighlight">\( t \in [t_0, t_0 + T] \)</span>.</p>
<p>However,  Instead of applying the entire computed control trajectory, the controller extracts only the first part of the solution, namely <span class="math notranslate nohighlight">\( \mathbf{u}^*(t_0) \)</span>, and applies it to the system. This strategy is called <em>receding horizon control</em>. The idea is that the control <span class="math notranslate nohighlight">\( \mathbf{u}^*(t_0) \)</span> is based on the best prediction available at time <span class="math notranslate nohighlight">\( t_0 \)</span>, considering the current state of the system and expected future disturbances.</p>
<p>After applying the first control input, the system evolves according to its dynamics, and the controller measures the new state at the next time step, <span class="math notranslate nohighlight">\( t_0 + \Delta t \)</span>. Using this updated state as the new initial condition, the MPC controller re-solves the trajectory optimization problem over a shifted prediction horizon <span class="math notranslate nohighlight">\( [t_0 + \Delta t, t_0 + \Delta t + T] \)</span>.</p>
<p>This procedure is then repeated ad infinitum or until the end of overall control problem. More concisely, here’s a pseudo-code showing the general blueprint of MPC methods:</p>
<div class="proof algorithm admonition" id="alg-mpc">
<p class="admonition-title"><span class="caption-number">Algorithm 9.1 </span> (Non-linear Model Predictive Control)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong></p>
<ul class="simple">
<li><p>Prediction horizon <span class="math notranslate nohighlight">\( T \)</span></p></li>
<li><p>Time step <span class="math notranslate nohighlight">\( \Delta t \)</span></p></li>
<li><p>Initial state <span class="math notranslate nohighlight">\( \mathbf{x}(t_0) \)</span></p></li>
<li><p>Cost functions <span class="math notranslate nohighlight">\( c(\mathbf{x}(t), \mathbf{u}(t)) \)</span> and <span class="math notranslate nohighlight">\( c(\mathbf{x}(t_0 + T)) \)</span></p></li>
<li><p>System dynamics <span class="math notranslate nohighlight">\( \dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) \)</span></p></li>
<li><p>Constraints <span class="math notranslate nohighlight">\( \mathbf{g}(\mathbf{x}(t), \mathbf{u}(t)) \leq \mathbf{0} \)</span></p></li>
<li><p>Control limits <span class="math notranslate nohighlight">\( \mathbf{u}_{\text{min}} \leq \mathbf{u}(t) \leq \mathbf{u}_{\text{max}} \)</span></p></li>
</ul>
<p><strong>Output:</strong></p>
<ul class="simple">
<li><p>Control input sequence <span class="math notranslate nohighlight">\( \{\mathbf{u}(t)\} \)</span> applied to the system</p></li>
</ul>
<p><strong>Initialization:</strong></p>
<ol class="arabic simple">
<li><p>Set <span class="math notranslate nohighlight">\( t \leftarrow t_0 \)</span></p></li>
<li><p>Measure initial state <span class="math notranslate nohighlight">\( \mathbf{x}_{\text{current}} \leftarrow \mathbf{x}(t) \)</span></p></li>
</ol>
<p><strong>Procedure:</strong></p>
<ol class="arabic" start="3">
<li><p><strong>Repeat</strong> until the end of the control task:</p>
<ol class="arabic simple" start="4">
<li><p><strong>Solve the following optimization problem:</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[\begin{split}
   \begin{aligned}
   \text{minimize} \quad &amp; c(\mathbf{x}(t + T)) + \int_{t}^{t + T} c(\mathbf{x}(\tau), \mathbf{u}(\tau)) \, d\tau \\
   \text{subject to} \quad &amp; \dot{\mathbf{x}}(\tau) = \mathbf{f}(\mathbf{x}(\tau), \mathbf{u}(\tau)) \quad \forall \tau \in [t, t + T] \\
   &amp; \mathbf{g}(\mathbf{x}(\tau), \mathbf{u}(\tau)) \leq \mathbf{0} \quad \forall \tau \in [t, t + T] \\
   &amp; \mathbf{u}_{\text{min}} \leq \mathbf{u}(\tau) \leq \mathbf{u}_{\text{max}} \quad \forall \tau \in [t, t + T] \\
   \text{given} \quad &amp; \mathbf{x}(t) = \mathbf{x}_{\text{current}}
   \end{aligned}
   \end{split}\]</div>
<ul class="simple">
<li><p>Obtain the optimal control trajectory <span class="math notranslate nohighlight">\( \mathbf{u}^*(\tau) \)</span> and the optimal state trajectory <span class="math notranslate nohighlight">\( \mathbf{x}^*(\tau) \)</span> for <span class="math notranslate nohighlight">\( \tau \in [t, t + T] \)</span>.</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p><strong>Apply the first control input:</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[
   \mathbf{u}(t) \leftarrow \mathbf{u}^*(t)
   \]</div>
<ul class="simple">
<li><p>Apply <span class="math notranslate nohighlight">\( \mathbf{u}(t) \)</span> to the system.</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p><strong>Advance the system state:</strong></p></li>
</ol>
<ul class="simple">
<li><p>Let the system evolve under the control <span class="math notranslate nohighlight">\( \mathbf{u}(t) \)</span> according to the dynamics <span class="math notranslate nohighlight">\( \dot{\mathbf{x}}(t) = \mathbf{f}(\mathbf{x}(t), \mathbf{u}(t)) \)</span>.</p></li>
<li><p>Update <span class="math notranslate nohighlight">\( t \leftarrow t + \Delta t \)</span>.</p></li>
</ul>
<ol class="arabic simple" start="7">
<li><p><strong>Measure the new state:</strong></p></li>
</ol>
<div class="math notranslate nohighlight">
\[
   \mathbf{x}_{\text{current}} \leftarrow \mathbf{x}(t)
   \]</div>
</li>
<li><p><strong>End Repeat</strong></p></li>
</ol>
</section>
</div><section id="example-propofol-infusion-control">
<h2><span class="section-number">9.1. </span>Example: Propofol Infusion Control<a class="headerlink" href="#example-propofol-infusion-control" title="Link to this heading">#</a></h2>
<p>This problem explores the control of propofol infusion in total intravenous anesthesia (TIVA). Our presentation follows the problem formulation developped by <span id="id1">Sawaguchi <em>et al.</em> [<a class="reference internal" href="bibliography.html#id19" title="Y. Sawaguchi, E. Furutani, G. Shirakami, M. Araki, and K. Fukuda. A model-predictive hypnosis control system under total intravenous anesthesia. IEEE Transactions on Biomedical Engineering, 55(3):874–887, March 2008. URL: http://dx.doi.org/10.1109/tbme.2008.915670, doi:10.1109/tbme.2008.915670.">19</a>]</span>. The primary objective is to maintain the desired level of unconsciousness while minimizing adverse reactions and ensuring quick recovery after surgery.</p>
<p>The level of unconsciousness is measured by the Bispectral Index (BIS), which is obtained using an electroencephalography (EEG) device. The BIS ranges from <span class="math notranslate nohighlight">\(0\)</span> (complete suppression of brain activity) to <span class="math notranslate nohighlight">\(100\)</span> (fully awake), with the target range for general anesthesia typically between <span class="math notranslate nohighlight">\(40\)</span> and <span class="math notranslate nohighlight">\(60\)</span>.</p>
<p>The goal is to design a control system that regulates the infusion rate of propofol to maintain the BIS within the target range. This can be formulated as an optimal control problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\min_{u(t)} &amp; \int_{0}^{T} \left( BIS(t) - BIS_{\text{target}} \right)^2 + \lambda u(t)^2 \, dt \\
\text{subject to:} \\
\dot{x}_1 &amp;= -(k_{10} + k_{12} + k_{13})x_1 + k_{21}x_2 + k_{31}x_3 + \frac{u(t)}{V_1} \\
\dot{x}_2 &amp;= k_{12}x_1 - k_{21}x_2 \\
\dot{x}_3 &amp;= k_{13}x_1 - k_{31}x_3 \\
\dot{x}_e &amp;= k_{e0}(x_1 - x_e) \\
BIS(t) &amp;= E_0 - E_{\text{max}}\frac{x_e^\gamma}{x_e^\gamma + EC_{50}^\gamma}
\end{align*}
\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(u(t)\)</span> is the propofol infusion rate (mg/kg/h)</p></li>
<li><p><span class="math notranslate nohighlight">\(x_1\)</span>, <span class="math notranslate nohighlight">\(x_2\)</span>, and <span class="math notranslate nohighlight">\(x_3\)</span> are the drug concentrations in different body compartments</p></li>
<li><p><span class="math notranslate nohighlight">\(x_e\)</span> is the effect-site concentration</p></li>
<li><p><span class="math notranslate nohighlight">\(k_{ij}\)</span> are rate constants for drug transfer between compartments</p></li>
<li><p><span class="math notranslate nohighlight">\(BIS(t)\)</span> is the Bispectral Index</p></li>
<li><p><span class="math notranslate nohighlight">\(\lambda\)</span> is a regularization parameter penalizing excessive drug use</p></li>
<li><p><span class="math notranslate nohighlight">\(E_0\)</span>, <span class="math notranslate nohighlight">\(E_{\text{max}}\)</span>, <span class="math notranslate nohighlight">\(EC_{50}\)</span>, and <span class="math notranslate nohighlight">\(\gamma\)</span> are parameters of the pharmacodynamic model</p></li>
</ul>
<p>The specific dynamics model used in this problem is so-called “Pharmacokinetic-Pharmacodynamic Model” and consists of three main components:</p>
<ol class="arabic simple">
<li><p><strong>Pharmacokinetic Model</strong>, which describes how the drug distributes through the body over time. It’s based on a three-compartment model:</p>
<ul class="simple">
<li><p>Central compartment (blood and well-perfused organs)</p></li>
<li><p>Shallow peripheral compartment (muscle and other tissues)</p></li>
<li><p>Deep peripheral compartment (fat)</p></li>
</ul>
</li>
<li><p><strong>Effect Site Model</strong>, which represents the delay between drug concentration in the blood and its effect on the brain.</p></li>
<li><p><strong>Pharmacodynamic Model</strong> that relates the effect-site concentration to the observed BIS.</p></li>
</ol>
<p>The propofol infusion control problem presents several interesting challenges from a research perspective.
First, there is a delay in how fast the drug can reach a different compartments in addition to the BIS measurements which can lag. This could lead to instability if not properly addressed in the control design.</p>
<p>Furthermore, every patient is different from another. Hence, we cannot simply learn a single controller offline and hope that it will generalize to an entire patient population. We will account for this variability through Model Predictive Control (MPC) and dynamically adapt to the model mismatch through replanning. How a patient will react to a given dose of drug also varies and must be carefully controlled to avoid overdoses. This adds an additional layer of complexity since we have to incorporate safety constraints. Finally, the patient might suddenly change state, for example due to surgical stimuli, and the controller must be able to adapt quickly to compensate for the disturbance to the system.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">class</span> <span class="nc">Patient</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">age</span><span class="p">,</span> <span class="n">weight</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">age</span> <span class="o">=</span> <span class="n">age</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_pk_params</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_pd_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_pk_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v1</span> <span class="o">=</span> <span class="mf">4.27</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.71</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">age</span> <span class="o">/</span> <span class="mi">30</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.39</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v2</span> <span class="o">=</span> <span class="mf">18.9</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.64</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">age</span> <span class="o">/</span> <span class="mi">30</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.62</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">v3</span> <span class="o">=</span> <span class="mi">238</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.95</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cl1</span> <span class="o">=</span> <span class="mf">1.89</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.75</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">age</span> <span class="o">/</span> <span class="mi">30</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cl2</span> <span class="o">=</span> <span class="mf">1.29</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.62</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cl3</span> <span class="o">=</span> <span class="mf">0.836</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weight</span> <span class="o">/</span> <span class="mi">70</span><span class="p">)</span> <span class="o">**</span> <span class="mf">0.77</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k10</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cl1</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">v1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k12</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cl2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">v1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k13</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cl3</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">v1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k21</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cl2</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">v2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k31</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cl3</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">v3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ke0</span> <span class="o">=</span> <span class="mf">0.456</span>

    <span class="k">def</span> <span class="nf">set_pd_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">E0</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Emax</span> <span class="o">=</span> <span class="mi">100</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">EC50</span> <span class="o">=</span> <span class="mf">3.4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="mi">3</span>

<span class="k">def</span> <span class="nf">pk_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">patient</span><span class="p">):</span>
    <span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">x3</span><span class="p">,</span> <span class="n">xe</span> <span class="o">=</span> <span class="n">x</span>
    <span class="n">dx1</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">patient</span><span class="o">.</span><span class="n">k10</span> <span class="o">+</span> <span class="n">patient</span><span class="o">.</span><span class="n">k12</span> <span class="o">+</span> <span class="n">patient</span><span class="o">.</span><span class="n">k13</span><span class="p">)</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">+</span> <span class="n">patient</span><span class="o">.</span><span class="n">k21</span> <span class="o">*</span> <span class="n">x2</span> <span class="o">+</span> <span class="n">patient</span><span class="o">.</span><span class="n">k31</span> <span class="o">*</span> <span class="n">x3</span> <span class="o">+</span> <span class="n">u</span> <span class="o">/</span> <span class="n">patient</span><span class="o">.</span><span class="n">v1</span>
    <span class="n">dx2</span> <span class="o">=</span> <span class="n">patient</span><span class="o">.</span><span class="n">k12</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">patient</span><span class="o">.</span><span class="n">k21</span> <span class="o">*</span> <span class="n">x2</span>
    <span class="n">dx3</span> <span class="o">=</span> <span class="n">patient</span><span class="o">.</span><span class="n">k13</span> <span class="o">*</span> <span class="n">x1</span> <span class="o">-</span> <span class="n">patient</span><span class="o">.</span><span class="n">k31</span> <span class="o">*</span> <span class="n">x3</span>
    <span class="n">dxe</span> <span class="o">=</span> <span class="n">patient</span><span class="o">.</span><span class="n">ke0</span> <span class="o">*</span> <span class="p">(</span><span class="n">x1</span> <span class="o">-</span> <span class="n">xe</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">dx1</span><span class="p">,</span> <span class="n">dx2</span><span class="p">,</span> <span class="n">dx3</span><span class="p">,</span> <span class="n">dxe</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">pd_model</span><span class="p">(</span><span class="n">ce</span><span class="p">,</span> <span class="n">patient</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">patient</span><span class="o">.</span><span class="n">E0</span> <span class="o">-</span> <span class="n">patient</span><span class="o">.</span><span class="n">Emax</span> <span class="o">*</span> <span class="p">(</span><span class="n">ce</span> <span class="o">**</span> <span class="n">patient</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">ce</span> <span class="o">**</span> <span class="n">patient</span><span class="o">.</span><span class="n">gamma</span> <span class="o">+</span> <span class="n">patient</span><span class="o">.</span><span class="n">EC50</span> <span class="o">**</span> <span class="n">patient</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">simulate_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">):</span>
    <span class="n">x_next</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">pk_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">patient</span><span class="p">)</span>
    <span class="n">bis</span> <span class="o">=</span> <span class="n">pd_model</span><span class="p">(</span><span class="n">x_next</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">patient</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_next</span><span class="p">,</span> <span class="n">bis</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">total_cost</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">bis</span> <span class="o">=</span> <span class="n">simulate_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
        <span class="n">total_cost</span> <span class="o">+=</span> <span class="p">(</span><span class="n">bis</span> <span class="o">-</span> <span class="n">target_bis</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">total_cost</span>

<span class="k">def</span> <span class="nf">mpc_step</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">):</span>
    <span class="n">u0</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>  <span class="c1"># Initial guess</span>
    <span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span><span class="p">)]</span> <span class="o">*</span> <span class="n">N</span>  <span class="c1"># Infusion rate between 0 and 20 mg/kg/h</span>
    
    <span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">u0</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">),</span>
                      <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bounds</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Return only the first control input</span>

<span class="k">def</span> <span class="nf">run_mpc_simulation</span><span class="p">(</span><span class="n">patient</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">):</span>
    <span class="n">steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">T</span> <span class="o">/</span> <span class="n">dt</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">steps</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="n">bis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="c1"># Add noise to the current state to simulate real-world uncertainty</span>
        <span class="n">x_noisy</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        
        <span class="c1"># Use noisy state for MPC planning</span>
        <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mpc_step</span><span class="p">(</span><span class="n">x_noisy</span><span class="p">,</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">)</span>
        
        <span class="c1"># Evolve the true state using the deterministic model</span>
        <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">bis</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">simulate_step</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">u</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">patient</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
    
    <span class="n">bis</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd_model</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">patient</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">bis</span><span class="p">,</span> <span class="n">u</span>

<span class="c1"># Set up the problem</span>
<span class="n">patient</span> <span class="o">=</span> <span class="n">Patient</span><span class="p">(</span><span class="n">age</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mi">70</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">120</span>  <span class="c1"># Total time in minutes</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Time step in minutes</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Prediction horizon</span>
<span class="n">target_bis</span> <span class="o">=</span> <span class="mi">50</span>  <span class="c1"># Target BIS value</span>

<span class="c1"># Run MPC simulation</span>
<span class="n">x</span><span class="p">,</span> <span class="n">bis</span><span class="p">,</span> <span class="n">u</span> <span class="o">=</span> <span class="n">run_mpc_simulation</span><span class="p">(</span><span class="n">patient</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">dt</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">target_bis</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">T</span><span class="o">+</span><span class="n">dt</span><span class="p">,</span> <span class="n">dt</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">bis</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;BIS&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">target_bis</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">u</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Infusion Rate (mg/kg/h)&#39;</span><span class="p">)</span>

<span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Effect-site Concentration (µg/mL)&#39;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time (min)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Initial BIS: </span><span class="si">{</span><span class="n">bis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final BIS: </span><span class="si">{</span><span class="n">bis</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean infusion rate: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">u</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> mg/kg/h&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final effect-site concentration: </span><span class="si">{</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> µg/mL&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/e797283b952764f37c5cc3cb9ba1b36fb829cf65cfa1d0a08e30de59954dc219.png" src="_images/e797283b952764f37c5cc3cb9ba1b36fb829cf65cfa1d0a08e30de59954dc219.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Initial BIS: 100.00
Final BIS: 50.09
Mean infusion rate: 8.85 mg/kg/h
Final effect-site concentration: 3.40 µg/mL
</pre></div>
</div>
</div>
</div>
</section>
<section id="computational-efficiency-improvements">
<h2><span class="section-number">9.2. </span>Computational Efficiency Improvements<a class="headerlink" href="#computational-efficiency-improvements" title="Link to this heading">#</a></h2>
<p>One challenge of Model Predictive Control (MPC) is its computational cost. In real-time applications, such as adaptive optics, the controller may need to operate at extremely high frequencies—for example, 1000 Hz. In this scenario, the solver has just 1 millisecond to compute an optimal solution, pushing the limits of computational efficiency.</p>
<section id="explicit-mpc">
<h3><span class="section-number">9.2.1. </span>Explicit MPC<a class="headerlink" href="#explicit-mpc" title="Link to this heading">#</a></h3>
<p>A potential solution to this problem is to offload some of the computational effort offline. Instead of solving the optimization problem at every time step during execution, we could attempt to <strong>precompute solutions</strong> for all potential states in advance. At first glance, this seems impractical—without leveraging specific structure or partitioning the state space intelligently, precomputing solutions for every possible state would be infeasible. However, with the right techniques, this approach becomes viable.</p>
<p>This is the essence of <strong>explicit MPC</strong>, which hinges on a subfield of mathematical programming known as multi-parametric (or simply parametric) programming.  A multiparametric programming problem can be described by the following formulation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{cl}
z(\boldsymbol{\theta}) = \min_{\mathbf{x}} &amp; f(\mathbf{x}, \boldsymbol{\theta}) \\
\text { s.t. } &amp; \mathbf{g}(\mathbf{x}, \boldsymbol{\theta}) \leq 0 \\
&amp; \mathbf{h}(\mathbf{x}, \boldsymbol{\theta}) = 0 \\
&amp; \mathbf{x} \in \mathbb{R}^n \\
&amp; \boldsymbol{\theta} \in \mathbb{R}^m
\end{array}
\end{split}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^n\)</span> are the decision variables,</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\theta} \in \mathbb{R}^m\)</span> are the parameters,</p></li>
<li><p><span class="math notranslate nohighlight">\(f(\mathbf{x}, \boldsymbol{\theta})\)</span> is the objective function,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{g}(\mathbf{x}, \boldsymbol{\theta}) \leq 0\)</span> and <span class="math notranslate nohighlight">\(\mathbf{h}(\mathbf{x}, \boldsymbol{\theta}) = 0\)</span> are the inequality and equality constraints, respectively.</p></li>
</ul>
<p>Parametric programming methods provides ways for efficiently evaluating <span class="math notranslate nohighlight">\(z(\boldsymbol{\theta})\)</span> – the <strong>value function</strong> – by leveraging the structure of the solution space. In particular, it leverages the idea that the solution space can be partitioned into <strong>critical regions</strong>—regions of the parameter space where the optimal solution structure remains unchanged. Within each region, the solution can often be expressed as a <strong>piecewise affine function</strong> of the parameters, which is easy to represent and compute offline.</p>
<p>In trajectory optimization problems, the initial state <span class="math notranslate nohighlight">\(\boldsymbol{x}_0\)</span> can also be treated as a <strong>parameter</strong>. This transforms the problem into a parametric optimization problem, where <span class="math notranslate nohighlight">\(\boldsymbol{x}_0\)</span> defines a family of optimization problems, each yielding a different optimal solution. The relationship between the parameters and solutions can be described using two key mappings:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{u}^\star(\boldsymbol{x}_0)\)</span>: The optimal control sequence as a function of the initial state.</p></li>
<li><p><span class="math notranslate nohighlight">\(v(\boldsymbol{x}_0)\)</span>: The value function, which gives the optimal objective value for a given <span class="math notranslate nohighlight">\(\boldsymbol{x}_0\)</span>.</p></li>
</ul>
<p>It is therefore at this level that parametric programming methods can come into play and provide efficient methods for computing the value function offline: that is without resorting to direct calls to a nonlinear programming solver for every new <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> encountered along a trajectory.</p>
<section id="amortized-optimization-and-neural-networks">
<h4><span class="section-number">9.2.1.1. </span>Amortized Optimization and Neural Networks<a class="headerlink" href="#amortized-optimization-and-neural-networks" title="Link to this heading">#</a></h4>
<p>The idea of solving an entire family of optimization problems efficiently is not unique to parametric programming. In machine learning, <strong>amortized optimization</strong> (or <strong>amortized inference</strong>) aims to “learn to optimize” by constructing models that generalize over a family of optimization problems. This approach is particularly relevant in applications such as hyperparameter optimization, meta-learning, and probabilistic inference.</p>
<p>In contrast to explicit MPC, which partitions the state space, amortized optimization typically uses <strong>neural networks</strong> to approximate the mapping from parameters to optimal solutions. This has led to recent explorations of <strong>amortizing NMPC (Nonlinear MPC) controllers</strong> into neural networks, blending the structure of MPC with the generalization power of neural networks. This represents a promising direction for creating efficient controllers that combine physics-based models, safety constraints, and the flexibility of learned models.</p>
<!-- 
As usual, the KKT conditions provide necessary conditions for optimality:

1. **Stationarity**:  

   $$
   \nabla_{\mathbf{x}} f(\mathbf{x}^*, \boldsymbol{\theta}) + \sum_{i=1}^{p} \lambda_i^* \nabla_{\mathbf{x}} g_i(\mathbf{x}^*, \boldsymbol{\theta}) + \sum_{j=1}^{q} \nu_j^* \nabla_{\mathbf{x}} h_j(\mathbf{x}^*, \boldsymbol{\theta}) = 0
   $$
   where $\boldsymbol{\lambda}^* = (\lambda_1^*, \ldots, \lambda_p^*)$ are the Lagrange multipliers for the inequality constraints, and $\boldsymbol{\nu}^* = (\nu_1^*, \ldots, \nu_q^*)$ are the Lagrange multipliers for the equality constraints.

2. **Primal Feasibility**:  

   $$
   \mathbf{g}(\mathbf{x}^*, \boldsymbol{\theta}) \leq 0, \quad \mathbf{h}(\mathbf{x}^*, \boldsymbol{\theta}) = 0
   $$

3. **Dual Feasibility**:  

   $$
   \lambda_i^* \geq 0, \quad \forall i
   $$

4. **Complementary Slackness**:  

   $$
   \lambda_i^* g_i(\mathbf{x}^*, \boldsymbol{\theta}) = 0, \quad \forall i
   $$


We can combine the KKT conditions into a single system of equations, denoted as $\mathbf{F}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\nu}, \boldsymbol{\theta}) = \mathbf{0}$, where:

$$
\mathbf{F}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\nu}, \boldsymbol{\theta}) = \begin{pmatrix}
\nabla_{\mathbf{x}} f(\mathbf{x}, \boldsymbol{\theta}) + \sum_{i=1}^{p} \lambda_i \nabla_{\mathbf{x}} g_i(\mathbf{x}, \boldsymbol{\theta}) + \sum_{j=1}^{q} \nu_j \nabla_{\mathbf{x}} h_j(\mathbf{x}, \boldsymbol{\theta}) \\
\mathbf{g}(\mathbf{x}, \boldsymbol{\theta}) \\
\mathbf{h}(\mathbf{x}, \boldsymbol{\theta}) \\
\boldsymbol{\lambda} \odot \mathbf{g}(\mathbf{x}, \boldsymbol{\theta}) \\
\min(\boldsymbol{\lambda}, \mathbf{0})
\end{pmatrix} = \mathbf{0}
$$

Here, $\mathbf{F}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\nu}, \boldsymbol{\theta}) = \mathbf{0}$ encapsulates the stationarity, primal feasibility, dual feasibility, and complementary slackness conditions. The symbol $\odot$ represents the element-wise product for the complementary slackness condition. -->
</section>
</section>
<section id="warmstarting-and-predictor-corrector-mpc">
<h3><span class="section-number">9.2.2. </span>Warmstarting and Predictor-Corrector MPC<a class="headerlink" href="#warmstarting-and-predictor-corrector-mpc" title="Link to this heading">#</a></h3>
<p>Another way in which we can speed up NMPC is by providing good initial guesses for the solver. When solving a series of optimization problems along a trajectory, it is likely that the solution to previous problem might be close to that of the current one. Hence, as a heuristic it often makes sense to “warmstart” from the previous solution.</p>
<p>Another alternative is to extrapolate what the next solution ought to be based on the previous one. What we mean here is that rather than simply using the last solution as a guess for that of the current problem, we leverage the “sensitivity information” around the last solution to make a guess about where we might be going. This idea is reminiscent of predictor-corrector schemes which we have briefly discussed in the first chapter.</p>
<p>To implement a predictor corrector MPC scheme, we need to understand how the optimal solution <span class="math notranslate nohighlight">\(\mathbf{x}^*(\boldsymbol{\theta})\)</span> and the value function <span class="math notranslate nohighlight">\(z(\boldsymbol{\theta})\)</span> change as the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> vary. We achieve this by applying the <strong>implicit function theorem</strong> to the <strong>KKT (Karush-Kuhn-Tucker) conditions</strong> of the parametric problem. The KKT conditions for a parametric optimization problem are necessary for optimality and can be written as:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{F}(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\nu}, \boldsymbol{\theta}) = 0,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{F}\)</span> encapsulates the stationarity, primal feasibility, dual feasibility, and complementary slackness conditions from the KKT theorem. By treating <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\nu}\)</span> as functions of the parameters <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, the implicit function theorem guarantees that, under certain regularity conditions, these optimal variables are <strong>continuously differentiable</strong> with respect to <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. This allows us to compute <strong>sensitivity derivatives</strong>, which describe how small changes in <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> affect the optimal solution.</p>
<p>By leveraging this sensitivity information, we can predict changes in the optimal solution and “warm-start” the optimization process at the next time step in MPC. This concept is related to <strong>numerical continuation</strong>, where a complex optimization problem is solved by gradually transforming a simpler, well-understood problem into the more difficult one.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="principle-of-optimality">
<h1><span class="section-number">10. </span>Principle of Optimality<a class="headerlink" href="#principle-of-optimality" title="Link to this heading">#</a></h1>
<p>Unlike the methods we’ve discussed so far, dynamic programming takes a step back and considers not just a single optimization problem, but an entire family of related problems. This approach, while seemingly more complex at first glance, can often lead to efficient solutions.</p>
<p>Dynamic programming leverage the solution structure underlying many control problems that allows for a decomposition it into smaller, more manageable subproblems. Each subproblem is itself an optimization problem, embedded within the larger whole. This recursive structure is the foundation upon which dynamic programming constructs its solutions.</p>
<p>To ground our discussion, let us return to the domain of discrete-time optimal control problems (DOCPs). These problems frequently arise from the discretization of continuous-time optimal control problems. While the focus here will be on deterministic problems, it is worth noting that these concepts extend naturally to stochastic problems by taking the expectation over the random quantities.</p>
<p>Consider a typical DOCP of Bolza type:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{minimize} \quad &amp; J \triangleq c_T(\mathbf{x}_T) + \sum_{t=1}^{T-1} c_t(\mathbf{x}_t, \mathbf{u}_t) \\
\text{subject to} \quad 
&amp; \mathbf{x}_{t+1} = \mathbf{f}_t(\mathbf{x}_t, \mathbf{u}_t), \quad t = 1, \ldots, T-1, \\
&amp; \mathbf{u}_{lb} \leq \mathbf{u}_t \leq \mathbf{u}_{ub}, \quad t = 1, \ldots, T, \\
&amp; \mathbf{x}_{lb} \leq \mathbf{x}_t \leq \mathbf{x}_{ub}, \quad t = 1, \ldots, T, \\
\text{given} \quad &amp; \mathbf{x}_1
\end{align*}
\end{split}\]</div>
<p>Rather than considering only the total cost from the initial time to the final time, dynamic programming introduces the concept of cost from an arbitrary point in time to the end. This leads to the definition of the “cost-to-go” or “value function” <span class="math notranslate nohighlight">\(J_k(\mathbf{x}_k)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
J_k(\mathbf{x}_k) \triangleq c_T(\mathbf{x}_T) + \sum_{t=k}^{T-1} c_t(\mathbf{x}_t, \mathbf{u}_t)
\]</div>
<p>This function represents the total cost incurred from stage <span class="math notranslate nohighlight">\(k\)</span> onwards to the end of the time horizon, given that the system is initialized in state <span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span> at stage <span class="math notranslate nohighlight">\(k\)</span>. Suppose the problem has been solved from stage <span class="math notranslate nohighlight">\(k+1\)</span> to the end, yielding the optimal cost-to-go <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x}_{k+1})\)</span> for any state <span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}\)</span> at stage <span class="math notranslate nohighlight">\(k+1\)</span>. The question then becomes: how does this information inform the decision at stage <span class="math notranslate nohighlight">\(k\)</span>?</p>
<p>Given knowledge of the optimal behavior from <span class="math notranslate nohighlight">\(k+1\)</span> onwards, the task reduces to determining the optimal action <span class="math notranslate nohighlight">\(\mathbf{u}_k\)</span> at stage <span class="math notranslate nohighlight">\(k\)</span>. This control should minimize the sum of the immediate cost <span class="math notranslate nohighlight">\(c_k(\mathbf{x}_k, \mathbf{u}_k)\)</span> and the optimal future cost <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x}_{k+1})\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}\)</span> is the resulting state after applying action <span class="math notranslate nohighlight">\(\mathbf{u}_k\)</span>. Mathematically, this is expressed as:</p>
<div class="math notranslate nohighlight">
\[
J_k^\star(\mathbf{x}_k) = \min_{\mathbf{u}_k} \left[ c_k(\mathbf{x}_k, \mathbf{u}_k) + J_{k+1}^\star(\mathbf{f}_k(\mathbf{x}_k, \mathbf{u}_k)) \right]
\]</div>
<p>This equation is known as Bellman’s equation, named after Richard Bellman, who formulated the principle of optimality:</p>
<blockquote>
<div><p>An optimal policy has the property that whatever the previous state and decision, the remaining decisions must constitute an optimal policy with regard to the state resulting from the previous decision.</p>
</div></blockquote>
<p>In other words, any sub-path of an optimal path, from any intermediate point to the end, must itself be optimal.</p>
<p>Dynamic programming can handle nonlinear systems and non-quadratic cost functions naturally. It provides a global optimal solution, when one exists, and can incorporate state and control constraints with relative ease. Howver, as the dimension of the state space increases, this approach suffers from what Bellman termed the “curse of dimensionality.” The computational complexity and memory requirements grow exponentially with the state dimension, rendering direct application of dynamic programming intractable for high-dimensional problems.</p>
<p>Fortunately, learning-based methods offer efficient tools to combat the curse of dimensionality on two fronts: by using function approximation (e.g., neural networks) to avoid explicit discretization, and by leveraging randomization through Monte Carlo methods inherent in the learning paradigm. Most of this course is dedicated to those ideas.</p>
<section id="backward-recursion">
<h2><span class="section-number">10.1. </span>Backward Recursion<a class="headerlink" href="#backward-recursion" title="Link to this heading">#</a></h2>
<p>The principle of optimality provides a methodology for solving optimal control problems. Beginning at the final time horizon and working backwards, at each stage the local optimization problem given by Bellman’s equation is solved. This process, termed backward recursion or backward induction constructs the optimal value function stage by stage.</p>
<div class="proof algorithm admonition" id="backward-recursion">
<p class="admonition-title"><span class="caption-number">Algorithm 10.1 </span> (Backward Recursion for Dynamic Programming)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Terminal cost function <span class="math notranslate nohighlight">\(c_T(\cdot)\)</span>, stage cost functions <span class="math notranslate nohighlight">\(c_t(\cdot, \cdot)\)</span>, system dynamics <span class="math notranslate nohighlight">\(f_t(\cdot, \cdot)\)</span>, time horizon <span class="math notranslate nohighlight">\(T\)</span></p>
<p><strong>Output:</strong> Optimal value functions <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span> and optimal control policies <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span></p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(J_T^\star(\mathbf{x}) = c_T(\mathbf{x})\)</span> for all <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in the state space</p></li>
<li><p>For <span class="math notranslate nohighlight">\(t = T-1, T-2, \ldots, 1\)</span>:</p>
<ol class="arabic simple">
<li><p>For each state <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in the state space:</p>
<ol class="arabic simple">
<li><p>Compute <span class="math notranslate nohighlight">\(J_t^\star(\mathbf{x}) = \min_{\mathbf{u}} \left[ c_t(\mathbf{x}, \mathbf{u}) + J_{t+1}^\star(f_t(\mathbf{x}, \mathbf{u})) \right]\)</span></p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(\mu_t^\star(\mathbf{x}) = \arg\min_{\mathbf{u}} \left[ c_t(\mathbf{x}, \mathbf{u}) + J_{t+1}^\star(f_t(\mathbf{x}, \mathbf{u})) \right]\)</span></p></li>
</ol>
</li>
<li><p>End For</p></li>
</ol>
</li>
<li><p>End For</p></li>
<li><p>Return <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span>, <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span></p></li>
</ol>
</section>
</div><p>Upon completion of this backward pass, we now have access to the optimal control to take at any stage and in any state. Furthermore, we can simulate optimal trajectories from any initial state and applying the optimal policy at each stage to generate the optimal trajectory.</p>
</section>
<section id="example-optimal-harvest-in-resource-management">
<h2><span class="section-number">10.2. </span>Example: Optimal Harvest in Resource Management<a class="headerlink" href="#example-optimal-harvest-in-resource-management" title="Link to this heading">#</a></h2>
<p>Dynamic programming is often used in resource management and conservation biology to devise policies to be implemented by decision makers and stakeholders : for eg. in fishereries, or timber harvesting. Per <span id="id2">[<a class="reference internal" href="bibliography.html#id22" title="Michael J. Conroy and James T. Peterson. Decision Making in Natural Resource Management: A Structured, Adaptive Approach: A Structured, Adaptive Approach. Wiley, January 2013. ISBN 9781118506196. URL: http://dx.doi.org/10.1002/9781118506196, doi:10.1002/9781118506196.">5</a>]</span>, we consider a population of a particular species, whose abundance we denote by <span class="math notranslate nohighlight">\(x_t\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> represents discrete time steps. Our objective is to maximize the cumulative harvest over a finite time horizon, while also considering the long-term sustainability of the population. This optimization problem can be formulated as:</p>
<div class="math notranslate nohighlight">
\[
\text{maximize} \quad \sum_{t=t_0}^{t_f} F(x_t \cdot h_t) + F_T(x_{t_f})
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(F(\cdot)\)</span> represents the immediate reward function associated with harvesting, <span class="math notranslate nohighlight">\(h_t\)</span> is the harvest rate at time <span class="math notranslate nohighlight">\(t\)</span>, and <span class="math notranslate nohighlight">\(F_T(\cdot)\)</span> denotes a terminal value function that could potentially assign value to the final population state. In this particular problem, we assign no terminal value to the final population state, setting <span class="math notranslate nohighlight">\(F_T(x_{t_f}) = 0\)</span> and allowing us to focus solely on the cumulative harvest over the time horizon.</p>
<p>In our model population model, the abundance of a specicy <span class="math notranslate nohighlight">\(x\)</span> ranges from 1 to 100 individuals. The decision variable is the harvest rate <span class="math notranslate nohighlight">\(h\)</span>, which can take values from the set <span class="math notranslate nohighlight">\(D = \{0, 0.1, 0.2, 0.3, 0.4, 0.5\}\)</span>. The population dynamics are governed by a modified logistic growth model:</p>
<div class="math notranslate nohighlight">
\[
x_{t+1} = x_t + 0.3x_t(1 - x_t/125) - h_tx_t
\]</div>
<p>where the <span class="math notranslate nohighlight">\(0.3\)</span> represents the growth rate and <span class="math notranslate nohighlight">\(125\)</span> is the carrying capacity (the maximum population size given the available resources). The logistic growth model returns continuous values; however our DP formulation uses a discrete state space. Therefore, we also round the the outcomes to the nearest integer.</p>
<p>Applying the principle of optimality, we can express the optimal value function <span class="math notranslate nohighlight">\(J^\star(x_t,t)\)</span> recursively:</p>
<div class="math notranslate nohighlight">
\[
J^\star(x_t, t) = \max_{h_t \in D} (F(x, h, t) + J^*(x_{t+1}, t+1))
\]</div>
<p>with the boundary condition <span class="math notranslate nohighlight">\(J^*(x_{t_f}) = 0\)</span>.</p>
<p>It’s worth noting that while this example uses a relatively simple model, the same principles can be applied to more complex scenarios involving stochasticity, multiple species interactions, or spatial heterogeneity.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Parameters</span>
<span class="n">r_max</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">125</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Number of time steps</span>
<span class="n">N_max</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Maximum population size to consider</span>
<span class="n">h_max</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Maximum harvest rate</span>
<span class="n">h_step</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Step size for harvest rate</span>

<span class="c1"># Create state and decision spaces</span>
<span class="n">N_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">h_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">h_max</span> <span class="o">+</span> <span class="n">h_step</span><span class="p">,</span> <span class="n">h_step</span><span class="p">)</span>

<span class="c1"># Initialize value function and policy</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>

<span class="c1"># Terminal value function (F_T)</span>
<span class="k">def</span> <span class="nf">terminal_value</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">0</span>

<span class="c1"># State return function (F)</span>
<span class="k">def</span> <span class="nf">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># State dynamics function</span>
<span class="k">def</span> <span class="nf">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">+</span> <span class="n">r_max</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">N</span> <span class="o">/</span> <span class="n">K</span><span class="p">)</span> <span class="o">-</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># Backward iteration</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
        <span class="n">max_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">best_h</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">h_space</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure harvest rate doesn&#39;t exceed 100%</span>
                <span class="k">continue</span>

            <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_N</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure population doesn&#39;t go extinct</span>
                <span class="k">continue</span>

            <span class="n">next_N_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">next_N</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_N_index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
                <span class="n">next_N_index</span> <span class="o">-=</span> <span class="mi">1</span>

            <span class="n">value</span> <span class="o">=</span> <span class="n">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">V</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">next_N_index</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">max_value</span><span class="p">:</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">best_h</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>
        <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_h</span>

<span class="c1"># Function to simulate the optimal policy with conversion to Python floats</span>
<span class="k">def</span> <span class="nf">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">initial_N</span><span class="p">)]</span>  <span class="c1"># Ensure first value is a Python float</span>
    <span class="n">harvests</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">N_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">N_index</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
            <span class="n">N_index</span> <span class="o">-=</span> <span class="mi">1</span>

        <span class="n">h</span> <span class="o">=</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">N_index</span><span class="p">]</span>
        <span class="n">harvests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">h</span><span class="p">))</span>  <span class="c1"># Ensure harvest is a Python float</span>

        <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">next_N</span><span class="p">))</span>  <span class="c1"># Ensure next population value is a Python float</span>

    <span class="k">return</span> <span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span>

<span class="c1"># Example usage</span>
<span class="n">initial_N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span> <span class="o">=</span> <span class="n">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal policy:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Population trajectory:&quot;</span><span class="p">,</span> <span class="n">trajectory</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Harvests:&quot;</span><span class="p">,</span> <span class="n">harvests</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total harvest:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">harvests</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal policy:
[[0.2 0.2 0.2 ... 0.4 0.4 0.5]
 [0.2 0.2 0.2 ... 0.4 0.4 0.5]
 [0.2 0.2 0.2 ... 0.4 0.4 0.4]
 ...
 [0.2 0.2 0.2 ... 0.5 0.5 0.5]
 [0.2 0.5 0.5 ... 0.5 0.5 0.5]
 [0.2 0.5 0.5 ... 0.5 0.5 0.5]]

Population trajectory: [50.0, 54.0, 63.2016, 53.614938617856, 62.80047226002128, 65.89520835342945, 62.063500827311884, 65.23169346891407, 61.5424456170318, 64.7610004703774, 61.171531280797, 64.42514256278633, 60.90621923290014, 52.003257133909514, 61.11382126799714, 64.37282756165249, 60.86484408994034, 39.80100508132969, 28.038916051902078, 20.544298889444192, 15.422475391094192]
Harvests: [5.0, 0.0, 18.960480000000004, 0.0, 6.280047226002129, 13.17904167068589, 6.206350082731189, 13.046338693782815, 6.15424456170318, 12.95220009407548, 6.1171531280797, 12.885028512557268, 18.271865769870047, 0.0, 6.111382126799715, 12.874565512330499, 30.43242204497017, 19.900502540664846, 14.019458025951039, 10.272149444722096]
Total harvest: 212.66322943492608
</pre></div>
</div>
</div>
</div>
</section>
<section id="discretization-and-interpolation">
<h2><span class="section-number">10.3. </span>Discretization and Interpolation<a class="headerlink" href="#discretization-and-interpolation" title="Link to this heading">#</a></h2>
<p>In many real-world problems, such as our resource management example, the state space is inherently continuous. However, the dynamic programming algorithm we’ve discussed operates on discrete state spaces. To bridge this gap, we have two main approaches: discretization and interpolation. In the previous example, we used a discretization method by rounding off values to the nearest grid point.</p>
<p>In our idealized models, we imagined population sizes as whole numbers—1 fish, 2 fish, 3 fish—but nature rarely conforms to such simplicity. What do you do when your survey reports 42.7 fish, for example? Without much explanation, our reflex in the previous example was to simply round things off. After all, what’s the harm in calling 42.7 fish just 43? This approach, known as discretization, is the simplest way to handle continuous states. It’s like overlaying a grid on a smooth landscape and only allowing yourself to stand at the intersections. In our demo code, we implemented this step via the <a class="reference external" href="https://numpy.org/doc/2.0/reference/generated/numpy.searchsorted.html">numpy.searchsorted</a> function.</p>
<p>Discretization is straightforward and allows you to apply dynamic programming algorithms directly. For many problems, it might even be sufficient. However, as you might imagine from the various time discretization schemes we’ve encountered in trajectory optimization, we can do better. Specifically, we want to address the following issues:</p>
<ol class="arabic simple">
<li><p>Our model might make abrupt changes in decisions, even when the population barely shifts.</p></li>
<li><p>We’re losing precision, especially when dealing with smaller population sizes where every individual counts.</p></li>
<li><p>We might want to scale up and add more factors to our model—perhaps considering the population’s age structure or environmental variables. However, the curse of dimensionality might leave us needing an impossibly large number of grid points to maintain accuracy.</p></li>
</ol>
<p>Rather than confining ourselves to grid intersections as we did with basic discretization, we can estimate the value between them via interpolation. When you encounter a state that doesn’t exactly match a grid point—like that population of 42.7 fish—you can estimate its value based on nearby points you’ve already calculated. In its simplest form, we could use linear interpolation. Intuitively, it’s like estimating the height of a hill between two surveyed points by drawing a straight line between them. Let’s formalize this approach in the context of the backward induction procedure.</p>
<section id="backward-recursion-with-interpolation">
<h3><span class="section-number">10.3.1. </span>Backward Recursion with Interpolation<a class="headerlink" href="#backward-recursion-with-interpolation" title="Link to this heading">#</a></h3>
<p>In a continuous state space, we don’t have <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x}_{k+1})\)</span> directly available for all possible <span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}\)</span>. Instead, we have <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x})\)</span> for a set of discrete grid points <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}_\text{grid}\)</span>. We use interpolation to estimate <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x}_{k+1})\)</span> for any <span class="math notranslate nohighlight">\(\mathbf{x}_{k+1}\)</span> not in <span class="math notranslate nohighlight">\(\mathcal{X}_\text{grid}\)</span>.</p>
<p>Let’s define an interpolation function <span class="math notranslate nohighlight">\(I_{k+1}(\mathbf{x})\)</span> that estimates <span class="math notranslate nohighlight">\(J_{k+1}^\star(\mathbf{x})\)</span> for any <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> based on the known values at grid points. Then, we can express Bellman’s equation with interpolation as:</p>
<div class="math notranslate nohighlight">
\[
J_k^\star(\mathbf{x}_k) = \min_{\mathbf{u}_k} \left[ c_k(\mathbf{x}_k, \mathbf{u}_k) + I_{k+1}(\mathbf{f}_k(\mathbf{x}_k, \mathbf{u}_k)) \right]
\]</div>
<p>For linear interpolation in a one-dimensional state space, <span class="math notranslate nohighlight">\(I_{k+1}(\mathbf{x})\)</span> would be defined as:</p>
<div class="math notranslate nohighlight">
\[
I_{k+1}(x) = J_{k+1}^\star(x_l) + \frac{x - x_l}{x_u - x_l} \left(J_{k+1}^\star(x_u) - J_{k+1}^\star(x_l)\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_l\)</span> and <span class="math notranslate nohighlight">\(x_u\)</span> are the nearest lower and upper grid points to <span class="math notranslate nohighlight">\(x\)</span>, respectively.</p>
<p>Here’s a pseudo-code algorithm for backward recursion with interpolation:</p>
<div class="proof algorithm admonition" id="backward-recursion-interpolation">
<p class="admonition-title"><span class="caption-number">Algorithm 10.2 </span> (Backward Recursion with Interpolation for Dynamic Programming)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong></p>
<ul class="simple">
<li><p>Terminal cost function <span class="math notranslate nohighlight">\(c_T(\cdot)\)</span></p></li>
<li><p>Stage cost functions <span class="math notranslate nohighlight">\(c_t(\cdot, \cdot)\)</span></p></li>
<li><p>System dynamics <span class="math notranslate nohighlight">\(f_t(\cdot, \cdot)\)</span></p></li>
<li><p>Time horizon <span class="math notranslate nohighlight">\(T\)</span></p></li>
<li><p>Grid of state points <span class="math notranslate nohighlight">\(\mathcal{X}_\text{grid}\)</span></p></li>
<li><p>Set of possible actions <span class="math notranslate nohighlight">\(\mathcal{U}\)</span></p></li>
</ul>
<p><strong>Output:</strong> Optimal value functions <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span> and optimal control policies <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span> at grid points</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(J_T^\star(\mathbf{x}) = c_T(\mathbf{x})\)</span> for all <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}_\text{grid}\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(t = T-1, T-2, \ldots, 1\)</span>:</p>
<ol class="arabic simple">
<li><p>For each state <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{X}_\text{grid}\)</span>:</p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(J_t^\star(\mathbf{x}) = \infty\)</span> and <span class="math notranslate nohighlight">\(\mu_t^\star(\mathbf{x}) = \text{None}\)</span></p></li>
<li><p>For each action <span class="math notranslate nohighlight">\(\mathbf{u} \in \mathcal{U}\)</span>:</p>
<ol class="arabic simple">
<li><p>Compute next state <span class="math notranslate nohighlight">\(\mathbf{x}_\text{next} = f_t(\mathbf{x}, \mathbf{u})\)</span></p></li>
<li><p>Compute interpolated future cost <span class="math notranslate nohighlight">\(J_\text{future} = I_{t+1}(\mathbf{x}_\text{next})\)</span></p></li>
<li><p>Compute total cost <span class="math notranslate nohighlight">\(J_\text{total} = c_t(\mathbf{x}, \mathbf{u}) + J_\text{future}\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(J_\text{total} &lt; J_t^\star(\mathbf{x})\)</span>:</p>
<ol class="arabic simple">
<li><p>Update <span class="math notranslate nohighlight">\(J_t^\star(\mathbf{x}) = J_\text{total}\)</span></p></li>
<li><p>Update <span class="math notranslate nohighlight">\(\mu_t^\star(\mathbf{x}) = \mathbf{u}\)</span></p></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><p>End For</p></li>
</ol>
</li>
<li><p>End For</p></li>
<li><p>Return <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span>, <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span></p></li>
</ol>
</section>
</div></section>
<section id="implementation-considerations">
<h3><span class="section-number">10.3.2. </span>Implementation Considerations<a class="headerlink" href="#implementation-considerations" title="Link to this heading">#</a></h3>
<p>The choice of interpolation method can significantly affect the accuracy of the solution. Linear interpolation is simple and often effective, but higher-order methods like cubic spline interpolation might provide better results in some problems. Furthermore, the layout and density of the grid points in <span class="math notranslate nohighlight">\(\mathcal{X}_\text{grid}\)</span> can impact both the accuracy and computational efficiency. A finer grid generally provides better accuracy but increases computational cost. To balance this tradeoff, you might consider techniques like adaptive grid refinement or function approximation methods instead of fixed grid-based interpolation. Special care may also be needed for states near the boundaries, where interpolation might not be possible in all directions.</p>
<p>While simple to implement, interpolation methods scale poorly in multi-dimensional spaces in terms of computational complexity. Techniques like multilinear interpolation with tensorized representations or more advanced methods like radial basis function interpolation might be necessary.</p>
<p>To better address this computational challenge, we will broaden our perspective through the lens of numerical approximation methods for solving functional operator equations. Polynomial interpolation is a form of approximation, with properties akin to generalization in machine learning. By building these connections, we will develop techniques capable of more robustly handling the curse of dimensionality by leveraging the generalization properties of machine learning models, and the “blessing of randomness” inherent in supervised learning and Monte Carlo methods.</p>
</section>
<section id="example-optimal-harvest-with-linear-interpolation">
<h3><span class="section-number">10.3.3. </span>Example: Optimal Harvest with Linear Interpolation<a class="headerlink" href="#example-optimal-harvest-with-linear-interpolation" title="Link to this heading">#</a></h3>
<p>Here is a demonstration of the backward recursion procedure using linear interpolation.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Parameters</span>
<span class="n">r_max</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">125</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Number of time steps</span>
<span class="n">N_max</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Maximum population size to consider</span>
<span class="n">h_max</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Maximum harvest rate</span>
<span class="n">h_step</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Step size for harvest rate</span>

<span class="c1"># Create state and decision spaces</span>
<span class="n">N_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">h_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">h_max</span> <span class="o">+</span> <span class="n">h_step</span><span class="p">,</span> <span class="n">h_step</span><span class="p">)</span>

<span class="c1"># Initialize value function and policy</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>

<span class="c1"># Terminal value function (F_T)</span>
<span class="k">def</span> <span class="nf">terminal_value</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">0</span>

<span class="c1"># State return function (F)</span>
<span class="k">def</span> <span class="nf">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># State dynamics function</span>
<span class="k">def</span> <span class="nf">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">+</span> <span class="n">r_max</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">N</span> <span class="o">/</span> <span class="n">K</span><span class="p">)</span> <span class="o">-</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># Function to linearly interpolate between grid points in N_space</span>
<span class="k">def</span> <span class="nf">interpolate_value_function</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">N_space</span><span class="p">,</span> <span class="n">next_N</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">next_N</span> <span class="o">&lt;=</span> <span class="n">N_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>  <span class="c1"># Below or at minimum population, return minimum value</span>
    <span class="k">if</span> <span class="n">next_N</span> <span class="o">&gt;=</span> <span class="n">N_space</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Above or at maximum population, return maximum value</span>
    
    <span class="c1"># Find indices to interpolate between</span>
    <span class="n">lower_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">next_N</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">upper_idx</span> <span class="o">=</span> <span class="n">lower_idx</span> <span class="o">+</span> <span class="mi">1</span>
    
    <span class="c1"># Linear interpolation</span>
    <span class="n">N_lower</span> <span class="o">=</span> <span class="n">N_space</span><span class="p">[</span><span class="n">lower_idx</span><span class="p">]</span>
    <span class="n">N_upper</span> <span class="o">=</span> <span class="n">N_space</span><span class="p">[</span><span class="n">upper_idx</span><span class="p">]</span>
    <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">next_N</span> <span class="o">-</span> <span class="n">N_lower</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">N_upper</span> <span class="o">-</span> <span class="n">N_lower</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">lower_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">upper_idx</span><span class="p">]</span>

<span class="c1"># Backward iteration with interpolation</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
        <span class="n">max_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">best_h</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">h_space</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure harvest rate doesn&#39;t exceed 100%</span>
                <span class="k">continue</span>
            
            <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_N</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure population doesn&#39;t go extinct</span>
                <span class="k">continue</span>
            
            <span class="c1"># Interpolate value for next_N</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">interpolate_value_function</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">N_space</span><span class="p">,</span> <span class="n">next_N</span><span class="p">,</span> <span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            
            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">max_value</span><span class="p">:</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">best_h</span> <span class="o">=</span> <span class="n">h</span>
        
        <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>
        <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_h</span>

<span class="c1"># Function to simulate the optimal policy using interpolation</span>
<span class="k">def</span> <span class="nf">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">initial_N</span><span class="p">]</span>
    <span class="n">harvests</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Interpolate optimal harvest rate</span>
        <span class="k">if</span> <span class="n">N</span> <span class="o">&lt;=</span> <span class="n">N_space</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">N</span> <span class="o">&gt;=</span> <span class="n">N_space</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">h</span> <span class="o">=</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lower_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="n">upper_idx</span> <span class="o">=</span> <span class="n">lower_idx</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">N_space</span><span class="p">[</span><span class="n">lower_idx</span><span class="p">])</span> <span class="o">/</span> <span class="p">(</span><span class="n">N_space</span><span class="p">[</span><span class="n">upper_idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">N_space</span><span class="p">[</span><span class="n">lower_idx</span><span class="p">])</span>
            <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">lower_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">upper_idx</span><span class="p">]</span>
        
        <span class="n">harvests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">h</span><span class="p">))</span>  <span class="c1"># Ensure harvest is a Python float</span>
        <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">next_N</span><span class="p">))</span>  <span class="c1"># Ensure next population value is a Python float</span>

    <span class="k">return</span> <span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span>

<span class="c1"># Example usage</span>
<span class="n">initial_N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span> <span class="o">=</span> <span class="n">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal policy:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Population trajectory:&quot;</span><span class="p">,</span> <span class="n">trajectory</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Harvests:&quot;</span><span class="p">,</span> <span class="n">harvests</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total harvest:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">harvests</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal policy:
[[0.  0.  0.  ... 0.4 0.4 0.4]
 [0.  0.  0.  ... 0.4 0.4 0.4]
 [0.  0.  0.  ... 0.4 0.4 0.4]
 ...
 [0.  0.  0.3 ... 0.5 0.5 0.5]
 [0.2 0.5 0.5 ... 0.5 0.5 0.5]
 [0.2 0.5 0.5 ... 0.5 0.5 0.5]]

Population trajectory: [50, 59.0, 62.445600000000006, 62.793456961535966, 60.906514028106535, 64.1847685511936, 60.71600257278426, 64.0117639631371, 60.5789261378371, 63.88717626457206, 60.48012279248407, 63.79731874379539, 60.40881570882111, 63.73243881376377, 60.3573056779798, 63.685556376683536, 60.32007179593332, 39.523630889226936, 27.8698229545787, 20.431713488016012, 15.34347899187751]
Harvests: [0.0, 5.9, 9.027135936000038, 11.26173625265758, 6.0906514028106535, 12.83695371023872, 6.071600257278426, 12.80235279262742, 6.057892613783711, 12.777435252914414, 6.0480122792484075, 12.759463748759078, 6.040881570882111, 12.746487762752755, 6.03573056779798, 12.737111275336709, 30.16003589796666, 19.761815444613468, 13.93491147728935, 10.215856744008006]
Total harvest: 213.26606498696546
</pre></div>
</div>
</div>
</div>
<p>Due to pedagogical considerations, this example is using our own implementation of the linear interpolation procedure. However, a more general and practical approach would be to use a built-in interpolation procedure in Numpy. Because our state space has a single dimension, we can simply use <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.interp1d.">scipy.interpolate.interp1d</a> which offers various interpolation methods through its <code class="docutils literal notranslate"><span class="pre">kind</span></code> argument, which can take values in ‘linear’, ‘nearest’, ‘nearest-up’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘previous’, or ‘next’. ‘zero’, ‘slinear’, ‘quadratic’ and ‘cubic’.</p>
<p>Here’s a more general implementation which here uses cubic interpolation through the <code class="docutils literal notranslate"><span class="pre">scipy.interpolate.interp1d</span></code> function:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">interp1d</span>

<span class="c1"># Parameters</span>
<span class="n">r_max</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">125</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># Number of time steps</span>
<span class="n">N_max</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Maximum population size to consider</span>
<span class="n">h_max</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Maximum harvest rate</span>
<span class="n">h_step</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Step size for harvest rate</span>

<span class="c1"># Create state and decision spaces</span>
<span class="n">N_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_max</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">h_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">h_max</span> <span class="o">+</span> <span class="n">h_step</span><span class="p">,</span> <span class="n">h_step</span><span class="p">)</span>

<span class="c1"># Initialize value function and policy</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>

<span class="c1"># Terminal value function (F_T)</span>
<span class="k">def</span> <span class="nf">terminal_value</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">0</span>

<span class="c1"># State return function (F)</span>
<span class="k">def</span> <span class="nf">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># State dynamics function</span>
<span class="k">def</span> <span class="nf">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">+</span> <span class="n">r_max</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">N</span> <span class="o">/</span> <span class="n">K</span><span class="p">)</span> <span class="o">-</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># Function to create interpolation function for a given time step</span>
<span class="k">def</span> <span class="nf">create_interpolator</span><span class="p">(</span><span class="n">V_t</span><span class="p">,</span> <span class="n">N_space</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">interp1d</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">V_t</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;cubic&#39;</span><span class="p">,</span> <span class="n">bounds_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="p">(</span><span class="n">V_t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">V_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Backward iteration with interpolation</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">interpolator</span> <span class="o">=</span> <span class="n">create_interpolator</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">N_space</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
        <span class="n">max_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">best_h</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">h_space</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure harvest rate doesn&#39;t exceed 100%</span>
                <span class="k">continue</span>

            <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">next_N</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure population doesn&#39;t go extinct</span>
                <span class="k">continue</span>

            <span class="c1"># Use interpolation to get the value for next_N</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">interpolator</span><span class="p">(</span><span class="n">next_N</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">max_value</span><span class="p">:</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">value</span>
                <span class="n">best_h</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>
        <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_h</span>

<span class="c1"># Function to simulate the optimal policy using interpolation</span>
<span class="k">def</span> <span class="nf">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">):</span>
    <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">initial_N</span><span class="p">]</span>
    <span class="n">harvests</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Create interpolator for the policy at time t</span>
        <span class="n">policy_interpolator</span> <span class="o">=</span> <span class="n">interp1d</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;cubic&#39;</span><span class="p">,</span> <span class="n">bounds_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="p">(</span><span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
        
        <span class="n">h</span> <span class="o">=</span> <span class="n">policy_interpolator</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
        <span class="n">harvests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">h</span><span class="p">))</span>  <span class="c1"># Ensure harvest is a Python float</span>

        <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">next_N</span><span class="p">))</span>  <span class="c1"># Ensure next population value is a Python float</span>

    <span class="k">return</span> <span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span>

<span class="c1"># Example usage</span>
<span class="n">initial_N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">trajectory</span><span class="p">,</span> <span class="n">harvests</span> <span class="o">=</span> <span class="n">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal policy (first few rows):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Population trajectory:&quot;</span><span class="p">,</span> <span class="n">trajectory</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Harvests:&quot;</span><span class="p">,</span> <span class="n">harvests</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total harvest:&quot;</span><span class="p">,</span> <span class="nb">sum</span><span class="p">(</span><span class="n">harvests</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal policy (first few rows):
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]]

Population trajectory: [50, 59.0, 62.445600000000006, 62.855816819468515, 66.38501069094303, 62.46338144008508, 66.19082983826176, 62.307060290079974, 65.86630883298251, 62.0275406161329, 65.08602250342238, 61.40579635061663, 65.16431296091169, 61.453283417050585, 65.25607512917723, 61.51516182245857, 65.36153916789908, 42.03585710472635, 29.38785380571154, 21.43753276143513, 16.047063462998068]
Harvests: [0.0, 5.9, 8.96477607806749, 5.84550227506383, 13.260405311492969, 5.6475483836178855, 13.226076208433781, 5.815662115341462, 13.18657133246797, 6.315982389823951, 13.03917612307405, 5.613609913801769, 13.068992991332266, 5.569578810421299, 13.097683026436252, 5.526294879593221, 32.68102988779013, 21.017928552363177, 14.693926902855774, 10.718766380713346]
Total harvest: 213.18951156269057
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="linear-quadratic-regulator-via-dynamic-programming">
<h2><span class="section-number">10.4. </span>Linear Quadratic Regulator via Dynamic Programming<a class="headerlink" href="#linear-quadratic-regulator-via-dynamic-programming" title="Link to this heading">#</a></h2>
<p>Let us now consider a special case of our dynamic programming formulation: the discrete-time Linear Quadratic Regulator (LQR) problem. This example will illustrate how the structure of linear dynamics and quadratic costs leads to a particularly elegant form of the backward recursion.</p>
<p>Consider a linear time-invariant system with dynamics:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{t+1} = A\mathbf{x}_t + B\mathbf{u}_t
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_t \in \mathbb{R}^n\)</span> is the state and <span class="math notranslate nohighlight">\(\mathbf{u}_t \in \mathbb{R}^m\)</span> is the control input.<br />
The cost function to be minimized is quadratic:</p>
<div class="math notranslate nohighlight">
\[
J = \frac{1}{2}\mathbf{x}_T^\top S_T \mathbf{x}_T + \frac{1}{2}\sum_{t=0}^{T-1} \left(\mathbf{x}_t^\top Q \mathbf{x}_t + \mathbf{u}_t^\top R \mathbf{u}_t\right)
\]</div>
<p>where <span class="math notranslate nohighlight">\(S_T \geq 0\)</span>, <span class="math notranslate nohighlight">\(Q \geq 0\)</span>, and <span class="math notranslate nohighlight">\(R &gt; 0\)</span> are symmetric matrices of appropriate dimensions.<br />
Our goal is to find the optimal control sequence <span class="math notranslate nohighlight">\(\mathbf{u}_t^*\)</span> that minimizes <span class="math notranslate nohighlight">\(J\)</span> over a fixed time horizon <span class="math notranslate nohighlight">\([0, T]\)</span>, given an initial state <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>.</p>
<p>Let’s apply the principle of optimality to derive the backward recursion for this problem. We’ll start at the final time step and work our way backward.</p>
<p>At <span class="math notranslate nohighlight">\(t = T\)</span>, the terminal cost is given by:</p>
<div class="math notranslate nohighlight">
\[
J_T^*(\mathbf{x}_T) = \frac{1}{2}\mathbf{x}_T^\top S_T \mathbf{x}_T
\]</div>
<p>At <span class="math notranslate nohighlight">\(t = T-1\)</span>, the cost-to-go is:</p>
<div class="math notranslate nohighlight">
\[
J_{T-1}(\mathbf{x}_{T-1}, \mathbf{u}_{T-1}) = \frac{1}{2}\mathbf{x}_{T-1}^\top Q \mathbf{x}_{T-1} + \frac{1}{2}\mathbf{u}_{T-1}^\top R \mathbf{u}_{T-1} + J_T^*(\mathbf{x}_T)
\]</div>
<p>Substituting the dynamics equation:</p>
<div class="math notranslate nohighlight">
\[
J_{T-1} = \frac{1}{2}\mathbf{x}_{T-1}^\top Q \mathbf{x}_{T-1} + \frac{1}{2}\mathbf{u}_{T-1}^\top R \mathbf{u}_{T-1} + \frac{1}{2}(A\mathbf{x}_{T-1} + B\mathbf{u}_{T-1})^\top S_T (A\mathbf{x}_{T-1} + B\mathbf{u}_{T-1})
\]</div>
<p>To find the optimal control, we differentiate with respect to <span class="math notranslate nohighlight">\(\mathbf{u}_{T-1}\)</span> and set it to zero:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial J_{T-1}}{\partial \mathbf{u}_{T-1}} = R\mathbf{u}_{T-1} + B^\top S_T (A\mathbf{x}_{T-1} + B\mathbf{u}_{T-1}) = 0
\]</div>
<p>Solving for <span class="math notranslate nohighlight">\(\mathbf{u}_{T-1}^*\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{u}_{T-1}^* = -(R + B^\top S_T B)^{-1}B^\top S_T A\mathbf{x}_{T-1}
\]</div>
<p>We can define the gain matrix:</p>
<div class="math notranslate nohighlight">
\[
K_{T-1} = (R + B^\top S_T B)^{-1}B^\top S_T A
\]</div>
<p>So that <span class="math notranslate nohighlight">\(\mathbf{u}_{T-1}^* = -K_{T-1}\mathbf{x}_{T-1}\)</span>. The optimal cost-to-go at <span class="math notranslate nohighlight">\(T-1\)</span> is then:</p>
<div class="math notranslate nohighlight">
\[
J_{T-1}^*(\mathbf{x}_{T-1}) = \frac{1}{2}\mathbf{x}_{T-1}^\top S_{T-1} \mathbf{x}_{T-1}
\]</div>
<p>Where <span class="math notranslate nohighlight">\(S_{T-1}\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
S_{T-1} = Q + A^\top S_T A - A^\top S_T B(R + B^\top S_T B)^{-1}B^\top S_T A
\]</div>
<p>Continuing this process backward in time, we find that for any <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{u}_t^* = -K_t\mathbf{x}_t
\]</div>
<p>Where:</p>
<div class="math notranslate nohighlight">
\[
K_t = (R + B^\top S_{t+1} B)^{-1}B^\top S_{t+1} A
\]</div>
<p>And the optimal cost-to-go is:</p>
<div class="math notranslate nohighlight">
\[
J_t^*(\mathbf{x}_t) = \frac{1}{2}\mathbf{x}_t^\top S_t \mathbf{x}_t
\]</div>
<p>Where <span class="math notranslate nohighlight">\(S_t\)</span> satisfies the so-called discrete-time Riccati equation:</p>
<div class="math notranslate nohighlight">
\[
S_t = Q + A^\top S_{t+1} A - A^\top S_{t+1} B(R + B^\top S_{t+1} B)^{-1}B^\top S_{t+1} A
\]</div>
<!-- 
### Example: Linear Quadratic Regulation of a Liquid Tank 

We are dealing with a liquid-level control system for a storage tank. This system consists of a reservoir connected to a tank via valves. These valves are controlled by a gear train, which is driven by a DC motor. The motor, in turn, is controlled by an electronic amplifier. The goal is to maintain a constant liquid level in the tank, adjusting only when necessary.

The system is described by a third-order continuous-time model with the following state variables:
- $x_1(t)$: the height of the liquid in the tank
- $x_2(t)$: the angular position of the electric motor driving the valves
- $x_3(t)$: the angular velocity of the motor

The input to the system, $u(t)$, represents the signal sent to the electronic amplifier connected to the motor.
The system dynamics are described by the following differential equations:

$$
\begin{aligned}
& \dot{x}_1(t) = -2x_1(t) \\
& \dot{x}_2(t) = x_3(t) \\
& \dot{x}_3(t) = -10x_3(t) + 9000u(t)
\end{aligned}
$$

To pose this as a discrete-time LQR problem, we need to discretize the continuous-time system. Let's assume a sampling time of $T_s$ seconds. We can use the forward Euler method for a simple discretization:

$$
\begin{aligned}
& x_1(k+1) = x_1(k) + T_s(-2x_1(k)) \\
& x_2(k+1) = x_2(k) + T_sx_3(k) \\
& x_3(k+1) = x_3(k) + T_s(-10x_3(k) + 9000u(k))
\end{aligned}
$$

This can be written in the standard discrete-time state-space form:

$x(k+1) = Ax(k) + Bu(k)$

Where:

$x(k) = \begin{bmatrix} x_1(k) \\ x_2(k) \\ x_3(k) \end{bmatrix}$

$A = \begin{bmatrix} 
1-2T_s & 0 & 0 \\
0 & 1 & T_s \\
0 & 0 & 1-10T_s
\end{bmatrix}$

$B = \begin{bmatrix} 
0 \\
0 \\
9000T_s
\end{bmatrix}$

The goal of our LQR controller is to maintain the liquid level at a desired reference value while minimizing control effort. We can formulate this as a discrete-time LQR problem with the following cost function:

$J = \sum_{k=0}^{\infty} \left( (x_1(k) - x_{1,ref})^2 + ru^2(k) \right)$

Where $x_{1,ref}$ is the reference liquid level and $r$ is a positive weight on the control input.

To put this in standard discrete-time LQR form, we rewrite the cost function as:

$J = \sum_{k=0}^{\infty} \left( x^T(k)Qx(k) + ru^2(k) \right)$

Where:

$Q = \begin{bmatrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}$

The discrete-time LQR problem is now to find the optimal control law $u^*(k) = -Kx(k)$ that minimizes this cost function, subject to the discrete-time system dynamics $x(k+1) = Ax(k) + Bu(k)$.

The solution involves solving the discrete-time algebraic Riccati equation:

$P = A^TPA - A^TPB(B^TPB + R)^{-1}B^TPA + Q$

Where $R = r$ (a scalar in this case), to find the positive definite matrix $P$. Then, the optimal gain matrix $K$ is given by:

$K = (B^TPB + R)^{-1}B^TPA$

This formulation ensures that:
1. The liquid level ($x_1(k)$) is maintained close to the reference value.
2. The system acts primarily when there's a change in the liquid level, as only $x_1(k)$ is directly penalized in the cost function.
3. The control effort is minimized, ensuring smooth operation of the valves.

By tuning the weight $r$ and the sampling time $T_s$, we can balance the trade-off between maintaining the desired liquid level, the amount of control effort used, and the responsiveness of the system. -->
</section>
<section id="stochastic-dynamic-programming">
<h2><span class="section-number">10.5. </span>Stochastic Dynamic Programming<a class="headerlink" href="#stochastic-dynamic-programming" title="Link to this heading">#</a></h2>
<p>While our previous discussion centered on deterministic systems, many real-world problems involve uncertainty. Stochastic Dynamic Programming (SDP) extends our framework to handle stochasticity in both the objective function and system dynamics.</p>
<p>In the stochastic setting, our system evolution takes the form:</p>
<div class="math notranslate nohighlight">
\[ \mathbf{x}_{t+1} = \mathbf{f}_t(\mathbf{x}_t, \mathbf{u}_t, \mathbf{w}_t) \]</div>
<p>Here, <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span> represents a random disturbance or noise term at time <span class="math notranslate nohighlight">\(t\)</span> due to the inherent uncertainty in the system’s behavior. The stage cost function may also incorporate stochastic influences:</p>
<div class="math notranslate nohighlight">
\[ c_t(\mathbf{x}_t, \mathbf{u}_t, \mathbf{w}_t) \]</div>
<p>In this context, our objective shifts from minimizing a deterministic cost to minimizing the expected total cost:</p>
<div class="math notranslate nohighlight">
\[ \mathbb{E}\left[c_T(\mathbf{x}_T) + \sum_{t=1}^{T-1} c_t(\mathbf{x}_t, \mathbf{u}_t, \mathbf{w}_t)\right] \]</div>
<p>where the expectation is taken over the distributions of the random variables <span class="math notranslate nohighlight">\(\mathbf{w}_t\)</span>. The principle of optimality still holds in the stochastic case, but Bellman’s optimality equation now involves an expectation:</p>
<div class="math notranslate nohighlight">
\[ J_k^\star(\mathbf{x}_k) = \min_{\mathbf{u}_k} \mathbb{E}_{\mathbf{w}_k}\left[c_k(\mathbf{x}_k, \mathbf{u}_k, \mathbf{w}_k) + J_{k+1}^\star(\mathbf{f}_k(\mathbf{x}_k, \mathbf{u}_k, \mathbf{w}_k))\right] \]</div>
<p>In practice, this expectation is often computed by discretizing the distribution of <span class="math notranslate nohighlight">\(\mathbf{w}_k\)</span> when the set of possible disturbances is very large or even continuous. Let’s say we approximate the distribution with <span class="math notranslate nohighlight">\(K\)</span> discrete values <span class="math notranslate nohighlight">\(\mathbf{w}_k^i\)</span>, each occurring with probability <span class="math notranslate nohighlight">\(p_k^i\)</span>. Then our Bellman equation becomes:</p>
<div class="math notranslate nohighlight">
\[ J_k^\star(\mathbf{x}_k) = \min_{\mathbf{u}_k} \sum_{i=1}^K p_k^i \left(c_k(\mathbf{x}_k, \mathbf{u}_k, \mathbf{w}_k^i) + J_{k+1}^\star(\mathbf{f}_k(\mathbf{x}_k, \mathbf{u}_k, \mathbf{w}_k^i))\right) \]</div>
<p>The backward recursion algorithm for SDP follows a similar structure to its deterministic counterpart, with the key difference being that we now have to compute expected values:</p>
<div class="proof algorithm admonition" id="stochastic-backward-recursion">
<p class="admonition-title"><span class="caption-number">Algorithm 10.3 </span> (Backward Recursion for Stochastic Dynamic Programming)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Terminal cost function <span class="math notranslate nohighlight">\(c_T(\cdot)\)</span>, stage cost functions <span class="math notranslate nohighlight">\(c_t(\cdot, \cdot, \cdot)\)</span>, system dynamics <span class="math notranslate nohighlight">\(\mathbf{f}_t(\cdot, \cdot, \cdot)\)</span>, time horizon <span class="math notranslate nohighlight">\(T\)</span>, disturbance distributions</p>
<p><strong>Output:</strong> Optimal value functions <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span> and optimal control policies <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span></p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(J_T^\star(\mathbf{x}) = c_T(\mathbf{x})\)</span> for all <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in the state space</p></li>
<li><p>For <span class="math notranslate nohighlight">\(t = T-1, T-2, \ldots, 1\)</span>:</p>
<ol class="arabic simple">
<li><p>For each state <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> in the state space:</p>
<ol class="arabic simple">
<li><p>Compute <span class="math notranslate nohighlight">\(J_t^\star(\mathbf{x}) = \min_{\mathbf{u}} \mathbb{E}_{\mathbf{w}_t}\left[c_t(\mathbf{x}, \mathbf{u}, \mathbf{w}_t) + J_{t+1}^\star(\mathbf{f}_t(\mathbf{x}, \mathbf{u}, \mathbf{w}_t))\right]\)</span></p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(\mu_t^\star(\mathbf{x}) = \arg\min_{\mathbf{u}} \mathbb{E}_{\mathbf{w}_t}\left[c_t(\mathbf{x}, \mathbf{u}, \mathbf{w}_t) + J_{t+1}^\star(\mathbf{f}_t(\mathbf{x}, \mathbf{u}, \mathbf{w}_t))\right]\)</span></p></li>
</ol>
</li>
<li><p>End For</p></li>
</ol>
</li>
<li><p>End For</p></li>
<li><p>Return <span class="math notranslate nohighlight">\(J_t^\star(\cdot)\)</span>, <span class="math notranslate nohighlight">\(\mu_t^\star(\cdot)\)</span> for <span class="math notranslate nohighlight">\(t = 1, \ldots, T\)</span></p></li>
</ol>
</section>
</div><p>While SDP provides us with a framework to for handling uncertainty, it makes the curse of dimensionality even more difficult to handle in practice. Not only does the state space need to be discretized, but now the disturbance space must be discretized as well. This can lead to a combinatorial explosion in the number of scenarios to be evaluated at each stage.</p>
<p>However, just as we tackled the challenges of continuous state spaces with discretization and interpolation, we can devise efficient methods to handle the additional complexity of evaluating expectations. This problem essentially becomes one of numerical integration. When the set of disturbances is continuous (as is often the case with continuous state spaces), we enter a domain where numerical quadrature methods could be applied. But these methods tend to scale poorly as the number of dimensions grows. This is where more efficient techniques, often rooted in Monte Carlo methods, come into play. The combination of two key ingredients emerges to tackle the curse of dimensionality:</p>
<ol class="arabic simple">
<li><p>Function approximation (through discretization, interpolation, neural networks, etc.)</p></li>
<li><p>Monte Carlo integration (simulation)</p></li>
</ol>
<p>These two elements essentially distill the key ingredients of machine learning, which is the direction we’ll be exploring in this course.</p>
<section id="example-stochastic-optimal-harvest-in-resource-management">
<h3><span class="section-number">10.5.1. </span>Example: Stochastic Optimal Harvest in Resource Management<a class="headerlink" href="#example-stochastic-optimal-harvest-in-resource-management" title="Link to this heading">#</a></h3>
<p>Building upon our previous deterministic model, we now introduce stochasticity to more accurately reflect the uncertainties inherent in real-world resource management scenarios <span id="id3">[<a class="reference internal" href="bibliography.html#id22" title="Michael J. Conroy and James T. Peterson. Decision Making in Natural Resource Management: A Structured, Adaptive Approach: A Structured, Adaptive Approach. Wiley, January 2013. ISBN 9781118506196. URL: http://dx.doi.org/10.1002/9781118506196, doi:10.1002/9781118506196.">5</a>]</span>. As before, we consider a population of a particular species, whose abundance we denote by <span class="math notranslate nohighlight">\(x_t\)</span>, where <span class="math notranslate nohighlight">\(t\)</span> represents discrete time steps. Our objective remains to maximize the cumulative harvest over a finite time horizon, while also considering the long-term sustainability of the population. However, we now account for two sources of stochasticity: partial controllability of harvest and environmental variability affecting growth rates.
The optimization problem can be formulated as:</p>
<div class="math notranslate nohighlight">
\[
\text{maximize} \quad \mathbb{E}\left[\sum_{t=t_0}^{t_f} F(x_t \cdot h_t)\right]
\]</div>
<p>Here, <span class="math notranslate nohighlight">\(F(\cdot)\)</span> represents the immediate reward function associated with harvesting, and <span class="math notranslate nohighlight">\(h_t\)</span> is the realized harvest rate at time <span class="math notranslate nohighlight">\(t\)</span>. The expectation <span class="math notranslate nohighlight">\(\mathbb{E}[\cdot]\)</span> over both harvest and growth rates, which we view as random variables.
In our stochastic model, the abundance <span class="math notranslate nohighlight">\(x\)</span> still ranges from 1 to 100 individuals. The decision variable is now the desired harvest rate <span class="math notranslate nohighlight">\(d_t\)</span>, which can take values from the set <span class="math notranslate nohighlight">\(D = {0, 0.1, 0.2, 0.3, 0.4, 0.5}\)</span>. However, the realized harvest rate <span class="math notranslate nohighlight">\(h_t\)</span> is stochastic and follows a discrete distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
h_t = \begin{cases}
0.75d_t &amp; \text{with probability } 0.25 \\
d_t &amp; \text{with probability } 0.5 \\
1.25d_t &amp; \text{with probability } 0.25
\end{cases}
\end{split}\]</div>
<p>By expressing the harvest rate as a random variable, we mean to capture the fact that harvesting is a not completely under our control: we might obtain more or less what we had intended to. Furthermore, we generalize the population dynamics to the stochastic cse via:
$$</p>
<p>x_{t+1} = x_t + r_tx_t(1 - x_t/K) - h_tx_t
$$</p>
<p>where <span class="math notranslate nohighlight">\(K = 125\)</span> is the carrying capacity. The growth rate <span class="math notranslate nohighlight">\(r_t\)</span> is now stochastic and follows a discrete distribution:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
r_t = \begin{cases}
0.85r_{\text{max}} &amp; \text{with probability } 0.25 \\
1.05r_{\text{max}} &amp; \text{with probability } 0.5 \\
1.15r_{\text{max}} &amp; \text{with probability } 0.25
\end{cases}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(r_{\text{max}} = 0.3\)</span> is the maximum growth rate.
Applying the principle of optimality, we can express the optimal value function <span class="math notranslate nohighlight">\(J^\star(x_t, t)\)</span> recursively:</p>
<div class="math notranslate nohighlight">
\[
J^\star(x_t, t) = \max_{d(t) \in D} \mathbb{E}\left[F(x_t \cdot h_t) + J^\star(x_{t+1}, t+1)\right]
\]</div>
<p>where the expectation is taken over the harvest and growth rate random variables. The boundary condition remains <span class="math notranslate nohighlight">\(J^*(x_{t_f}) = 0\)</span>. We can now adapt our previous code to account for the stochasticity in our model. One important difference is that simulating a solution in this context requires multiple realizations of our process. This is an important consideration when evaluating reinforcement learning methods in practice, as success cannot be claimed based on a single successful trajectory.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.interpolate</span> <span class="kn">import</span> <span class="n">interp1d</span>

<span class="c1"># Parameters</span>
<span class="n">r_max</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">125</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">30</span>  <span class="c1"># Number of time steps</span>
<span class="n">N_max</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Maximum population size to consider</span>
<span class="n">h_max</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Maximum harvest rate</span>
<span class="n">h_step</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Step size for harvest rate</span>

<span class="c1"># Create state and decision spaces</span>
<span class="n">N_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">N_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># Using more granular state space</span>
<span class="n">h_space</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">h_max</span> <span class="o">+</span> <span class="n">h_step</span><span class="p">,</span> <span class="n">h_step</span><span class="p">)</span>

<span class="c1"># Stochastic parameters</span>
<span class="n">h_outcomes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.75</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.25</span><span class="p">])</span>
<span class="n">h_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>
<span class="n">r_outcomes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">1.15</span><span class="p">])</span> <span class="o">*</span> <span class="n">r_max</span>
<span class="n">r_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">])</span>

<span class="c1"># Initialize value function and policy</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>
<span class="n">policy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">T</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_space</span><span class="p">)))</span>

<span class="c1"># State return function (F)</span>
<span class="k">def</span> <span class="nf">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">*</span> <span class="n">h</span>

<span class="c1"># State dynamics function (stochastic)</span>
<span class="k">def</span> <span class="nf">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">N</span> <span class="o">+</span> <span class="n">r</span> <span class="o">*</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">N</span> <span class="o">/</span> <span class="n">K</span><span class="p">)</span> <span class="o">-</span> <span class="n">h</span> <span class="o">*</span> <span class="n">N</span>

<span class="c1"># Function to create interpolation function for a given time step</span>
<span class="k">def</span> <span class="nf">create_interpolator</span><span class="p">(</span><span class="n">V_t</span><span class="p">,</span> <span class="n">N_space</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">interp1d</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">V_t</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">bounds_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="p">(</span><span class="n">V_t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">V_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Backward iteration with stochastic dynamics</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">interpolator</span> <span class="o">=</span> <span class="n">create_interpolator</span><span class="p">(</span><span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">N_space</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">N_space</span><span class="p">):</span>
        <span class="n">max_value</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
        <span class="n">best_h</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">h_space</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">h</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure harvest rate doesn&#39;t exceed 100%</span>
                <span class="k">continue</span>

            <span class="n">expected_value</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">h_factor</span><span class="p">,</span> <span class="n">h_prob</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">h_outcomes</span><span class="p">,</span> <span class="n">h_probs</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">r_factor</span><span class="p">,</span> <span class="n">r_prob</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">r_outcomes</span><span class="p">,</span> <span class="n">r_probs</span><span class="p">):</span>
                    <span class="n">realized_h</span> <span class="o">=</span> <span class="n">h</span> <span class="o">*</span> <span class="n">h_factor</span>
                    <span class="n">realized_r</span> <span class="o">=</span> <span class="n">r_factor</span>

                    <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">realized_h</span><span class="p">,</span> <span class="n">realized_r</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">next_N</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Ensure population doesn&#39;t go extinct</span>
                        <span class="k">continue</span>

                    <span class="c1"># Use interpolation to get the value for next_N</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">state_return</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">realized_h</span><span class="p">)</span> <span class="o">+</span> <span class="n">interpolator</span><span class="p">(</span><span class="n">next_N</span><span class="p">)</span>
                    <span class="n">expected_value</span> <span class="o">+=</span> <span class="n">value</span> <span class="o">*</span> <span class="n">h_prob</span> <span class="o">*</span> <span class="n">r_prob</span>

            <span class="k">if</span> <span class="n">expected_value</span> <span class="o">&gt;</span> <span class="n">max_value</span><span class="p">:</span>
                <span class="n">max_value</span> <span class="o">=</span> <span class="n">expected_value</span>
                <span class="n">best_h</span> <span class="o">=</span> <span class="n">h</span>

        <span class="n">V</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>
        <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_h</span>

<span class="c1"># Function to simulate the optimal policy using interpolation (stochastic version)</span>
<span class="k">def</span> <span class="nf">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">num_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">all_trajectories</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_harvests</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_simulations</span><span class="p">):</span>
        <span class="n">trajectory</span> <span class="o">=</span> <span class="p">[</span><span class="n">initial_N</span><span class="p">]</span>
        <span class="n">harvests</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">N</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            
            <span class="c1"># Create interpolator for the policy at time t</span>
            <span class="n">policy_interpolator</span> <span class="o">=</span> <span class="n">interp1d</span><span class="p">(</span><span class="n">N_space</span><span class="p">,</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">],</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">bounds_error</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="p">(</span><span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">policy</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            
            <span class="n">intended_h</span> <span class="o">=</span> <span class="n">policy_interpolator</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
            
            <span class="c1"># Apply stochasticity</span>
            <span class="n">h_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">h_outcomes</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">h_probs</span><span class="p">)</span>
            <span class="n">r_factor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">r_outcomes</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">r_probs</span><span class="p">)</span>
            
            <span class="n">realized_h</span> <span class="o">=</span> <span class="n">intended_h</span> <span class="o">*</span> <span class="n">h_factor</span>
            <span class="n">harvests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">realized_h</span><span class="p">)</span>

            <span class="n">next_N</span> <span class="o">=</span> <span class="n">state_dynamics</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">realized_h</span><span class="p">,</span> <span class="n">r_factor</span><span class="p">)</span>
            <span class="n">trajectory</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">next_N</span><span class="p">)</span>

        <span class="n">all_trajectories</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)</span>
        <span class="n">all_harvests</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">harvests</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">all_trajectories</span><span class="p">,</span> <span class="n">all_harvests</span>

<span class="c1"># Example usage</span>
<span class="n">initial_N</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">trajectories</span><span class="p">,</span> <span class="n">harvests</span> <span class="o">=</span> <span class="n">simulate_optimal_policy</span><span class="p">(</span><span class="n">initial_N</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>

<span class="c1"># Calculate average trajectory and total harvest</span>
<span class="n">avg_trajectory</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trajectories</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">avg_total_harvest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="nb">sum</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">harvests</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimal policy (first few rows):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">policy</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Average population trajectory:&quot;</span><span class="p">,</span> <span class="n">avg_trajectory</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average total harvest:&quot;</span><span class="p">,</span> <span class="n">avg_total_harvest</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="k">for</span> <span class="n">traj</span> <span class="ow">in</span> <span class="n">trajectories</span><span class="p">[:</span><span class="mi">20</span><span class="p">]:</span>  <span class="c1"># Plot first 20 trajectories</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">traj</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">avg_trajectory</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Population Trajectories&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Population&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="nb">sum</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">harvests</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Total Harvest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Total Harvest&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal policy (first few rows):
[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.3
  0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.4 0.4 0.4 0.4 0.4 0.4
  0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4 0.4]]

Average population trajectory: [50.         59.405      62.98363587 62.46003152 62.06238131 62.69509383
 62.12494089 62.63725285 62.96663568 62.49220899 61.88597304 62.85710115
 62.4073812  62.33265867 62.19850817 62.58449157 62.55476511 62.89791289
 62.47409527 62.83165982 62.70214137 62.41783757 62.68903339 62.39201789
 62.32204191 62.46491239 62.09650418 42.11709868 29.62962458 21.5278193
 16.37380103]
Average total harvest: 312.46374840448823
</pre></div>
</div>
<img alt="_images/0f374d7bfaf99dae13410512d6c22c8e305cb6872817c8bef9b42415436ea04d.png" src="_images/0f374d7bfaf99dae13410512d6c22c8e305cb6872817c8bef9b42415436ea04d.png" />
</div>
</div>
</section>
<section id="markov-decision-process-formulation">
<h3><span class="section-number">10.5.2. </span>Markov Decision Process Formulation<a class="headerlink" href="#markov-decision-process-formulation" title="Link to this heading">#</a></h3>
<p>Rather than expressing the stochasticity in our system through a disturbance term as a parameter to a deterministic difference equation, we often work with an alternative representation (more common in operations research) which uses the Markov Decision Process formulation. The idea is that when we model our system in this way with the disturbance term being drawn indepently of the previous stages, the induced trajectory are those of a Markov chain. Hence, we can re-cast our control problem in that language, leading to the so-called Markov Decision Process framework in which we express the system dynamics in terms of transition probabilities rather than explicit state equations. In this framework, we express the probability that the system is in a given state using the transition probability function:</p>
<div class="math notranslate nohighlight">
\[ p_t(\mathbf{x}_{t+1} | \mathbf{x}_t, \mathbf{u}_t) \]</div>
<p>This function gives the probability of transitioning to state <span class="math notranslate nohighlight">\(\mathbf{x}_{t+1}\)</span> at time <span class="math notranslate nohighlight">\(t+1\)</span>, given that the system is in state <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> and action <span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> is taken at time <span class="math notranslate nohighlight">\(t\)</span>. Therefore, <span class="math notranslate nohighlight">\(p_t\)</span> specifies a conditional probability distribution over the next states: namely, the sum (for discrete state spaces) or integral over the next state should be 1.</p>
<p>Given the control theory formulation of our problem via a deterministic dynamics function and a noise term, we can derive the corresponding transition probability function through the following relationship:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
p_t(\mathbf{x}_{t+1} | \mathbf{x}_t, \mathbf{u}_t) &amp;= \mathbb{P}(\mathbf{W}_t \in \left\{\mathbf{w} \in \mathbf{W}: \mathbf{x}_{t+1} = f_t(\mathbf{x}_t, \mathbf{u}_t, \mathbf{w})\right\}) \\
&amp;= \sum_{\left\{\mathbf{w} \in \mathbf{W}: \mathbf{x}_{t+1} = f_t(\mathbf{x}_t, \mathbf{u}_t, \mathbf{w})\right\}} q_t(\mathbf{w})
\end{aligned}
\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(q_t(\mathbf{w})\)</span> represents the probability density or mass function of the disturbance <span class="math notranslate nohighlight">\(\mathbf{W}_t\)</span> (assuming discrete state spaces). When dealing with continuous spaces, the above expression simply contains an integral rather than a summation.</p>
<p>For a system with deterministic dynamics and no disturbance, the transition probabilities become much simpler and be expressed using the indicator function. Given a deterministic system with dynamics:</p>
<div class="math notranslate nohighlight">
\[ \mathbf{x}_{t+1} = f_t(\mathbf{x}_t, \mathbf{u}_t) \]</div>
<p>The transition probability function can be expressed as:</p>
<div class="math notranslate nohighlight">
\[\begin{split} p_t(\mathbf{x}_{t+1} | \mathbf{x}_t, \mathbf{u}_t) = \begin{cases}
1 &amp; \text{if } \mathbf{x}_{t+1} = f_t(\mathbf{x}_t, \mathbf{u}_t) \\
0 &amp; \text{otherwise}
\end{cases} \end{split}\]</div>
<p>With this transition probability function, we can recast our Bellman optimality equation:</p>
<div class="math notranslate nohighlight">
\[ J_t^\star(\mathbf{x}_t) = \max_{\mathbf{u}_t \in \mathbf{U}} \left\{ c_t(\mathbf{x}_t, \mathbf{u}_t) + \sum_{\mathbf{x}_{t+1}} p_t(\mathbf{x}_{t+1} | \mathbf{x}_t, \mathbf{u}_t) J_{t+1}^\star(\mathbf{x}_{t+1}) \right\} \]</div>
<p>Here, <span class="math notranslate nohighlight">\({c}(\mathbf{x}_t, \mathbf{u}_t)\)</span> represents the expected immediate reward (or negative cost) when in state <span class="math notranslate nohighlight">\(\mathbf{x}_t\)</span> and taking action <span class="math notranslate nohighlight">\(\mathbf{u}_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span>. The summation term computes the expected optimal value for the future states, weighted by their transition probabilities.</p>
<p>This formulation offers several advantages:</p>
<ol class="arabic simple">
<li><p>It makes the Markovian nature of the problem explicit: the future state depends only on the current state and action, not on the history of states and actions.</p></li>
<li><p>For discrete-state problems, the entire system dynamics can be specified by a set of transition matrices, one for each possible action.</p></li>
<li><p>It allows us to bridge the gap with the wealth of methods in the field of probabilistic graphical models and statistical machine learning techniques for modelling and analysis.</p></li>
</ol>
</section>
</section>
<section id="from-control-theory-to-operations-research-notation">
<h2><span class="section-number">10.6. </span>From Control Theory to Operations Research Notation<a class="headerlink" href="#from-control-theory-to-operations-research-notation" title="Link to this heading">#</a></h2>
<p>The presentation above was intended to bridge the gap between the control-theoretic perspective and the world of closed-loop control through the idea of determining the value function of a parametric optimal control problem. We then saw how the backward induction procedure was applicable to both the deterministic and stochastic cases by taking the expectation over the disturbance variable. We then said that we can alternatively work with a representation of our system where instead of writing our model as a deterministic dynamics function taking a disturbance as an input, we would rather work directly via its transition probability function, which gives rise to the Markov chain interpretation of our system in simulation.</p>
<p>Now we should highlight that the notation used in control theory tends to differ from that found in operations research communities, in which the field of dynamic programming flourished. We summarize those (purely notational) differences in this section.</p>
<p>In operations research, the system state at each decision epoch is typically denoted by <span class="math notranslate nohighlight">\(s \in \mathcal{S}\)</span>, where <span class="math notranslate nohighlight">\(S\)</span> is the set of possible system states. When the system is in state <span class="math notranslate nohighlight">\(s\)</span>, the decision maker may choose an action <span class="math notranslate nohighlight">\(a\)</span> from the set of allowable actions <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span>. The union of all action sets is denoted as <span class="math notranslate nohighlight">\(\mathcal{A} = \bigcup_{s \in \mathcal{S}} \mathcal{A}_s\)</span>.</p>
<p>The dynamics of the system are described by a transition probability function <span class="math notranslate nohighlight">\(p_t(j | s, a)\)</span>, which represents the probability of transitioning to state <span class="math notranslate nohighlight">\(j \in \mathcal{S}\)</span> at time <span class="math notranslate nohighlight">\(t+1\)</span>, given that the system is in state <span class="math notranslate nohighlight">\(s\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> and action <span class="math notranslate nohighlight">\(a \in \mathcal{A}_s\)</span> is chosen. This transition probability function satisfies:</p>
<div class="math notranslate nohighlight">
\[\sum_{j \in \mathcal{S}} p_t(j | s, a) = 1\]</div>
<p>It’s worth noting that in operations research, we typically work with reward maximization rather than cost minimization, which is more common in control theory. However, we can easily switch between these perspectives by simply negating the quantity. That is, maximizing a reward function is equivalent to minimizing its negative, which we would then call a cost function.</p>
<p>The reward function is denoted by <span class="math notranslate nohighlight">\(r_t(s, a)\)</span>, representing the reward received at time <span class="math notranslate nohighlight">\(t\)</span> when the system is in state <span class="math notranslate nohighlight">\(s\)</span> and action <span class="math notranslate nohighlight">\(a\)</span> is taken. In some cases, the reward may also depend on the next state, in which case it is denoted as <span class="math notranslate nohighlight">\(r_t(s, a, j)\)</span>. The expected reward can then be computed as:</p>
<div class="math notranslate nohighlight">
\[r_t(s, a) = \sum_{j \in \mathcal{S}} r_t(s, a, j) p_t(j | s, a)\]</div>
<p>Combined together, these elemetns specify a Markov decision process, which is fully described by the tuple:</p>
<div class="math notranslate nohighlight">
\[\{T, S, \mathcal{A}_s, p_t(\cdot | s, a), r_t(s, a)\}\]</div>
<p>where <span class="math notranslate nohighlight">\(T\)</span> represents the set of decision epochs (the horizon).</p>
<section id="example-sample-size-determination-in-pharmaceutical-development">
<h3><span class="section-number">10.6.1. </span>Example: Sample Size Determination in Pharmaceutical Development<a class="headerlink" href="#example-sample-size-determination-in-pharmaceutical-development" title="Link to this heading">#</a></h3>
<p>Pharmaceutical development is the process of bringing a new drug from initial discovery to market availability. This process is lengthy, expensive, and risky, typically involving several stages:</p>
<ol class="arabic simple">
<li><p><strong>Drug Discovery</strong>: Identifying a compound that could potentially treat a disease.</p></li>
<li><p><strong>Preclinical Testing</strong>: Laboratory and animal testing to assess safety and efficacy.
. <strong>Clinical Trials</strong>: Testing the drug in humans, divided into phases:</p>
<ul class="simple">
<li><p>Phase I: Testing for safety in a small group of healthy volunteers.</p></li>
<li><p>Phase II: Testing for efficacy and side effects in a larger group with the target condition.</p></li>
<li><p>Phase III: Large-scale testing to confirm efficacy and monitor side effects.</p></li>
</ul>
</li>
<li><p><strong>Regulatory Review</strong>: Submitting a New Drug Application (NDA) for approval.</p></li>
<li><p><strong>Post-Market Safety Monitoring</strong>: Continuing to monitor the drug’s effects after market release.</p></li>
</ol>
<p>This process can take 10-15 years and cost over $1 billion <span id="id4">[<a class="reference internal" href="bibliography.html#id20" title="Christopher Paul Adams and Van Vu Brantner. Spending on new drug development1. Health Economics, 19(2):130–141, February 2009. URL: http://dx.doi.org/10.1002/hec.1454, doi:10.1002/hec.1454.">1</a>]</span>. The high costs and risks involved call for a principled approach to decision making. We’ll focus on the clinical trial phases and NDA approval, per the MDP model presented by <span id="id5">[<a class="reference internal" href="bibliography.html#id21" title="Mark Chang. Monte Carlo Simulation for the Pharmaceutical Industry: Concepts, Algorithms, and Case Studies. CRC Press, September 2010. ISBN 9780429152382. URL: http://dx.doi.org/10.1201/EBK1439835920, doi:10.1201/ebk1439835920.">4</a>]</span>:</p>
<ol class="arabic simple">
<li><p><strong>States</strong> (<span class="math notranslate nohighlight">\(S\)</span>): Our state space is <span class="math notranslate nohighlight">\(S = \{s_1, s_2, s_3, s_4\}\)</span>, where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_1\)</span>: Phase I clinical trial</p></li>
<li><p><span class="math notranslate nohighlight">\(s_2\)</span>: Phase II clinical trial</p></li>
<li><p><span class="math notranslate nohighlight">\(s_3\)</span>: Phase III clinical trial</p></li>
<li><p><span class="math notranslate nohighlight">\(s_4\)</span>: NDA approval</p></li>
</ul>
</li>
<li><p><strong>Actions</strong> (<span class="math notranslate nohighlight">\(A\)</span>): At each state, the action is choosing the sample size <span class="math notranslate nohighlight">\(n_i\)</span> for the corresponding clinical trial. The action space is <span class="math notranslate nohighlight">\(A = \{10, 11, ..., 1000\}\)</span>, representing possible sample sizes.</p></li>
<li><p><strong>Transition Probabilities</strong> (<span class="math notranslate nohighlight">\(P\)</span>): The probability of moving from one state to the next depends on the chosen sample size and the inherent properties of the drug.
We define:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(s_2|s_1, n_1) = p_{12}(n_1) = \sum_{i=0}^{\lfloor\eta_1 n_1\rfloor} \binom{n_1}{i} p_0^i (1-p_0)^{n_1-i}\)</span>
where <span class="math notranslate nohighlight">\(p_0\)</span> is the true toxicity rate and <span class="math notranslate nohighlight">\(\eta_1\)</span> is the toxicity threshold for Phase I.</p></li>
</ul>
</li>
</ol>
<ul>
<li><p>Of particular interest is the transition from Phase II to Phase III which we model as:</p>
<p><span class="math notranslate nohighlight">\(P(s_3|s_2, n_2) = p_{23}(n_2) = \Phi\left(\frac{\sqrt{n_2}}{2}\delta - z_{1-\eta_2}\right)\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\Phi\)</span> is the cumulative distribution function (CDF) of the standard normal distribution:</p>
<p><span class="math notranslate nohighlight">\(\Phi(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-t^2/2} dt\)</span></p>
<p>This is giving us the probability that we would observe a treatment effect this large or larger if the null hypothesis (no treatment effect) were true. A higher probability indicates stronger evidence of a treatment effect, making it more likely that the drug will progress to Phase III.</p>
<p>In this expression, <span class="math notranslate nohighlight">\(\delta\)</span> is called the “normalized treatment effect”. In clinical trials, we’re often interested in the difference between the treatment and control groups. The “normalized” part means we’ve adjusted this difference for the variability in the data. Specifically <span class="math notranslate nohighlight">\(\delta = \frac{\mu_t - \mu_c}{\sigma}\)</span> where <span class="math notranslate nohighlight">\(\mu_t\)</span> is the mean outcome in the treatment group, <span class="math notranslate nohighlight">\(\mu_c\)</span> is the mean outcome in the control group, and <span class="math notranslate nohighlight">\(\sigma\)</span> is the standard deviation of the outcome. A larger <span class="math notranslate nohighlight">\(\delta\)</span> indicates a stronger treatment effect.</p>
<p>Furthermore, the term <span class="math notranslate nohighlight">\(z_{1-\eta_2}\)</span> is the <span class="math notranslate nohighlight">\((1-\eta_2)\)</span>-quantile of the standard normal distribution. In other words, it’s the value where the probability of a standard normal random variable being greater than this value is <span class="math notranslate nohighlight">\(\eta_2\)</span>. For example, if <span class="math notranslate nohighlight">\(\eta_2 = 0.05\)</span>, then <span class="math notranslate nohighlight">\(z_{1-\eta_2} \approx 1.645\)</span>. A smaller <span class="math notranslate nohighlight">\(\eta_2\)</span> makes the trial more conservative, requiring stronger evidence to proceed to Phase III.</p>
<p>Finally, <span class="math notranslate nohighlight">\(n_2\)</span> is the sample size for Phase II. The <span class="math notranslate nohighlight">\(\sqrt{n_2}\)</span> term reflects that the precision of our estimate of the treatment effect improves with the square root of the sample size.</p>
</li>
<li><p><span class="math notranslate nohighlight">\(P(s_4|s_3, n_3) = p_{34}(n_3) = \Phi\left(\frac{\sqrt{n_3}}{2}\delta - z_{1-\eta_3}\right)\)</span>
where <span class="math notranslate nohighlight">\(\eta_3\)</span> is the significance level for Phase III.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p><strong>Rewards</strong> (<span class="math notranslate nohighlight">\(R\)</span>): The reward function captures the costs of running trials and the potential profit from a successful drug:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R(s_i, n_i) = -c_i(n_i)\)</span> for <span class="math notranslate nohighlight">\(i = 1, 2, 3\)</span>, where <span class="math notranslate nohighlight">\(c_i(n_i)\)</span> is the cost of running a trial with sample size <span class="math notranslate nohighlight">\(n_i\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(R(s_4) = g_4\)</span>, where <span class="math notranslate nohighlight">\(g_4\)</span> is the expected profit from a successful drug.</p></li>
</ul>
</li>
<li><p><strong>Discount Factor</strong> (<span class="math notranslate nohighlight">\(\gamma\)</span>): We use a discount factor <span class="math notranslate nohighlight">\(0 &lt; \gamma \leq 1\)</span> to account for the time value of money and risk preferences.</p></li>
</ol>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">ndtr</span> <span class="k">as</span> <span class="n">norm_cdf</span>

<span class="k">def</span> <span class="nf">binomial_pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">transition_prob_phase1</span><span class="p">(</span><span class="n">n1</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">p0</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">binomial_pmf</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n1</span><span class="p">,</span> <span class="n">p0</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">eta1</span> <span class="o">*</span> <span class="n">n1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>

<span class="k">def</span> <span class="nf">transition_prob_phase2</span><span class="p">(</span><span class="n">n2</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">norm_cdf</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n2</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">-</span> <span class="n">norm_cdf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">eta2</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">transition_prob_phase3</span><span class="p">(</span><span class="n">n3</span><span class="p">,</span> <span class="n">eta3</span><span class="p">,</span> <span class="n">delta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">norm_cdf</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n3</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">delta</span> <span class="o">-</span> <span class="n">norm_cdf</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">eta3</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">immediate_reward</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">n</span>  <span class="c1"># Changed to negative to represent cost</span>

<span class="k">def</span> <span class="nf">value_iteration</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">g4</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">eta3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">S</span><span class="p">))</span>
    <span class="n">V</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">g4</span>  <span class="c1"># Value for NDA approval state</span>
    <span class="n">optimal_n</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span>  <span class="c1"># Store optimal n for each phase</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">V_old</span> <span class="o">=</span> <span class="n">V</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>  <span class="c1"># Iterate backwards from Phase III to Phase I</span>
            <span class="n">max_value</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

            <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">A</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Phase I</span>
                    <span class="n">p</span> <span class="o">=</span> <span class="n">transition_prob_phase1</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">p0</span><span class="p">)</span>
                <span class="k">elif</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Phase II</span>
                    <span class="n">p</span> <span class="o">=</span> <span class="n">transition_prob_phase2</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># Phase III</span>
                    <span class="n">p</span> <span class="o">=</span> <span class="n">transition_prob_phase3</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">eta3</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>

                <span class="n">value</span> <span class="o">=</span> <span class="n">immediate_reward</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">value</span> <span class="o">&gt;</span> <span class="n">max_value</span><span class="p">:</span>
                    <span class="n">max_value</span> <span class="o">=</span> <span class="n">value</span>
                    <span class="n">optimal_n</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>

            <span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">V</span> <span class="o">-</span> <span class="n">V_old</span><span class="p">))</span> <span class="o">&lt;</span> <span class="n">epsilon</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">V</span><span class="p">,</span> <span class="n">optimal_n</span>

<span class="c1"># Set up the problem parameters</span>
<span class="n">S</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Phase I&#39;</span><span class="p">,</span> <span class="s1">&#39;Phase II&#39;</span><span class="p">,</span> <span class="s1">&#39;Phase III&#39;</span><span class="p">,</span> <span class="s1">&#39;NDA approval&#39;</span><span class="p">]</span>
<span class="n">A</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1001</span><span class="p">)</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">g4</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">p0</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Example toxicity rate for Phase I</span>
<span class="n">delta</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># Example normalized treatment difference</span>
<span class="n">eta1</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">eta3</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.025</span>

<span class="c1"># Run the value iteration algorithm</span>
<span class="n">V</span><span class="p">,</span> <span class="n">optimal_n</span> <span class="o">=</span> <span class="n">value_iteration</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">g4</span><span class="p">,</span> <span class="n">p0</span><span class="p">,</span> <span class="n">delta</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">eta2</span><span class="p">,</span> <span class="n">eta3</span><span class="p">)</span>

<span class="c1"># Print results</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">S</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value for </span><span class="si">{</span><span class="n">state</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">V</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal sample sizes: Phase I: </span><span class="si">{</span><span class="n">optimal_n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, Phase II: </span><span class="si">{</span><span class="n">optimal_n</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">, Phase III: </span><span class="si">{</span><span class="n">optimal_n</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Sanity checks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sanity checks:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;1. NDA approval value: </span><span class="si">{</span><span class="n">V</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;2. All values non-negative and &lt;= NDA value: </span><span class="si">{</span><span class="nb">all</span><span class="p">(</span><span class="mi">0</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">V</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">V</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;3. Optimal sample sizes in range: </span><span class="si">{</span><span class="nb">all</span><span class="p">(</span><span class="mi">10</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="mi">1000</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">optimal_n</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Value for Phase I: 8050.54
Value for Phase II: 8576.47
Value for Phase III: 9267.42
Value for NDA approval: 10000.00
Optimal sample sizes: Phase I: 75, Phase II: 190, Phase III: 195

Sanity checks:
1. NDA approval value: 10000.0
2. All values non-negative and &lt;= NDA value: True
3. Optimal sample sizes in range: True
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="decision-rules-and-policies">
<h2><span class="section-number">10.7. </span>Decision Rules and Policies<a class="headerlink" href="#decision-rules-and-policies" title="Link to this heading">#</a></h2>
<p>In the presentation provided so far, we directly assumed that the form of our feedback controller was of the form <span class="math notranslate nohighlight">\(u(\mathbf{x}, t)\)</span>. The idea is that rather than just looking at the stage as in open-loop control, we would now consider the current state to account for the presence of noise. We came to that conclusion by considering the parametric optimization problem corresponding to the trajectory optimization perspective and saw that the “argmax” counterpart to the value function (the max) was exactly this function <span class="math notranslate nohighlight">\(u(x, t)\)</span>. But this presentation was mostly for intuition and neglected the fact that we could consider other kinds of feedback controllers. In the context of MDPs and under the OR terminology, we should now rather talk of policies instead of controllers.</p>
<p>But to properly introduce the concept of policy, we first have to talk about decision rules. A decision rule is a prescription of a procedure for action selection in each state at a specified decision epoch. These rules can vary in their complexity due to their potential dependence on the history and ways in which actions are then selected. Decision rules can be classified based on two main criteria:</p>
<ol class="arabic simple">
<li><p>Dependence on history: Markovian or History-dependent</p></li>
<li><p>Action selection method: Deterministic or Randomized</p></li>
</ol>
<p>Markovian decision rules are those that depend only on the current state, while history-dependent rules consider the entire sequence of past states and actions. Formally, we can define a history <span class="math notranslate nohighlight">\(h_t\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> as:</p>
<div class="math notranslate nohighlight">
\[h_t = (s_1, a_1, \ldots, s_{t-1}, a_{t-1}, s_t)\]</div>
<p>where <span class="math notranslate nohighlight">\(s_u\)</span> and <span class="math notranslate nohighlight">\(a_u\)</span> denote the state and action at decision epoch <span class="math notranslate nohighlight">\(u\)</span>. The set of all possible histories at time <span class="math notranslate nohighlight">\(t\)</span>, denoted <span class="math notranslate nohighlight">\(H_t\)</span>, grows rapidly with <span class="math notranslate nohighlight">\(t\)</span>:</p>
<div class="math notranslate nohighlight">
\[H_1 = \mathcal{S}\]</div>
<div class="math notranslate nohighlight">
\[H_2 = \mathcal{S} \times A \times \mathcal{S}\]</div>
<div class="math notranslate nohighlight">
\[H_t = H_{t-1} \times A \times \mathcal{S} = \mathcal{S} \times (A \times \mathcal{S})^{t-1}\]</div>
<p>This exponential growth in the size of the history set motivates us to seek conditions under which we can avoid searching for history-dependent decision rules and instead focus on Markovian rules, which are much simpler to implement and evaluate.</p>
<p>Decision rules can be further classified as deterministic or randomized. A deterministic rule selects an action with certainty, while a randomized rule specifies a probability distribution over the action space.</p>
<p>These classifications lead to four types of decision rules:</p>
<ol class="arabic simple">
<li><p>Markovian Deterministic (MD): <span class="math notranslate nohighlight">\(d_t: \mathcal{S} \rightarrow \mathcal{A}_s\)</span></p></li>
<li><p>Markovian Randomized (MR): <span class="math notranslate nohighlight">\(d_t: \mathcal{S} \rightarrow \mathcal{P}(\mathcal{A}_s)\)</span></p></li>
<li><p>History-dependent Deterministic (HD): <span class="math notranslate nohighlight">\(d_t: H_t \rightarrow \mathcal{A}_s\)</span></p></li>
<li><p>History-dependent Randomized (HR): <span class="math notranslate nohighlight">\(d_t: H_t \rightarrow \mathcal{P}(\mathcal{A}_s)\)</span></p></li>
</ol>
<p>Where <span class="math notranslate nohighlight">\(\mathcal{P}(\mathcal{A}_s)\)</span> denotes the set of probability distributions over <span class="math notranslate nohighlight">\(\mathcal{A}_s\)</span>.</p>
<!-- The choice of decision rule affects how the MDP's rewards and transition probabilities are computed. For example, with a Markovian deterministic rule $d_t \in D_t^{MD}$, we have:

$$r_t(s, d_t(s)) \text{ and } p_t(j|s, d_t(s))$$

With a randomized Markovian rule, these become expected values:

$$r_t(s, d_t(s)) = \sum_{a \in \mathcal{A}_s} r_t(s,a) q_{d_t(s)}(a)$$
$$p_t(j|s, d_t(s)) = \sum_{a \in \mathcal{A}_s} p_t(j|s,a) q_{d_t(s)}(a)$$

Where $q_{d_t(s)}(a)$ is the probability of choosing action $a$ in state $s$ under decision rule $d_t$. -->
<p>It’s important to note that decision rules are stage-wise objects. However, to solve an MDP, we need a strategy for the entire horizon. This is where we make a distinction and introduce the concept of a policy. A policy <span class="math notranslate nohighlight">\(\pi\)</span> is a sequence of decision rules, one for each decision epoch:</p>
<div class="math notranslate nohighlight">
\[\pi = (d_1, d_2, ..., d_{N-1})\]</div>
<p>Where <span class="math notranslate nohighlight">\(N\)</span> is the horizon length (possibly infinite). The set of all policies of class <span class="math notranslate nohighlight">\(K\)</span> (where <span class="math notranslate nohighlight">\(K\)</span> can be HR, HD, MR, or MD) is denoted as <span class="math notranslate nohighlight">\(\Pi^K\)</span>.</p>
<p>A special type of policy is a stationary policy, where the same decision rule is used at all epochs: <span class="math notranslate nohighlight">\(\pi = (d, d, ...)\)</span>, often denoted as <span class="math notranslate nohighlight">\(d^\infty\)</span>. Stationary policies are particularly important in infinite horizon problems.</p>
<p>The relationships between these policy classes form a hierarchy:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
\Pi^{SD} \subset \Pi^{SR} \subset \Pi^{MR} \subset \Pi^{HR}\\
\Pi^{SD} \subset \Pi^{MD} \subset \Pi^{MR} \subset \Pi^{HR} \\
\Pi^{SD} \subset \Pi^{MD} \subset \Pi^{HD} \subset \Pi^{HR}
\end{align*}
\end{split}\]</div>
<p>Where SD stands for Stationary Deterministic and SR for Stationary Randomized. The largest set is by far the set of history randomized policies.</p>
<p>A fundamental question in MDP theory is: under what conditions can we avoid working with the set <span class="math notranslate nohighlight">\(\Pi^{HR}\)</span> and focus for example on the much simpler set of deterministic Markovian policy? Even more so, we will see that in the infinite horizon case, we can drop the dependance on time and simply consider stationary deterministic Markovian policies.</p>
<!-- ### Special Kind of MDP: Bandit Models

Markov Decision Processes (MDPs) and optimal control problems in general are all about dealing with sequential problems: problems in which entire sequences of actions or ways of acting through time are considered. This makes these methods general and powerful, but also challenging from a practical and theoretical perspective.

In some problems, there might be further simplifications at play that would allow us to devise more efficient methods. A particular sub-class of such problems is that of bandit models. These models are often encountered in applications like adaptive optics, ad placement, or can even be found in frameworks like that of GFlowNets or LLMs.

More precisely, we define a bandit model as follows:

A bandit model is a sequential decision model in which, at each decision epoch, the decision maker observes the state of each of $K$ Markov reward processes and, based on the states, the transition probabilities, and rewards of each, selects a process to use in the current period. The selected process changes state according to its transition probabilities, and the states of all other processes remain fixed.

Formally, we can define a bandit model as a Markov Decision Process with the following components:

1. Decision epochs: $T = \{1, 2, \ldots, N\}$, where $N \leq \infty$.

2. States: $S = S^1 \times S^2 \times \cdots \times S^K$, where $S^i$ is the state space of the $i$-th process.

3. Actions: At each decision epoch, the action is to choose one of the $K$ processes.

4. Transition probabilities: For process $i$ in state $s^i \in S^i$, the transition probability to state $j^i$ is given by $p_t^i(j^i | s^i)$.

5. Rewards: When process $i$ in state $s^i$ is chosen, the decision maker receives a reward $r_t^i(s^i)$.

The effects of choosing process $i$ when it is in state $s^i \in S^i$, $i = 1, 2, \ldots, K$ are:

1. It changes state according to the transition law $p_t^i(j^i | s^i)$.
2. The decision maker receives a reward $r_t^i(s^i)$.
3. All other processes remain in their current state. --></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="cocp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5. </span>Continuous-Time Trajectory Optimization</p>
      </div>
    </a>
    <a class="right-next"
       href="bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">11. </span>Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">7. Dynamic Programming</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#open-loop-vs-closed-loop-control">8. Open-Loop vs Closed-Loop Control</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#closing-the-loop-by-replanning">9. Closing the Loop by Replanning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-propofol-infusion-control">9.1. Example: Propofol Infusion Control</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#computational-efficiency-improvements">9.2. Computational Efficiency Improvements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explicit-mpc">9.2.1. Explicit MPC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#amortized-optimization-and-neural-networks">9.2.1.1. Amortized Optimization and Neural Networks</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#warmstarting-and-predictor-corrector-mpc">9.2.2. Warmstarting and Predictor-Corrector MPC</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#principle-of-optimality">10. Principle of Optimality</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-recursion">10.1. Backward Recursion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-optimal-harvest-in-resource-management">10.2. Example: Optimal Harvest in Resource Management</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discretization-and-interpolation">10.3. Discretization and Interpolation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#backward-recursion-with-interpolation">10.3.1. Backward Recursion with Interpolation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-considerations">10.3.2. Implementation Considerations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-optimal-harvest-with-linear-interpolation">10.3.3. Example: Optimal Harvest with Linear Interpolation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-quadratic-regulator-via-dynamic-programming">10.4. Linear Quadratic Regulator via Dynamic Programming</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stochastic-dynamic-programming">10.5. Stochastic Dynamic Programming</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-stochastic-optimal-harvest-in-resource-management">10.5.1. Example: Stochastic Optimal Harvest in Resource Management</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-decision-process-formulation">10.5.2. Markov Decision Process Formulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#from-control-theory-to-operations-research-notation">10.6. From Control Theory to Operations Research Notation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-sample-size-determination-in-pharmaceutical-development">10.6.1. Example: Sample Size Determination in Pharmaceutical Development</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rules-and-policies">10.7. Decision Rules and Policies</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pierre-Luc Bacon
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>