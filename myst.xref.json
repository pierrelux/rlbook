{"version":"1","myst":"1.6.3","references":[{"kind":"page","data":"/index.json","url":"/"},{"identifier":"the-decision-problem","kind":"heading","data":"/index.json","url":"/","implicit":true},{"identifier":"what-this-book-offers","kind":"heading","data":"/index.json","url":"/","implicit":true},{"kind":"page","data":"/dynamics.json","url":"/dynamics"},{"identifier":"models-for-decision-making","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"modeling-realism-and-control","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"example-a-simple-model-that-supports-better-decisions","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"dynamics-models-for-decision-making","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"the-state-space-perspective","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"discrete-versus-continuous-time","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"examples-of-deterministic-dynamics-hvac-control","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"control-abstraction-levels","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"advantages-of-physics-based-models","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"simulating-the-1r1c-model","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"from-deterministic-to-stochastic","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"function-plus-noise","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"transition-kernel","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"continuous-time-analogue","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"example-managing-a-qu-bec-hydroelectric-reservoir","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"partial-observability","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"observation-kernel-view","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"example-stabilizing-a-telescopes-vision-with-adaptive-optics","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"programs-as-models","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"case-study-robotics-with-mujoco","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"systems-with-discrete-events","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"hybrid-systems","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"case-study-building-energy-with-energyplus","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"agent-based-models","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"case-study-traffic-simulation-with-sumo","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"case-study-curbside-access-at-montr-al-trudeau-airport","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"identifier":"summary","kind":"heading","data":"/dynamics.json","url":"/dynamics","implicit":true},{"kind":"page","data":"/trajectories.json","url":"/trajectories"},{"identifier":"a-motivating-example-inventory-control","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"discrete-time-optimal-control-problems-docps","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"existence-of-solutions-and-optimality-conditions","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"existence-of-solutions","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"optimality-conditions","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"from-kkt-to-algorithms","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"primal-dual-gradient-dynamics-arrow-hurwicz","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"sqp-as-newton-on-the-kkt-system-equality-case","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"examples-of-docps","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"end-of-day-portfolio-rebalancing","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"daily-ad-budget-allocation-with-carryover","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"docps-arising-from-the-discretization-of-continuous-time-ocps","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"programs-as-docps-and-differentiable-programming","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"example-retry-loop-optimization","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"example-gradient-descent-with-momentum-as-docp","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"variants-lagrange-and-mayer-problems","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"reducing-to-mayer-form-by-state-augmentation","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"numerical-methods-for-solving-docps","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"simultaneous-methods","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"sequential-methods","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"single-shooting-forward-unroll","kind":"proof:algorithm","data":"/trajectories.json","url":"/trajectories"},{"identifier":"in-between-sequential-and-simultaneous","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"the-discrete-time-pontryagin-principle","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"necessary-conditions","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"the-adjoint-equation-as-reverse-accumulation","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"summary-and-outlook","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercises","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-1-kkt-conditions-for-a-simple-docp","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-2-lagrange-to-mayer-conversion","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-3-when-licq-fails","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-4-costate-recursion-as-sensitivity","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-5-single-shooting-implementation","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-6-multiple-shooting-segments","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-7-adjoint-gradient-verification","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"identifier":"exercise-8-resource-allocation-as-a-docp","kind":"heading","data":"/trajectories.json","url":"/trajectories","implicit":true},{"kind":"page","data":"/collocation.json","url":"/collocation"},{"identifier":"a-motivating-example-minimum-time-braking","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"problem-formulations","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"direct-transcription-methods","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"discretizing-cost-and-dynamics-together","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"on-the-choice-of-interior-points","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"step-function-based-construction-piecewise-constants-rectangle-or-midpoint","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"interpolating-function-based-construction-low-order-polynomials-trapezoid-simpson-gauss-radau-lobatto","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"polynomial-interpolation","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"solving-for-the-coefficients-monomial-basis","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"using-a-different-basis","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"derivative-constraints","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"interpolating-ode-trajectories-collocation","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"boundary-conditions-and-node-families","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"control-parameterization-and-cost-integration","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"a-compendium-of-direct-transcription-methods-in-trajectory-optimization","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"euler-collocation","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"trapezoidal-collocation","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"hermite-simpson-quadratic-interpolation-midpoint-included","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"examples","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"compressor-surge-problem","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"solution-by-trapezoidal-collocation","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"system-identification-as-trajectory-optimization-compressor-surge","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"flight-trajectory-optimization","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"hydro-cascade-scheduling-with-physical-routing-and-multiple-shooting","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"exercises","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"identifier":"ex-collocation-truncation","kind":"exercise","data":"/collocation.json","url":"/collocation"},{"identifier":"ex-collocation-gauss-continuity","kind":"exercise","data":"/collocation.json","url":"/collocation"},{"identifier":"ex-collocation-hermite-simpson","kind":"exercise","data":"/collocation.json","url":"/collocation"},{"identifier":"ex-collocation-braking","kind":"exercise","data":"/collocation.json","url":"/collocation"},{"identifier":"summary-and-outlook","kind":"heading","data":"/collocation.json","url":"/collocation","implicit":true},{"kind":"page","data":"/mpc.json","url":"/mpc"},{"identifier":"closing-the-loop-by-replanning","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"the-receding-horizon-principle","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"horizon-selection-and-problem-formulation","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"infinite-horizon-regulation","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"finite-duration-tasks","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"periodic-tasks","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"the-mpc-algorithm","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"alg-mpc-complete","kind":"proof:algorithm","data":"/mpc.json","url":"/mpc"},{"identifier":"successive-linearization-and-quadratic-approximations","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"theoretical-guarantees","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"stability-notions-across-control-tasks","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"mpc-with-stability-guarantees","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"thm-mpc-stability","kind":"proof:theorem","data":"/mpc.json","url":"/mpc"},{"identifier":"suboptimality-bounds","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"deriving-the-approximation-error","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"the-landscape-of-mpc-variants","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"tracking-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"regulatory-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"economic-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"robust-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"stochastic-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"hybrid-and-mixed-integer-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"distributed-and-decentralized-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"adaptive-and-learning-based-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"robustness-in-real-time-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"example-wind-farm-yield-optimization","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"softening-constraints-through-slack-variables","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"feasibility-restoration","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"reference-governors","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"backup-controllers","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"cascade-architectures","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"example-chemical-reactor-control-under-failure","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"computational-efficiency-via-parametric-programming","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"general-framework-parametric-optimization","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"solution-sensitivity-via-the-implicit-function-theorem","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"predictor-corrector-mpc","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"amortized-optimization-and-neural-approximation-of-controllers","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"imitation-learning-framework","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"identifier":"example-propofol-infusion-control","kind":"heading","data":"/mpc.json","url":"/mpc","implicit":true},{"kind":"page","data":"/dp.json","url":"/dp"},{"identifier":"backward-recursion","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"backward-recursion-deterministic","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"thm-bolza-backward","kind":"proof:theorem","data":"/dp.json","url":"/dp"},{"identifier":"example-optimal-harvest-in-resource-management","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"handling-continuous-spaces-with-interpolation","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"backward-recursion-with-interpolation","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"backward-recursion-interp","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"example-optimal-harvest-with-linear-interpolation","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"stochastic-dynamic-programming-and-markov-decision-processes","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"decision-rules-and-policies","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"stochastic-system-dynamics","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"optimality-equations-in-the-stochastic-setting","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"stoch-principle-opt","kind":"proof:theorem","data":"/dp.json","url":"/dp"},{"identifier":"stoch-state-suff","kind":"proof:proposition","data":"/dp.json","url":"/dp"},{"identifier":"stoch-policy-reduction","kind":"proof:theorem","data":"/dp.json","url":"/dp"},{"identifier":"backward-recursion-stochastic","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"example-stochastic-optimal-harvest-in-resource-management","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"linear-quadratic-regulator-via-dynamic-programming","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"backward-recursion-lqr","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"markov-decision-process-formulation","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"notation-in-operations-reseach","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"what-is-an-optimal-policy","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"backward-induction","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"backward-policy-evaluation","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"example-sample-size-determination-in-pharmaceutical-development","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"infinite-horizon-mdps","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"random-horizon-interpretation-of-discounting","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"prop-5-3-1","kind":"proof:theorem","data":"/dp.json","url":"/dp"},{"identifier":"vector-representation-in-markov-decision-processes","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"neumann-series","kind":"proof:theorem","data":"/dp.json","url":"/dp"},{"identifier":"solving-operator-equations","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"successive-approximation-method","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"successive-approximation","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"newton-kantorovich-method","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"optimality-equations-for-infinite-horizon-mdps","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"algorithms-for-solving-the-optimality-equations","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"value-iteration","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"identifier":"value-iteration-convergence","kind":"proof:proposition","data":"/dp.json","url":"/dp"},{"identifier":"newton-kantorovich-applied-to-bellman-optimality","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"perspective-1-max-of-affine-maps","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"perspective-2-envelope-theorem","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"perspective-3-the-implicit-function-theorem","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"connection-to-policy-iteration","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"the-semismooth-newton-perspective","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"policy-iteration","kind":"heading","data":"/dp.json","url":"/dp","implicit":true},{"identifier":"policy-iteration-standard","kind":"proof:algorithm","data":"/dp.json","url":"/dp"},{"kind":"page","data":"/smoothing.json","url":"/smoothing"},{"identifier":"smooth-bellman-optimality-equations","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"smooth-value-iteration-algorithm","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"smooth-value-iteration","kind":"proof:algorithm","data":"/smoothing.json","url":"/smoothing"},{"identifier":"alternative-soft-maximum-gaussian-uncertainty-weighted-aggregation","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"gumbel-noise-on-the-rewards","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"step-1-define-the-augmented-mdp-with-gumbel-noise","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"step-2-the-hard-bellman-equation-on-the-augmented-state-space","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"step-3-define-the-ex-ante-inclusive-value-function","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"step-4-separate-the-deterministic-and-random-components","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"step-5-apply-the-gumbel-random-utility-identity","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"gumbel-random-utility","kind":"proof:lemma","data":"/smoothing.json","url":"/smoothing"},{"identifier":"step-6-summary-of-the-derivation","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"deriving-the-optimal-smooth-policy","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"gumbel-softmax","kind":"proof:lemma","data":"/smoothing.json","url":"/smoothing"},{"identifier":"regularized-markov-decision-processes","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"legendre-fenchel-transform","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"regularized-bellman-operators","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"recovering-the-smooth-bellman-equations","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"smooth-policy-iteration-algorithm","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"smooth-policy-evaluation","kind":"proof:algorithm","data":"/smoothing.json","url":"/smoothing"},{"identifier":"policy-iteration-smooth","kind":"proof:algorithm","data":"/smoothing.json","url":"/smoothing"},{"identifier":"equivalence-between-smooth-bellman-equations-and-entropy-regularized-mdps","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"entropy-regularized-dynamic-programming-algorithms","kind":"heading","data":"/smoothing.json","url":"/smoothing","implicit":true},{"identifier":"entropy-regularized-value-iteration","kind":"proof:algorithm","data":"/smoothing.json","url":"/smoothing"},{"identifier":"policy-iteration-entropy-regularized","kind":"proof:algorithm","data":"/smoothing.json","url":"/smoothing"},{"kind":"page","data":"/projection.json","url":"/projection"},{"identifier":"a-motivating-example-optimal-stopping-with-continuous-states","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"testing-whether-a-residual-vanishes","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"from-variational-conditions-to-optimization","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"the-general-framework","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"step-1-choose-a-finite-dimensional-approximation-space","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"step-2-define-the-residual-function","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"step-3-minimize-the-residual","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"collocation-make-the-residual-zero-at-selected-points","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"galerkin-make-the-residual-orthogonal-to-the-approximation-space","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"least-squares-minimize-the-l-2-norm-of-the-residual","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"fitted-q-iteration-project-then-iterate","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"step-4-solve-the-finite-dimensional-problem","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"computational-cost-and-conditioning","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"two-main-solution-approaches","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"method-1-function-iteration-successive-approximation","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"method-2-newtons-method","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"comparison-and-practical-recommendations","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"step-5-verify-the-solution","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"application-to-the-bellman-equation","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"collocation","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"collocation-function-iteration","kind":"proof:algorithm","data":"/projection.json","url":"/projection"},{"identifier":"collocation-newton","kind":"proof:algorithm","data":"/projection.json","url":"/projection"},{"identifier":"worked-example-collocation-on-the-optimal-stopping-problem","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"galerkin","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"galerkin-function-iteration","kind":"proof:algorithm","data":"/projection.json","url":"/projection"},{"identifier":"galerkin-newton","kind":"proof:algorithm","data":"/projection.json","url":"/projection"},{"identifier":"galerkin-for-discrete-mdps-lstd-and-lspi","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"policy-evaluation-lstd","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"eq:lstd-galerkin","html_id":"eq-lstd-galerkin","kind":"equation","data":"/projection.json","url":"/projection"},{"identifier":"worked-example-lstd-for-policy-evaluation","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"the-bellman-optimality-equation-function-iteration-and-newtons-method","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"extension-to-nonlinear-approximators","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"monotone-projection-and-the-preservation-of-contraction","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"monotone-approximators-and-stability","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"monotonicity-implies-nonexpansiveness","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"monotone-nonexpansive","kind":"proof:proposition","data":"/projection.json","url":"/projection"},{"identifier":"preservation-of-contraction","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"santos-vigo-aguiar-stability","kind":"proof:theorem","data":"/projection.json","url":"/projection"},{"identifier":"averagers-in-discrete-state-problems","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"gordon-averager","kind":"proof:definition","data":"/projection.json","url":"/projection"},{"identifier":"gordon-stability","kind":"proof:theorem","data":"/projection.json","url":"/projection"},{"identifier":"connecting-back-to-collocation-galerkin-and-least-squares","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"beyond-monotone-approximators","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"the-policy-evaluation-problem-and-lstd","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"lstd-as-projected-bellman-equation","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"orthogonal-projection-is-non-expansive","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"contraction-of-bellmanpi-in-cdot-xi","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"interpretation-the-on-policy-condition","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"the-bellman-optimality-case","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"fitted-value-q-iteration-fvi-fqi","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"identifier":"fitted-value-iteration","kind":"proof:algorithm","data":"/projection.json","url":"/projection"},{"identifier":"summary","kind":"heading","data":"/projection.json","url":"/projection","implicit":true},{"kind":"page","data":"/montecarlo.json","url":"/montecarlo"},{"identifier":"evaluating-the-bellman-operator-with-numerical-quadrature","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"orthogonal-collocation-with-chebyshev-polynomials","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"galerkin-projection-with-hermite-polynomials","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"monte-carlo-integration","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"monte-carlo-as-randomized-quadrature","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"monte-carlo-evaluation-of-the-bellman-operator","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"sampling-the-outer-expectations","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"simulation-based-projection-methods","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"amortizing-action-selection-via-q-functions","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"simadp-parametric-q-value-iteration","kind":"proof:algorithm","data":"/montecarlo.json","url":"/montecarlo"},{"identifier":"the-single-sample-paradigm","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"overestimation-bias-and-mitigation-strategies","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"sources-of-overestimation-bias","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"learning-the-bias-correction","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"keane-wolpin-bias-correction","kind":"proof:algorithm","data":"/montecarlo.json","url":"/montecarlo"},{"identifier":"analytical-bias-correction","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"decoupling-selection-and-evaluation","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"double-q-value-iteration","kind":"proof:algorithm","data":"/montecarlo.json","url":"/montecarlo"},{"identifier":"weighted-estimators-a-third-approach","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"identifier":"summary-and-forward-look","kind":"heading","data":"/montecarlo.json","url":"/montecarlo","implicit":true},{"kind":"page","data":"/fqi.json","url":"/fqi"},{"identifier":"design-choices-in-fqi-methods","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"plug-in-approximation-with-empirical-distributions","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"data-buffers-and-the-unified-template","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"batch-algorithms-ernsts-fqi-and-nfqi","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"fitted-q-iteration-batch","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"from-nested-to-flattened-q-iteration","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"making-the-nested-structure-explicit","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"nfqi-explicit-inner","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"flattening-into-a-single-loop","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"nfqi-flattened","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"smooth-target-updates-via-exponential-moving-average","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"nfqi-flattened-ema","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"online-algorithms-dqn-and-extensions","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"deep-q-network-dqn","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"dqn","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"double-deep-q-network-double-dqn","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"double-dqn","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"q-learning-the-limiting-case","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"q-learning","kind":"proof:algorithm","data":"/fqi.json","url":"/fqi"},{"identifier":"convergence-analysis-via-the-ode-method","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"regression-losses-and-noise-models","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"gumbel-regression","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"classification-based-q-learning","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"identifier":"summary","kind":"heading","data":"/fqi.json","url":"/fqi","implicit":true},{"kind":"page","data":"/amortization.json","url":"/amortization"},{"identifier":"explicit-optimization","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"fitted-q-iteration-explicit","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"amortized-optimization-approach","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"fitted-q-iteration-amortized","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"deterministic-parametrized-policies","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"the-amortization-problem-for-continuous-actions","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"neural-fitted-q-iteration-for-continuous-actions-nfqca","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"from-discrete-to-continuous-actions","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"nfqca","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"deep-deterministic-policy-gradient-ddpg","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"exploration-via-action-noise","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"ddpg","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"twin-delayed-deep-deterministic-policy-gradient-td3","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"twin-q-networks-and-the-minimum-operator","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"td3","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"soft-actor-critic","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"from-intractable-integral-to-tractable-expectation","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"learning-the-policy-matching-the-boltzmann-distribution","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"sac","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"path-consistency-learning-pcl","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"the-path-consistency-property","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"eq:v-general-policy","html_id":"eq-v-general-policy","kind":"equation","data":"/amortization.json","url":"/amortization"},{"identifier":"eq:v-q-exact-boltzmann","html_id":"eq-v-q-exact-boltzmann","kind":"equation","data":"/amortization.json","url":"/amortization"},{"identifier":"eq:path-consistency-exact","html_id":"eq-path-consistency-exact","kind":"equation","data":"/amortization.json","url":"/amortization"},{"identifier":"eq:path-residual","html_id":"eq-path-residual","kind":"equation","data":"/amortization.json","url":"/amortization"},{"identifier":"structural-requirements-deterministic-dynamics-and-entropy-regularization","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"deterministic-dynamics-avoiding-the-double-sampling-problem","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"entropy-regularization-enabling-all-action-consistency","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"the-learning-objective","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"pcl","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"unified-parameterization-single-q-network","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"connection-to-existing-methods","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"pcl-vs-sac-residual-minimization-vs-successive-approximation","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"pcl-as-amortization","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"model-predictive-path-integral-control","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"mppi","kind":"proof:algorithm","data":"/amortization.json","url":"/amortization"},{"identifier":"mppi-as-non-amortized-optimization","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"an-alternative-euler-equation-methods","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"identifier":"summary","kind":"heading","data":"/amortization.json","url":"/amortization","implicit":true},{"kind":"page","data":"/pg.json","url":"/pg"},{"identifier":"derivative-estimation-for-stochastic-optimization","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-likelihood-ratio-method","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-reparameterization-trick","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"common-examples-of-reparameterization","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-truncated-normal-distribution","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-kumaraswamy-distribution","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-gumbel-softmax-distribution","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"numerical-analysis-of-gradient-estimators","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"score-function-methods-in-reinforcement-learning","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"leveraging-conditional-independence","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"eq:score-function-zero-mean","html_id":"eq-score-function-zero-mean","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"reinforce","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"the-surrogate-loss-perspective","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"variance-reduction-via-control-variates","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"general-control-variate-theory","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"application-to-reinforce","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"policy-grad-baseline","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"policy-grad-cv-batch","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"generalized-advantage-estimation","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"decomposing-the-monte-carlo-advantage","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"gae-as-a-shrinkage-estimator","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"eq:gae-definition","html_id":"eq-gae-definition","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"mixture-of-multi-step-estimators","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"using-gae-in-the-policy-gradient","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"policy-grad-gae-batch","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"actor-critic-as-the-lambda-0-limit","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"actor-critic-td0","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"likelihood-ratio-methods-in-reinforcement-learning","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"eq:lr-estimator","html_id":"eq-lr-estimator","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"eq:importance-weighted-surrogate","html_id":"eq-importance-weighted-surrogate","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"variance-and-the-dominance-condition","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"proximal-policy-optimization","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"from-trajectory-expectations-to-state-action-averages","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"eq:time-marginal","html_id":"eq-time-marginal","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"the-clipped-surrogate-objective","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"eq:ppo-per-sample","html_id":"eq-ppo-per-sample","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"eq:ppo-clip-population","html_id":"eq-ppo-clip-population","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"eq:ppo-clip","html_id":"eq-ppo-clip","kind":"equation","data":"/pg.json","url":"/pg"},{"identifier":"intuition-for-the-clipping-mechanism","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"ppo","kind":"proof:algorithm","data":"/pg.json","url":"/pg"},{"identifier":"the-policy-gradient-theorem","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"normalized-discounted-state-visitation-distribution","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"the-actor-critic-architecture","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"reparameterization-methods-in-reinforcement-learning","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"stochastic-value-gradients","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"svg-0-model-free-reparameterization","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"svg-1-to-svg-n-model-based-rollouts","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"svg-infty-pure-model-based-optimization","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"noise-inference-for-off-policy-learning","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"identifier":"summary","kind":"heading","data":"/pg.json","url":"/pg","implicit":true},{"kind":"page","data":"/appendix-examples.json","url":"/appendix-examples"},{"identifier":"inverted-pendulum","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"identifier":"pendulum-in-the-gym-environment","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"identifier":"heat-exchanger","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"identifier":"nuclear-reactor","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"identifier":"chemotherapy","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"identifier":"government-corruption","kind":"heading","data":"/appendix-examples.json","url":"/appendix-examples","implicit":true},{"kind":"page","data":"/appendix-ivps.json","url":"/appendix-ivps"},{"identifier":"eulers-method","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"euler-method","kind":"proof:algorithm","data":"/appendix-ivps.json","url":"/appendix-ivps"},{"identifier":"implicit-eulers-method","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"implicit-euler-method","kind":"proof:algorithm","data":"/appendix-ivps.json","url":"/appendix-ivps"},{"identifier":"stiff-odes","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"trapezoid-method","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"trapezoidal-predictor-corrector","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"collocation-methods","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"quick-primer-on-polynomials","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"orthogonal-polynomials","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"legendre-polynomials","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"chebyshev-polynomials","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"hermite-polynomials","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"collocation-conditions","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"common-numerical-integration-techniques-as-collocation-methods","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"explicit-euler-method","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"trapezoidal-method","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"runge-kutta-methods","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"identifier":"example-solving-a-simple-ode-by-collocation","kind":"heading","data":"/appendix-ivps.json","url":"/appendix-ivps","implicit":true},{"kind":"page","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"karush-kuhn-tucker-kkt-conditions","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"kkt-conditions","kind":"proof:definition","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"lagrange-multiplier-theorem","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"newtons-method","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"efficient-implementation-of-newtons-method","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"solving-equality-constrained-programs-with-newtons-method","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"demonstration","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"the-sqp-approach-taylor-expansion-and-quadratic-approximation","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"alg-sqp","kind":"proof:algorithm","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"connection-to-newtons-method-in-the-equality-constrained-case","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"sqp-for-inequality-constrained-optimization","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"alg-sqp-ineq","kind":"proof:algorithm","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"demonstration-with-jax-and-cvxpy","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"the-arrow-hurwicz-uzawa-algorithm","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"ahuz-eq","kind":"proof:algorithm","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"ahuz-full","kind":"proof:algorithm","data":"/appendix-nlp.json","url":"/appendix-nlp"},{"identifier":"projected-gradient-descent","kind":"heading","data":"/appendix-nlp.json","url":"/appendix-nlp","implicit":true},{"identifier":"proj-grad-descent-bound-constraints","kind":"proof:algorithm","data":"/appendix-nlp.json","url":"/appendix-nlp"}]}