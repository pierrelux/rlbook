
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Nonlinear Programming &#8212; Practical Reinforcement Learning: From Algorithms to Applications</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"bm": ["{\\boldsymbol #1}", 1]}, "processEscapes": true}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'appendix_nlp';</script>
    <script src="_static/iframe-modal.js?v=f72a1242"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Bibliography" href="bibliography.html" />
    <link rel="prev" title="Solving Initial Value Problems" href="appendix_ivps.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Practical Reinforcement Learning: From Algorithms to Applications</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Why This Book?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="modeling.html">Why Build a Model? For Whom?</a></li>

<li class="toctree-l1"><a class="reference internal" href="ssm.html">Dynamics Models for Decision Making</a></li>




<li class="toctree-l1"><a class="reference internal" href="simulation.html">Programs as Models</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Numerical Trajectory Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ocp.html">Discrete-Time Trajectory Optimization</a></li>


<li class="toctree-l1"><a class="reference internal" href="cocp.html">Trajectory Optimization in Continuous Time</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">From Trajectories to Policies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mpc.html">Model Predictive Control</a></li>




<li class="toctree-l1"><a class="reference internal" href="dp.html">Dynamic Programming</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning from Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="adp.html">Approximate Dynamic Programming</a></li>





<li class="toctree-l1"><a class="reference internal" href="cadp.html">Policy Parametrization Methods</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="appendix_examples.html">Example COCPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix_ivps.html">Solving Initial Value Problems</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Nonlinear Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/edit/main/appendix_nlp.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/issues/new?title=Issue%20on%20page%20%2Fappendix_nlp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/appendix_nlp.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Nonlinear Programming</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) conditions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lagrange-multiplier-theorem">Lagrange Multiplier Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-s-method">Newton’s Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficient-implementation-of-newton-s-method">Efficient Implementation of Newton’s Method</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-equality-constrained-programs-with-newton-s-method">Solving Equality Constrained Programs with Newton’s Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration">Demonstration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sqp-approach-taylor-expansion-and-quadratic-approximation">The SQP Approach: Taylor Expansion and Quadratic Approximation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connection-to-newton-s-method-in-the-equality-constrained-case">Connection to Newton’s Method in the Equality-Constrained Case</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sqp-for-inequality-constrained-optimization">SQP for Inequality-Constrained Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-with-jax-and-cvxpy">Demonstration with JAX and CVXPy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-arrow-hurwicz-uzawa-algorithm">The Arrow-Hurwicz-Uzawa algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#projected-gradient-descent">Projected Gradient Descent</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="nonlinear-programming">
<h1>Nonlinear Programming<a class="headerlink" href="#nonlinear-programming" title="Link to this heading">#</a></h1>
<p>Unless specific assumptions are made on the dynamics and cost structure, a DOCP is, in its most general form, a nonlinear mathematical program (commonly referred to as an NLP, not to be confused with Natural Language Processing). An NLP can be formulated as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{minimize } &amp; f(\mathbf{x}) \\
\text{subject to } &amp; \mathbf{g}(\mathbf{x}) \leq \mathbf{0} \\
&amp; \mathbf{h}(\mathbf{x}) = \mathbf{0}
\end{aligned}
\end{split}\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f: \mathbb{R}^n \to \mathbb{R}\)</span> is the objective function</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{g}: \mathbb{R}^n \to \mathbb{R}^m\)</span> represents inequality constraints</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{h}: \mathbb{R}^n \to \mathbb{R}^\ell\)</span> represents equality constraints</p></li>
</ul>
<p>Unlike unconstrained optimization commonly used in deep learning, the optimality of a solution in constrained optimization must consider both the objective value and constraint feasibility. To illustrate this, consider the following problem, which includes both equality and inequality constraints:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{Minimize} \quad &amp; f(x_1, x_2) = (x_1 - 1)^2 + (x_2 - 2.5)^2 \\
\text{subject to} \quad &amp; g(x_1, x_2) = (x_1 - 1)^2 + (x_2 - 1)^2 \leq 1.5, \\
&amp; h(x_1, x_2) = x_2 - \left(0.5 \sin(2 \pi x_1) + 1.5\right) = 0.
\end{align*}
\end{split}\]</div>
<p>In this example, the objective function <span class="math notranslate nohighlight">\(f(x_1, x_2)\)</span> is quadratic, the inequality constraint <span class="math notranslate nohighlight">\(g(x_1, x_2)\)</span> defines a circular feasible region centered at <span class="math notranslate nohighlight">\((1, 1)\)</span> with a radius of <span class="math notranslate nohighlight">\(\sqrt{1.5}\)</span> and the equality constraint <span class="math notranslate nohighlight">\(h(x_1, x_2)\)</span> requires <span class="math notranslate nohighlight">\(x_2\)</span> to lie on a sine wave function. The following code demonstrates the difference between the unconstrained, and constrained solutions to this problem.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>

<span class="c1"># Define the objective function</span>
<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Define the inequality constraint function</span>
<span class="k">def</span> <span class="nf">constraint</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1.5</span>

<span class="c1"># Define the gradient of the objective function</span>
<span class="k">def</span> <span class="nf">objective_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)])</span>

<span class="c1"># Define the gradient of the inequality constraint function</span>
<span class="k">def</span> <span class="nf">constraint_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)])</span>

<span class="c1"># Define the sine wave equality constraint function</span>
<span class="k">def</span> <span class="nf">sine_wave_equality_constraint</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mf">1.5</span><span class="p">)</span>

<span class="c1"># Define the gradient of the sine wave equality constraint function</span>
<span class="k">def</span> <span class="nf">sine_wave_equality_constraint_gradient</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># Define the constraints including the sine wave equality constraint</span>
<span class="n">sine_wave_constraints</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="n">constraint</span><span class="p">,</span> <span class="s1">&#39;jac&#39;</span><span class="p">:</span> <span class="n">constraint_gradient</span><span class="p">},</span>  <span class="c1"># Inequality constraint</span>
                         <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;eq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="n">sine_wave_equality_constraint</span><span class="p">,</span> <span class="s1">&#39;jac&#39;</span><span class="p">:</span> <span class="n">sine_wave_equality_constraint_gradient</span><span class="p">}]</span>  <span class="c1"># Sine wave equality constraint</span>

<span class="c1"># Define only the inequality constraint</span>
<span class="n">inequality_constraints</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="n">constraint</span><span class="p">,</span> <span class="s1">&#39;jac&#39;</span><span class="p">:</span> <span class="n">constraint_gradient</span><span class="p">}]</span>

<span class="c1"># Initial guess</span>
<span class="n">x0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.25</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]</span>

<span class="c1"># Solve the optimization problem with the sine wave equality constraint</span>
<span class="n">res_sine_wave_constraint</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">objective_gradient</span><span class="p">,</span> 
                                    <span class="n">constraints</span><span class="o">=</span><span class="n">sine_wave_constraints</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>

<span class="n">x_opt_sine_wave_constraint</span> <span class="o">=</span> <span class="n">res_sine_wave_constraint</span><span class="o">.</span><span class="n">x</span>

<span class="c1"># Solve the optimization problem with only the inequality constraint</span>
<span class="n">res_inequality_only</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">objective_gradient</span><span class="p">,</span> 
                               <span class="n">constraints</span><span class="o">=</span><span class="n">inequality_constraints</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>

<span class="n">x_opt_inequality_only</span> <span class="o">=</span> <span class="n">res_inequality_only</span><span class="o">.</span><span class="n">x</span>

<span class="c1"># Solve the unconstrained optimization problem for reference</span>
<span class="n">res_unconstrained</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">objective_gradient</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">})</span>
<span class="n">x_opt_unconstrained</span> <span class="o">=</span> <span class="n">res_unconstrained</span><span class="o">.</span><span class="n">x</span>

<span class="c1"># Generate data for visualization</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>  <span class="c1"># Objective function values</span>
<span class="n">constraint_values</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="c1"># Data for sine wave constraint</span>
<span class="n">x_sine</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<span class="n">y_sine</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">x_sine</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.5</span>

<span class="c1"># Visualization with Improved Color Scheme</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>  <span class="c1"># Heatmap for the objective function</span>

<span class="c1"># Plot all the optimal points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_opt_inequality_only</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt_inequality_only</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Optimal Solution (Inequality Only)&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_opt_sine_wave_constraint</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt_sine_wave_constraint</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;mo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Optimal Solution (Sine Wave Equality &amp; Inequality)&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_opt_unconstrained</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt_unconstrained</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;co&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Unconstrained Minimum&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="c1"># Adjust constraint boundary colors</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">constraint_values</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mf">1.5</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;navy&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">constraint_values</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Plot the sine wave equality constraint with a high contrast color</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_sine</span><span class="p">,</span> <span class="n">y_sine</span><span class="p">,</span> <span class="s1">&#39;lime&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Sine Wave Equality Constraint&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Example NLP&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;small&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">fancybox</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Set the aspect ratio to be equal so the circle appears correctly</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">,</span> <span class="n">adjustable</span><span class="o">=</span><span class="s1">&#39;box&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="_images/a95d33db6f43793ce53f2013f680c2acd46da464ed344d2fa4bbf0c0e5680982.png" src="_images/a95d33db6f43793ce53f2013f680c2acd46da464ed344d2fa4bbf0c0e5680982.png" />
</div>
</div>
<section id="karush-kuhn-tucker-kkt-conditions">
<h2>Karush-Kuhn-Tucker (KKT) conditions<a class="headerlink" href="#karush-kuhn-tucker-kkt-conditions" title="Link to this heading">#</a></h2>
<p>While this example is simple enough to convince ourselves visually of the solution to this particular problem, it falls short of providing us with actionable chracterization of what constitutes and optimal solution in general.
The Karush-Kuhn-Tucker (KKT) conditions provide us with an answer to this problem by generalizing the first-order optimality conditions in unconstrained optimization to problems involving both equality and inequality constraints.
This result relies on the construction of an auxiliary function called the Lagrangian, defined as:</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}(\mathbf{x}, \boldsymbol{\mu}, \boldsymbol{\lambda})=f(\mathbf{x})+\boldsymbol{\mu}^{\top} \mathbf{g}(\mathbf{x})+\boldsymbol{\lambda}^{\top} \mathbf{h}(\mathbf{x})\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\mu} \in \mathbb{R}^m\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\lambda} \in \mathbb{R}^\ell\)</span> are known as Lagrange multipliers. The first-order optimality conditions then state that if <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>, then there must exist corresponding Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^*\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^*\)</span> such that:</p>
<div class="proof definition admonition" id="kkt-conditions">
<p class="admonition-title"><span class="caption-number">Definition 8 </span></p>
<section class="definition-content" id="proof-content">
<ol class="arabic">
<li><p>The gradient of the Lagrangian with respect to <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> must be zero at the optimal point (<strong>stationarity</strong>):</p>
<div class="math notranslate nohighlight">
\[\nabla_x \mathcal{L}(\mathbf{x}^*, \boldsymbol{\mu}^*, \boldsymbol{\lambda}^*) = \nabla f(\mathbf{x}^*) + \sum_{i=1}^m \mu_i^* \nabla g_i(\mathbf{x}^*) + \sum_{j=1}^\ell \lambda_j^* \nabla h_j(\mathbf{x}^*) = \mathbf{0}\]</div>
<p>In the case where we only have equality constraints, this means that the gradient of the objective and that of constraint are parallel to each other at the optimum but point in opposite directions.</p>
</li>
<li><p>A valid solution of a NLP is one which satisfies all the constraints (<strong>primal feasibility</strong>)</p>
<div class="math notranslate nohighlight">
\[\begin{aligned}
   \mathbf{g}(\mathbf{x}^*) &amp;\leq \mathbf{0}, \enspace \text{and} \enspace \mathbf{h}(\mathbf{x}^*) &amp;= \mathbf{0}
   \end{aligned}\]</div>
</li>
<li><p>Furthermore, the Lagrange multipliers for <strong>inequality</strong> constraints must be non-negative (<strong>dual feasibility</strong>)</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{\mu}^* \geq \mathbf{0}\]</div>
<p>This condition stems from the fact that the inequality constraints can only push the solution in one direction.</p>
</li>
<li><p>Finally, for each inequality constraint, either the constraint is active (equality holds) or its corresponding Lagrange multiplier is zero at an optimal solution (<strong>complementary slackness</strong>)</p>
<div class="math notranslate nohighlight">
\[\mu_i^* g_i(\mathbf{x}^*) = 0, \quad \forall i = 1,\ldots,m\]</div>
</li>
</ol>
</section>
</div><p>Let’s now solve our example problem above, this time using <a class="reference external" href="https://coin-or.github.io/Ipopt/">Ipopt</a> via the <a class="reference external" href="http://www.pyomo.org/">Pyomo</a> interface so that we can access the Lagrange multipliers found by the solver.</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyomo.environ</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">pyomo.opt</span> <span class="kn">import</span> <span class="n">SolverFactory</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="c1"># Define the Pyomo model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ConcreteModel</span><span class="p">()</span>

<span class="c1"># Define the variables</span>
<span class="n">model</span><span class="o">.</span><span class="n">x1</span> <span class="o">=</span> <span class="n">Var</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="mf">1.25</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">x2</span> <span class="o">=</span> <span class="n">Var</span><span class="p">(</span><span class="n">initialize</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

<span class="c1"># Define the objective function</span>
<span class="k">def</span> <span class="nf">objective_rule</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x2</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
<span class="n">model</span><span class="o">.</span><span class="n">obj</span> <span class="o">=</span> <span class="n">Objective</span><span class="p">(</span><span class="n">rule</span><span class="o">=</span><span class="n">objective_rule</span><span class="p">,</span> <span class="n">sense</span><span class="o">=</span><span class="n">minimize</span><span class="p">)</span>

<span class="c1"># Define the inequality constraint (circle)</span>
<span class="k">def</span> <span class="nf">inequality_constraint_rule</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x1</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;=</span> <span class="mf">1.5</span>
<span class="n">model</span><span class="o">.</span><span class="n">ineq_constraint</span> <span class="o">=</span> <span class="n">Constraint</span><span class="p">(</span><span class="n">rule</span><span class="o">=</span><span class="n">inequality_constraint_rule</span><span class="p">)</span>

<span class="c1"># Define the equality constraint (sine wave) using Pyomo&#39;s math functions</span>
<span class="k">def</span> <span class="nf">equality_constraint_rule</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">x2</span> <span class="o">==</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">x1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1.5</span>
<span class="n">model</span><span class="o">.</span><span class="n">eq_constraint</span> <span class="o">=</span> <span class="n">Constraint</span><span class="p">(</span><span class="n">rule</span><span class="o">=</span><span class="n">equality_constraint_rule</span><span class="p">)</span>

<span class="c1"># Create a suffix component to capture dual values</span>
<span class="n">model</span><span class="o">.</span><span class="n">dual</span> <span class="o">=</span> <span class="n">Suffix</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="n">Suffix</span><span class="o">.</span><span class="n">IMPORT</span><span class="p">)</span>

<span class="c1"># Create a solver</span>
<span class="n">solver</span><span class="o">=</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;ipopt&#39;</span><span class="p">)</span>

<span class="c1"># Solve the problem</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tee</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Check if the solver found an optimal solution</span>
<span class="k">if</span> <span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="n">SolverStatus</span><span class="o">.</span><span class="n">ok</span> <span class="ow">and</span> 
    <span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">termination_condition</span> <span class="o">==</span> <span class="n">TerminationCondition</span><span class="o">.</span><span class="n">optimal</span><span class="p">):</span>
    
    <span class="c1"># Print the results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x1: </span><span class="si">{</span><span class="n">value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x1</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x2: </span><span class="si">{</span><span class="n">value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">x2</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="c1"># Print the objective value</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Objective value: </span><span class="si">{</span><span class="n">value</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">obj</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Print the Lagrange multipliers (dual values)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Lagrange multipliers:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">component_objects</span><span class="p">(</span><span class="n">Constraint</span><span class="p">,</span> <span class="n">active</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">c</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">[</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">dual</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">index</span><span class="p">]]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">glue</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">[</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">dual</span><span class="p">[</span><span class="n">c</span><span class="p">[</span><span class="n">index</span><span class="p">]],</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Solver did not find an optimal solution.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Solver Status: </span><span class="si">{</span><span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">status</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Termination Condition: </span><span class="si">{</span><span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">termination_condition</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING: Could not locate the &#39;ipopt&#39; executable, which is required for solver
ipopt
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ApplicationError</span><span class="g g-Whitespace">                          </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">line</span> <span class="mi">35</span>
<span class="g g-Whitespace">     </span><span class="mi">32</span> <span class="n">solver</span><span class="o">=</span><span class="n">SolverFactory</span><span class="p">(</span><span class="s1">&#39;ipopt&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span> <span class="c1"># Solve the problem</span>
<span class="ne">---&gt; </span><span class="mi">35</span> <span class="n">results</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tee</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span> <span class="c1"># Check if the solver found an optimal solution</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span> <span class="k">if</span> <span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">status</span> <span class="o">==</span> <span class="n">SolverStatus</span><span class="o">.</span><span class="n">ok</span> <span class="ow">and</span> 
<span class="g g-Whitespace">     </span><span class="mi">39</span>     <span class="n">results</span><span class="o">.</span><span class="n">solver</span><span class="o">.</span><span class="n">termination_condition</span> <span class="o">==</span> <span class="n">TerminationCondition</span><span class="o">.</span><span class="n">optimal</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">40</span>     
<span class="g g-Whitespace">     </span><span class="mi">41</span>     <span class="c1"># Print the results</span>

<span class="nn">File ~/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/pyomo/opt/base/solvers.py:534,</span> in <span class="ni">OptSolver.solve</span><span class="nt">(self, *args, **kwds)</span>
<span class="g g-Whitespace">    </span><span class="mi">531</span> <span class="k">def</span> <span class="nf">solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwds</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">532</span><span class="w">     </span><span class="sd">&quot;&quot;&quot;Solve the problem&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">534</span>     <span class="bp">self</span><span class="o">.</span><span class="n">available</span><span class="p">(</span><span class="n">exception_flag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">535</span>     <span class="c1">#</span>
<span class="g g-Whitespace">    </span><span class="mi">536</span>     <span class="c1"># If the inputs are models, then validate that they have been</span>
<span class="g g-Whitespace">    </span><span class="mi">537</span>     <span class="c1"># constructed! Collect suffix names to try and import from solution.</span>
<span class="g g-Whitespace">    </span><span class="mi">538</span>     <span class="c1">#</span>
<span class="g g-Whitespace">    </span><span class="mi">539</span>     <span class="kn">from</span> <span class="nn">pyomo.core.base.block</span> <span class="kn">import</span> <span class="n">BlockData</span>

<span class="nn">File ~/.local/pipx/venvs/jupyter-book/lib/python3.13/site-packages/pyomo/opt/solver/shellcmd.py:140,</span> in <span class="ni">SystemCallSolver.available</span><span class="nt">(self, exception_flag)</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>     <span class="k">if</span> <span class="n">exception_flag</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">139</span>         <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;No executable found for solver &#39;</span><span class="si">%s</span><span class="s2">&#39;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">140</span>         <span class="k">raise</span> <span class="n">ApplicationError</span><span class="p">(</span><span class="n">msg</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span>     <span class="k">return</span> <span class="kc">False</span>
<span class="g g-Whitespace">    </span><span class="mi">142</span> <span class="k">return</span> <span class="kc">True</span>

<span class="ne">ApplicationError</span>: No executable found for solver &#39;ipopt&#39;
</pre></div>
</div>
</div>
</details>
</div>
<p>After running the code, we find that the Lagrange multiplier associated with the inequality constraint is approximately . This very small value, close to zero, suggests that the inequality constraint is not active at the optimal solution, meaning that the solution point lies inside the circle defined by this constraint. This can be verified visually in the figure above. As for the equality constraint, its corresponding Lagrange multiplier is  and the fact that it’s non-zero indicates that this constraint is active at the optimal solution. In general when we find a Lagrange multiplier close to zero (like the one for the inequality constraint), it means that constraint is not “binding”—the optimal solution does not lie on the boundary defined by this constraint. In contrast, a non-zero Lagrange multiplier, such as the one for the equality constraint, indicates that the constraint is active and that any relaxation would directly affect the objective function’s value, as required by the stationarity condition.</p>
</section>
<section id="lagrange-multiplier-theorem">
<h2>Lagrange Multiplier Theorem<a class="headerlink" href="#lagrange-multiplier-theorem" title="Link to this heading">#</a></h2>
<p>The KKT conditions introduced above characterize the solution structure of constrained optimization problems with equality constraints. In this particular context, these conditions are referred to as the first-order optimality conditions, as part of the Lagrange multiplier theorem. Let’s just re-state them in that simpler setting:</p>
<div class="proof definition admonition" id="definition-1">
<p class="admonition-title"><span class="caption-number">Definition 9 </span> (Lagrange Multiplier Theorem)</p>
<section class="definition-content" id="proof-content">
<p>Consider the constrained optimization problem:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{\mathbf{x}} \quad &amp; f(\mathbf{x}) \\
\text{subject to} \quad &amp; h_i(\mathbf{x}) = 0, \quad i = 1, \ldots, m
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathbb{R}^n\)</span>, <span class="math notranslate nohighlight">\(f: \mathbb{R}^n \to \mathbb{R}\)</span>, and <span class="math notranslate nohighlight">\(h_i: \mathbb{R}^n \to \mathbb{R}\)</span> for <span class="math notranslate nohighlight">\(i = 1, \ldots, m\)</span>.</p>
<p>Assume that:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(h_i\)</span> are continuously differentiable functions.</p></li>
<li><p>The gradients <span class="math notranslate nohighlight">\(\nabla h_i(\mathbf{x}^*)\)</span> are linearly independent at the optimal point <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>.</p></li>
</ol>
<p>Then, there exist unique Lagrange multipliers <span class="math notranslate nohighlight">\(\lambda_i^* \in \mathbb{R}\)</span>, <span class="math notranslate nohighlight">\(i = 1, \ldots, m\)</span>, such that the following first-order optimality conditions hold:</p>
<ol class="arabic simple">
<li><p>Stationarity: <span class="math notranslate nohighlight">\(\nabla f(\mathbf{x}^*) + \sum_{i=1}^m \lambda_i^* \nabla h_i(\mathbf{x}^*) = \mathbf{0}\)</span></p></li>
<li><p>Primal feasibility: <span class="math notranslate nohighlight">\(h_i(\mathbf{x}^*) = 0\)</span>, for <span class="math notranslate nohighlight">\(i = 1, \ldots, m\)</span></p></li>
</ol>
</section>
</div><p>Note that both the stationarity and primal feasibility statements are simply saying that the derivative of the Lagrangian in either the primal or dual variables must be zero at an optimal constrained solution. In other words:</p>
<div class="math notranslate nohighlight">
\[
\nabla_{\mathbf{x}, \boldsymbol{\lambda}} L(\mathbf{x}^*, \boldsymbol{\lambda}^*) = \mathbf{0}
\]</div>
<p>Letting <span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{x}, \boldsymbol{\lambda})\)</span> stand for <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}, \boldsymbol{\lambda}} L(\mathbf{x}, \boldsymbol{\lambda})\)</span>, the Lagrange multipliers theorem tells us that an optimal primal-dual pair is actually a zero of that function <span class="math notranslate nohighlight">\(\mathbf{F}\)</span>: the derivative of the Lagrangian. Therefore, we can use this observation to craft a solution method for solving equality constrained optimization using Newton’s method, which is a numerical procedure for finding zeros of a nonlinear function.</p>
</section>
<section id="newton-s-method">
<h2>Newton’s Method<a class="headerlink" href="#newton-s-method" title="Link to this heading">#</a></h2>
<p>Newton’s method is a numerical procedure for solving root-finding problems. These are nonlinear systems of equations of the form:</p>
<p>Find <span class="math notranslate nohighlight">\(\mathbf{z}^* \in \mathbb{R}^n\)</span> such that <span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{z}^*) = \mathbf{0}\)</span></p>
<p>where <span class="math notranslate nohighlight">\(\mathbf{F}: \mathbb{R}^n \to \mathbb{R}^n\)</span> is a continuously differentiable function. Newton’s method then consists in applying the following sequence of iterates:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}^{k+1} = \mathbf{z}^k - [\nabla \mathbf{F}(\mathbf{z}^k)]^{-1} \mathbf{F}(\mathbf{z}^k)
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{z}^k\)</span> is the k-th iterate, and <span class="math notranslate nohighlight">\(\nabla \mathbf{F}(\mathbf{z}^k)\)</span> is the Jacobian matrix of <span class="math notranslate nohighlight">\(\mathbf{F}\)</span> evaluated at <span class="math notranslate nohighlight">\(\mathbf{z}^k\)</span>.</p>
<p>Newton’s method exhibits local quadratic convergence: if the initial guess <span class="math notranslate nohighlight">\(\mathbf{z}^0\)</span> is sufficiently close to the true solution <span class="math notranslate nohighlight">\(\mathbf{z}^*\)</span>, and <span class="math notranslate nohighlight">\(\nabla \mathbf{F}(\mathbf{z}^*)\)</span> is nonsingular, the method converges quadratically to <span class="math notranslate nohighlight">\(\mathbf{z}^*\)</span> <span id="id1">[<a class="reference internal" href="bibliography.html#id8" title="J. M. Ortega and W. C. Rheinboldt. Iterative Solution of Nonlinear Equations in Several Variables. Computer Science and Applied Mathematics. Academic Press, New York, 1970.">32</a>]</span>. However, the method is sensitive to the initial guess; if it’s too far from the desired solution, Newton’s method might fail to converge or converge to a different root. To mitigate this problem, a set of techniques known as numerical continuation methods <span id="id2">[<a class="reference internal" href="bibliography.html#id9" title="E. L. Allgower and K. Georg. Numerical Continuation Methods: An Introduction. Volume 13 of Springer Series in Computational Mathematics. Springer-Verlag, Berlin, Heidelberg, 1990.">2</a>]</span> have been developed. These methods effectively enlarge the basin of attraction of Newton’s method by solving a sequence of related problems, progressing from an easy one to the target problem. This approach is reminiscent of several concepts in machine learning and statistical inference: curriculum learning in machine learning, where models are trained on increasingly complex data; tempering in Markov Chain Monte Carlo (MCMC) samplers, which gradually adjusts the target distribution to improve mixing; and modern diffusion models, which use a similar concept of gradually transforming noise into structured data.</p>
<section id="efficient-implementation-of-newton-s-method">
<h3>Efficient Implementation of Newton’s Method<a class="headerlink" href="#efficient-implementation-of-newton-s-method" title="Link to this heading">#</a></h3>
<p>Note that each step of Newton’s method involves computing the inverse of a Jacobian matrix. However, a cardinal rule in numerical linear algebra is to avoid computing matrix inverses explicitly: rarely, if ever, should there be a <code class="docutils literal notranslate"><span class="pre">np.lindex.inv</span></code> in your code. Instead, the numerically stable and computationally efficient approach is to solve a linear system of equations at each step.
Given the Newton’s method iterate:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}^{k+1} = \mathbf{z}^k - [\nabla \mathbf{F}(\mathbf{z}^k)]^{-1} \mathbf{F}(\mathbf{z}^k)
\]</div>
<p>We can reformulate this as a two-step procedure:</p>
<ol class="arabic simple">
<li><p>Solve the linear system: <span class="math notranslate nohighlight">\(\underbrace{[\nabla \mathbf{F}(\mathbf{z}^k)]}_{\mathbf{A}} \Delta \mathbf{z}^k = -\mathbf{F}(\mathbf{z}^k)\)</span></p></li>
<li><p>Update: <span class="math notranslate nohighlight">\(\mathbf{z}^{k+1} = \mathbf{z}^k + \Delta \mathbf{z}^k\)</span></p></li>
</ol>
<p>The structure of the linear system in step 1 often allows for specialized solution methods. In the context of automatic differentiation, matrix-free linear solvers are particularly useful. These solvers can find a solution without explicitly forming the matrix A, requiring only the ability to evaluate matrix-vector or vector-matrix products. Typical examples of such methods include classical matrix-splitting methods (e.g., Richardson iteration) or conjugate gradient methods through <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.cg.html"><code class="docutils literal notranslate"><span class="pre">sparse.linalg.cg</span></code></a> for example. Another useful method is the Generalized Minimal Residual method (GMRES) implemented in SciPy via <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.gmres.html"><code class="docutils literal notranslate"><span class="pre">sparse.linalg.gmres</span></code></a>, which is useful when facing non-symmetric and indefinite systems.</p>
<p>By inspecting the structure of matrix <span class="math notranslate nohighlight">\(\mathbf{A}\)</span> in the specific application where the function <span class="math notranslate nohighlight">\(\mathbf{F}\)</span> is the derivative of the Lagrangian, we will also uncover an important structure known as the KKT matrix. This structure will then allow us to derive a Quadratic Programming (QP) sub-problem as part of a larger iterative procedure for solving equality and inequality constrained problems via Sequential Quadratic Programming (SQP).</p>
</section>
</section>
<section id="solving-equality-constrained-programs-with-newton-s-method">
<h2>Solving Equality Constrained Programs with Newton’s Method<a class="headerlink" href="#solving-equality-constrained-programs-with-newton-s-method" title="Link to this heading">#</a></h2>
<p>To solve equality-constrained optimization problems using Newton’s method, we begin by recognizing that the problem reduces to finding a zero of the function <span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{z}) = \nabla_{\mathbf{x}, \boldsymbol{\lambda}} L(\mathbf{x}, \boldsymbol{\lambda})\)</span>. Here, <span class="math notranslate nohighlight">\(\mathbf{F}\)</span> represents the derivative of the Lagrangian function, and <span class="math notranslate nohighlight">\(\mathbf{z} = (\mathbf{x}, \boldsymbol{\lambda})\)</span> combines both the primal variables <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and the dual variables (Lagrange multipliers) <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span>. Explicitly, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{F}(\mathbf{z}) = \begin{bmatrix} \nabla_{\mathbf{x}} L(\mathbf{x}, \boldsymbol{\lambda}) \\ \mathbf{h}(\mathbf{x}) \end{bmatrix} = \begin{bmatrix} \nabla f(\mathbf{x}) + \sum_{i=1}^m \lambda_i \nabla h_i(\mathbf{x}) \\ \mathbf{h}(\mathbf{x}) \end{bmatrix}.
\end{split}\]</div>
<p>Newton’s method involves linearizing <span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{z})\)</span> around the current iterate <span class="math notranslate nohighlight">\(\mathbf{z}^k = (\mathbf{x}^k, \boldsymbol{\lambda}^k)\)</span> and then solving the resulting linear system. At each iteration <span class="math notranslate nohighlight">\(k\)</span>, Newton’s method updates the current estimate by solving the linear system:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{z}^{k+1} = \mathbf{z}^k - [\nabla \mathbf{F}(\mathbf{z}^k)]^{-1} \mathbf{F}(\mathbf{z}^k).
\]</div>
<p>However, instead of explicitly inverting the Jacobian matrix <span class="math notranslate nohighlight">\(\nabla \mathbf{F}(\mathbf{z}^k)\)</span>, we solve the linear system:</p>
<div class="math notranslate nohighlight">
\[
\underbrace{\nabla \mathbf{F}(\mathbf{z}^k)}_{\mathbf{A}} \Delta \mathbf{z}^k = -\mathbf{F}(\mathbf{z}^k),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta \mathbf{z}^k = (\Delta \mathbf{x}^k, \Delta \boldsymbol{\lambda}^k)\)</span> represents the Newton step for the primal and dual variables. Substituting the expression for <span class="math notranslate nohighlight">\(\mathbf{F}(\mathbf{z})\)</span> and its Jacobian, the system becomes:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
\nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k) &amp; \nabla \mathbf{h}(\mathbf{x}^k)^T \\
\nabla \mathbf{h}(\mathbf{x}^k) &amp; \mathbf{0}
\end{bmatrix}
\begin{bmatrix}
\Delta \mathbf{x}^k \\
\Delta \boldsymbol{\lambda}^k
\end{bmatrix}
=
-
\begin{bmatrix}
\nabla f(\mathbf{x}^k) + \nabla \mathbf{h}(\mathbf{x}^k)^T \boldsymbol{\lambda}^k \\
\mathbf{h}(\mathbf{x}^k)
\end{bmatrix}.
\end{split}\]</div>
<p>The matrix on the left-hand side is known as the KKT matrix, as it stems from the Karush-Kuhn-Tucker conditions for this optimization problem
The solution of this system provides the updates <span class="math notranslate nohighlight">\(\Delta \mathbf{x}^k\)</span> and <span class="math notranslate nohighlight">\(\Delta \boldsymbol{\lambda}^k\)</span>, which are then used to update the primal and dual variables:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}^{k+1} = \mathbf{x}^k + \Delta \mathbf{x}^k, \quad \boldsymbol{\lambda}^{k+1} = \boldsymbol{\lambda}^k + \Delta \boldsymbol{\lambda}^k.
\]</div>
<section id="demonstration">
<h3>Demonstration<a class="headerlink" href="#demonstration" title="Link to this heading">#</a></h3>
<p>The following code demonstates how we can implement this idea in Jax. In this demonstration, we are minimizing a quadratic objective function subject to a single equality constraint, a problem formally stated as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{x \in \mathbb{R}^2} \quad &amp; f(x) = (x_1 - 2)^2 + (x_2 - 1)^2 \\
\text{subject to} \quad &amp; h(x) = x_1^2 + x_2^2 - 1 = 0
\end{aligned}
\end{split}\]</div>
<p>Geometrically speaking, the constraint <span class="math notranslate nohighlight">\(h(x)\)</span> describes a unit circle centered at the origin. To solve this problem using the method of Lagrange multipliers, we form the Lagrangian:</p>
<div class="math notranslate nohighlight">
\[
L(x, \lambda) = f(x) + \lambda h(x) = (x_1 - 2)^2 + (x_2 - 1)^2 + \lambda(x_1^2 + x_2^2 - 1)
\]</div>
<p>For this particular problem, it happens so that we can also find an analytical without even having to use Newton’s method. From the first-order optimality conditions, we obtain the following linear system of equations:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
   2(x_1 - 2) + 2\lambda x_1 &amp;= 0 \\
   2(x_2 - 1) + 2\lambda x_2 &amp;= 0 \\
   x_1^2 + x_2^2 - 1 &amp;= 0\\
\end{align*}\]</div>
<p>From the first two equations, we then get:</p>
<div class="math notranslate nohighlight">
\[x_1 = \frac{2}{1 + \lambda}, \quad x_2 = \frac{1}{1 + \lambda}\]</div>
<p>which we can substitute these into the 3rd constraint equation to obtain:</p>
<div class="math notranslate nohighlight">
\[(\frac{2}{1 + \lambda})^2 + (\frac{1}{1 + \lambda})^2 = 1 \Leftrightarrow \lambda = \sqrt{5} - 1$\]</div>
<p>This value of the Lagrange multiplier can then be backsubstituted into the above equations to obtain <span class="math notranslate nohighlight">\(x_1 = \frac{2}{\sqrt{5}}\)</span> and <span class="math notranslate nohighlight">\(x_2 =  \frac{1}{\sqrt{5}}\)</span>.
We can verify numerically (and visually on the following graph) that the point <span class="math notranslate nohighlight">\((2/\sqrt{5}, 1/\sqrt{5})\)</span> is indeed the point on the unit circle closest to <span class="math notranslate nohighlight">\((2, 1)\)</span>.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">jacfwd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the objective function and constraint</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># Lagrangian</span>
<span class="k">def</span> <span class="nf">L</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">lambda_</span> <span class="o">*</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Gradient and Hessian of Lagrangian</span>
<span class="n">grad_L_x</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">grad_L_lambda</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">hess_L_xx</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">grad_L_x</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">hess_L_xlambda</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">grad_L_x</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Newton&#39;s method</span>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">newton_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">):</span>
    <span class="n">grad_x</span> <span class="o">=</span> <span class="n">grad_L_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
    <span class="n">grad_lambda</span> <span class="o">=</span> <span class="n">grad_L_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
    <span class="n">hess_xx</span> <span class="o">=</span> <span class="n">hess_L_xx</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
    <span class="n">hess_xlambda</span> <span class="o">=</span> <span class="n">hess_L_xlambda</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Construct the full KKT matrix</span>
    <span class="n">kkt_matrix</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">block</span><span class="p">([</span>
        <span class="p">[</span><span class="n">hess_xx</span><span class="p">,</span> <span class="n">hess_xlambda</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
        <span class="p">[</span><span class="n">hess_xlambda</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.0</span><span class="p">]])]</span>
    <span class="p">])</span>
    
    <span class="c1"># Construct the right-hand side</span>
    <span class="n">rhs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="o">-</span><span class="n">grad_x</span><span class="p">,</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">grad_lambda</span><span class="p">])])</span>
    
    <span class="c1"># Solve the KKT system</span>
    <span class="n">delta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">kkt_matrix</span><span class="p">,</span> <span class="n">rhs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">delta</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">lambda_</span> <span class="o">+</span> <span class="n">delta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">solve_constrained_optimization</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">x_new</span><span class="p">,</span> <span class="n">lambda_new</span> <span class="o">=</span> <span class="n">newton_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_new</span> <span class="o">-</span> <span class="n">x</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">lambda_new</span> <span class="o">-</span> <span class="n">lambda_</span><span class="p">])]))</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">lambda_new</span>
    
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>

<span class="c1"># Analytical solution</span>
<span class="k">def</span> <span class="nf">analytical_solution</span><span class="p">():</span>
    <span class="n">x1</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">x2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">lambda_opt</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]),</span> <span class="n">lambda_opt</span>

<span class="c1"># Solve the problem numerically</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">lambda0</span> <span class="o">=</span> <span class="mf">0.0</span>
<span class="n">x_opt_num</span><span class="p">,</span> <span class="n">lambda_opt_num</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="n">solve_constrained_optimization</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">)</span>

<span class="c1"># Compute analytical solution</span>
<span class="n">x_opt_ana</span><span class="p">,</span> <span class="n">lambda_opt_ana</span> <span class="o">=</span> <span class="n">analytical_solution</span><span class="p">()</span>

<span class="c1"># Verify the result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Numerical Solution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Constraint violation: </span><span class="si">{</span><span class="n">g</span><span class="p">(</span><span class="n">x_opt_num</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Objective function value: </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt_num</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Analytical Solution:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Constraint violation: </span><span class="si">{</span><span class="n">g</span><span class="p">(</span><span class="n">x_opt_ana</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Objective function value: </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt_ana</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Comparison:&quot;</span><span class="p">)</span>
<span class="n">x_diff</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">x_opt_num</span> <span class="o">-</span> <span class="n">x_opt_ana</span><span class="p">)</span>
<span class="n">lambda_diff</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lambda_opt_num</span> <span class="o">-</span> <span class="n">lambda_opt_ana</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Difference in x: </span><span class="si">{</span><span class="n">x_diff</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Difference in lambda: </span><span class="si">{</span><span class="n">lambda_diff</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Precision test</span>
<span class="n">rtol</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># relative tolerance</span>
<span class="n">atol</span> <span class="o">=</span> <span class="mf">1e-8</span>  <span class="c1"># absolute tolerance</span>

<span class="n">x_close</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">x_opt_num</span><span class="p">,</span> <span class="n">x_opt_ana</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">)</span>
<span class="n">lambda_close</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">lambda_opt_num</span><span class="p">,</span> <span class="n">lambda_opt_ana</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Precision Test:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;x values are close: </span><span class="si">{</span><span class="n">x_close</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;lambda values are close: </span><span class="si">{</span><span class="n">lambda_close</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">x_close</span> <span class="ow">and</span> <span class="n">lambda_close</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The numerical solution matches the analytical solution within the specified tolerance.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The numerical solution differs from the analytical solution more than the specified tolerance.&quot;</span><span class="p">)</span>

<span class="c1"># Visualize the result</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create a mesh for the contour plot</span>
<span class="n">x1_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x1_range</span><span class="p">,</span> <span class="n">x2_range</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">f</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">x1_range</span><span class="p">]</span> <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">x2_range</span><span class="p">])</span>

<span class="c1"># Plot filled contours</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Objective Function Value&#39;</span><span class="p">)</span>

<span class="c1"># Plot the constraint</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Constraint&#39;</span><span class="p">)</span>

<span class="c1"># Plot the optimal points (numerical and analytical) and initial point</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_opt_num</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt_num</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Numerical Optimal Point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_opt_ana</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt_ana</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Analytical Optimal Point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Initial Point&#39;</span><span class="p">)</span>

<span class="c1"># Add labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Constrained Optimization: Numerical vs Analytical Solution&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Set the axis limits explicitly</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="the-sqp-approach-taylor-expansion-and-quadratic-approximation">
<h2>The SQP Approach: Taylor Expansion and Quadratic Approximation<a class="headerlink" href="#the-sqp-approach-taylor-expansion-and-quadratic-approximation" title="Link to this heading">#</a></h2>
<p>Sequential Quadratic Programming (SQP) tackles the problem of solving constrained programs by iteratively solving a sequence of simpler subproblems. Specifically, these subproblems are quadratic programs (QPs) that approximate the original problem around the current iterate by using a quadratic model of the objective function and a linear model of the constraints. Suppose we have the following optimization problem with equality constraints:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{\mathbf{x}} \quad &amp; f(\mathbf{x}) \\
\text{subject to} \quad &amp; \mathbf{h}(\mathbf{x}) = \mathbf{0}.
\end{aligned}
\end{split}\]</div>
<p>At each iteration <span class="math notranslate nohighlight">\(k\)</span>, we approximate the objective function <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> using a second-order Taylor expansion around the current iterate <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span>. The standard Taylor expansion for <span class="math notranslate nohighlight">\(f\)</span> would be:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
f(\mathbf{x}) \approx f(\mathbf{x}^k) + \nabla f(\mathbf{x}^k)^T (\mathbf{x} - \mathbf{x}^k) + \frac{1}{2} (\mathbf{x} - \mathbf{x}^k)^T \nabla^2 f(\mathbf{x}^k) (\mathbf{x} - \mathbf{x}^k).
\end{align*}\]</div>
<p>This expansion uses the <strong>Hessian of the objective function</strong> <span class="math notranslate nohighlight">\(\nabla^2 f(\mathbf{x}^k)\)</span> to capture the curvature of <span class="math notranslate nohighlight">\(f\)</span>. However, in the context of constrained optimization, we also need to account for the effect of the constraints on the local behavior of the solution. If we were to use only <span class="math notranslate nohighlight">\(\nabla^2 f(\mathbf{x}^k)\)</span>, we would not capture the influence of the constraints on the curvature of the feasible region. The resulting subproblem might then lead to steps that violate the constraints or are less effective in achieving convergence. The choice that we make instead is to use the Hessian of the Lagrangian, <span class="math notranslate nohighlight">\(\nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k)\)</span>, leading to the following quadratic model:</p>
<div class="math notranslate nohighlight">
\[
f(\mathbf{x}) \approx f(\mathbf{x}^k) + \nabla f(\mathbf{x}^k)^T (\mathbf{x} - \mathbf{x}^k) + \frac{1}{2} (\mathbf{x} - \mathbf{x}^k)^T \nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k) (\mathbf{x} - \mathbf{x}^k).
\]</div>
<p>Similarly, the equality constraints <span class="math notranslate nohighlight">\(\mathbf{h}(\mathbf{x})\)</span> are linearized around <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{h}(\mathbf{x}) \approx \mathbf{h}(\mathbf{x}^k) + \nabla \mathbf{h}(\mathbf{x}^k) (\mathbf{x} - \mathbf{x}^k).
\]</div>
<p>Combining these approximations, we obtain a Quadratic Programming (QP) subproblem, which approximates our original problem locally at <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span> but is easier to solve:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\text{Minimize} \quad &amp; \nabla f(\mathbf{x}^k)^T \Delta \mathbf{x} + \frac{1}{2} \Delta \mathbf{x}^T \nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k) \Delta \mathbf{x} \\
\text{subject to} \quad &amp; \nabla \mathbf{h}(\mathbf{x}^k) \Delta \mathbf{x} + \mathbf{h}(\mathbf{x}^k) = \mathbf{0},
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta \mathbf{x} = \mathbf{x} - \mathbf{x}^k\)</span>. The QP subproblem solved at each iteration focuses on finding the optimal step direction <span class="math notranslate nohighlight">\(\Delta \mathbf{x}\)</span> for the primal variables.
While solving this QP, we obtain not only the step <span class="math notranslate nohighlight">\(\Delta \mathbf{x}\)</span> but also the associated Lagrange multipliers for the QP subproblem, which correspond to an updated dual variable vector <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1}\)</span>. More specifically, after solving the QP, we use <span class="math notranslate nohighlight">\(\Delta \mathbf{x}^k\)</span> to update the primal variables:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\mathbf{x}^{k+1} = \mathbf{x}^k + \Delta \mathbf{x}^k.
\end{align*}\]</div>
<p>Simultaneously, the Lagrange multipliers from the QP provide the updated dual variables <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1}\)</span>.
We summarize the SQP algorithm in the following pseudo-code:</p>
<div class="proof algorithm admonition" id="alg-sqp">
<p class="admonition-title"><span class="caption-number">Algorithm 48 </span> (Sequential Quadratic Programming (SQP))</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Initial estimate <span class="math notranslate nohighlight">\(\mathbf{x}^0\)</span>, initial Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^0\)</span>, tolerance <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>.</p>
<p><strong>Output:</strong> Solution <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>, Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^*\)</span>.</p>
<p><strong>Procedure:</strong></p>
<ol class="arabic">
<li><p><strong>Compute the QP Solution:</strong> Solve the QP subproblem to obtain <span class="math notranslate nohighlight">\(\Delta \mathbf{x}^k\)</span>. The QP solver also provides the updated Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1}\)</span> associated with the constraints.</p></li>
<li><p><strong>Update the Estimates:</strong> Update the primal variables:</p>
<div class="math notranslate nohighlight">
\[
   \mathbf{x}^{k+1} = \mathbf{x}^k + \Delta \mathbf{x}^k.
   \]</div>
<p>Set the dual variables to the updated values <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1}\)</span> from the QP solution.</p>
</li>
<li><p><strong>Repeat Until Convergence:</strong> Continue iterating until <span class="math notranslate nohighlight">\(\|\Delta \mathbf{x}^k\| &lt; \epsilon\)</span> and the KKT conditions are satisfied.</p></li>
</ol>
</section>
</div><section id="connection-to-newton-s-method-in-the-equality-constrained-case">
<h3>Connection to Newton’s Method in the Equality-Constrained Case<a class="headerlink" href="#connection-to-newton-s-method-in-the-equality-constrained-case" title="Link to this heading">#</a></h3>
<p>The QP subproblem in SQP is directly related to applying Newton’s method for equality-constrained optimization. To see this, note that the KKT matrix of the QP subproblem is:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\begin{bmatrix}
\nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k) &amp; \nabla \mathbf{h}(\mathbf{x}^k)^T \\
\nabla \mathbf{h}(\mathbf{x}^k) &amp; \mathbf{0}
\end{bmatrix}
\begin{bmatrix}
\Delta \mathbf{x}^k \\
\Delta \boldsymbol{\lambda}^k
\end{bmatrix}
=
-
\begin{bmatrix}
\nabla f(\mathbf{x}^k) + \nabla \mathbf{h}(\mathbf{x}^k)^T \boldsymbol{\lambda}^k \\
\mathbf{h}(\mathbf{x}^k)
\end{bmatrix}
\end{align*}\]</div>
<p>This is exactly the same linear system that have to solve when applying Newton’s method to the KKT conditions of the original program! Thus, solving the QP subproblem at each iteration of SQP is equivalent to taking a Newton step on the KKT conditions of the original nonlinear problem.</p>
</section>
</section>
<section id="sqp-for-inequality-constrained-optimization">
<h2>SQP for Inequality-Constrained Optimization<a class="headerlink" href="#sqp-for-inequality-constrained-optimization" title="Link to this heading">#</a></h2>
<p>So far, we’ve applied the ideas behind Sequential Quadratic Programming (SQP) to problems with only equality constraints. Now, let’s extend this framework to handle optimization problems that also include inequality constraints.
Consider a general nonlinear optimization problem that includes both equality and inequality constraints:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\min_{\mathbf{x}} \quad &amp; f(\mathbf{x}) \\
\text{subject to} \quad &amp; \mathbf{g}(\mathbf{x}) \leq \mathbf{0}, \\
&amp; \mathbf{h}(\mathbf{x}) = \mathbf{0}.
\end{align*}\]</div>
<p>As we did earlier, we approximate this problem by constructing a quadratic approximation to the objective and a linearization of the constraints. QP subproblem at each iteration is then formulated as:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\text{Minimize} \quad &amp; \nabla f(\mathbf{x}^k)^T \Delta \mathbf{x} + \frac{1}{2} \Delta \mathbf{x}^T \nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k, \boldsymbol{\nu}^k) \Delta \mathbf{x} \\
\text{subject to} \quad &amp; \nabla \mathbf{g}(\mathbf{x}^k) \Delta \mathbf{x} + \mathbf{g}(\mathbf{x}^k) \leq \mathbf{0}, \\
&amp; \nabla \mathbf{h}(\mathbf{x}^k) \Delta \mathbf{x} + \mathbf{h}(\mathbf{x}^k) = \mathbf{0},
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(\Delta \mathbf{x} = \mathbf{x} - \mathbf{x}^k\)</span> represents the step direction for the primal variables. The following pseudocode outlines the steps involved in applying SQP to a problem with both equality and inequality constraints:</p>
<div class="proof algorithm admonition" id="alg-sqp-ineq">
<p class="admonition-title"><span class="caption-number">Algorithm 49 </span> (Sequential Quadratic Programming (SQP) with Inequality Constraints)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Initial estimate <span class="math notranslate nohighlight">\(\mathbf{x}^0\)</span>, initial multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^0, \boldsymbol{\nu}^0\)</span>, tolerance <span class="math notranslate nohighlight">\(\epsilon &gt; 0\)</span>.</p>
<p><strong>Output:</strong> Solution <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>, Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^*, \boldsymbol{\nu}^*\)</span>.</p>
<p><strong>Procedure:</strong></p>
<ol class="arabic">
<li><p><strong>Initialization:</strong>
Set <span class="math notranslate nohighlight">\(k = 0\)</span>.</p></li>
<li><p><strong>Repeat:</strong></p>
<p>a. <strong>Construct the QP Subproblem:</strong>
Formulate the QP subproblem using the current iterate <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^k\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{\nu}^k\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
   \begin{aligned}
   \text{Minimize} \quad &amp; \nabla f(\mathbf{x}^k)^T \Delta \mathbf{x} + \frac{1}{2} \Delta \mathbf{x}^T \nabla^2_{\mathbf{x}\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k, \boldsymbol{\nu}^k) \Delta \mathbf{x} \\
   \text{subject to} \quad &amp; \nabla \mathbf{g}(\mathbf{x}^k) \Delta \mathbf{x} + \mathbf{g}(\mathbf{x}^k) \leq \mathbf{0}, \\
   &amp; \nabla \mathbf{h}(\mathbf{x}^k) \Delta \mathbf{x} + \mathbf{h}(\mathbf{x}^k) = \mathbf{0}.
   \end{aligned}
   \end{split}\]</div>
<p>b. <strong>Solve the QP Subproblem:</strong>
Solve for <span class="math notranslate nohighlight">\(\Delta \mathbf{x}^k\)</span> and obtain the updated Lagrange multipliers <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\nu}^{k+1}\)</span>.</p>
<p>c. <strong>Update the Estimates:</strong>
Update the primal variables and multipliers:</p>
<div class="math notranslate nohighlight">
\[
   \mathbf{x}^{k+1} = \mathbf{x}^k + \Delta \mathbf{x}^k.
   \]</div>
<p>d. <strong>Check for Convergence:</strong>
If <span class="math notranslate nohighlight">\(\|\Delta \mathbf{x}^k\| &lt; \epsilon\)</span> and the KKT conditions are satisfied, stop. Otherwise, set <span class="math notranslate nohighlight">\(k = k + 1\)</span> and repeat.</p>
</li>
<li><p><strong>Return:</strong>
<span class="math notranslate nohighlight">\(\mathbf{x}^* = \mathbf{x}^{k+1}, \boldsymbol{\lambda}^* = \boldsymbol{\lambda}^{k+1}, \boldsymbol{\nu}^* = \boldsymbol{\nu}^{k+1}\)</span>.</p></li>
</ol>
</section>
</div><section id="demonstration-with-jax-and-cvxpy">
<h3>Demonstration with JAX and CVXPy<a class="headerlink" href="#demonstration-with-jax-and-cvxpy" title="Link to this heading">#</a></h3>
<p>Consider the following equality and inequality-constrained problem:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\min_{x \in \mathbb{R}^2} \quad &amp; f(x) = (x_1 - 2)^2 + (x_2 - 1)^2 \\
\text{subject to} \quad &amp; g(x) = x_1^2 - x_2 \leq 0  \\
&amp; h(x) = x_1^2 + x_2^2 - 1 = 0
\end{align*}\]</div>
<p>This example builds on our previous one but adds a parabola-shaped inequality constraint. We require our solution to lie not only on the circle defining our equality constraint but also below the parabola. To solve the QP subproblem, we will be using the <a class="reference external" href="https://www.cvxpy.org/">CVXPY</a> package. While the Lagrangian and derivatives could be computed easily by hand, we use <a class="reference external" href="https://jax.readthedocs.io/">JAX</a> for generality:</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">jacfwd</span><span class="p">,</span> <span class="n">hessian</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cvxpy</span> <span class="k">as</span> <span class="nn">cp</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the objective function and constraints</span>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">h</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>  <span class="c1"># Corrected inequality constraint: x[1] &lt;= x[0]^2</span>

<span class="c1"># Compute gradients and Jacobians using JAX</span>
<span class="n">grad_f</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
<span class="n">hess_f</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">hessian</span><span class="p">(</span><span class="n">f</span><span class="p">))</span>
<span class="n">jac_g</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
<span class="n">jac_h</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">lagrangian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">hess_L</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">hessian</span><span class="p">(</span><span class="n">lagrangian</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">solve_qp_subproblem</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nu</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">delta_x</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    
    <span class="c1"># Convert JAX arrays to numpy for cvxpy</span>
    <span class="n">grad_f_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">grad_f</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">hess_L_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hess_L</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nu</span><span class="p">))</span>
    <span class="n">jac_g_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">jac_g</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">jac_h_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">jac_h</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">g_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">h_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    
    <span class="n">obj</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Minimize</span><span class="p">(</span><span class="n">grad_f_np</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">delta_x</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">cp</span><span class="o">.</span><span class="n">quad_form</span><span class="p">(</span><span class="n">delta_x</span><span class="p">,</span> <span class="n">hess_L_np</span><span class="p">))</span>
    
    <span class="n">constraints</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">jac_g_np</span> <span class="o">@</span> <span class="n">delta_x</span> <span class="o">+</span> <span class="n">g_np</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">jac_h_np</span> <span class="o">@</span> <span class="n">delta_x</span> <span class="o">+</span> <span class="n">h_np</span> <span class="o">&lt;=</span> <span class="mi">0</span>
    <span class="p">]</span>
    
    <span class="n">prob</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">Problem</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">constraints</span><span class="p">)</span>
    <span class="n">prob</span><span class="o">.</span><span class="n">solve</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">delta_x</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">constraints</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dual_value</span><span class="p">,</span> <span class="n">prob</span><span class="o">.</span><span class="n">constraints</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">dual_value</span>

<span class="k">def</span> <span class="nf">sqp</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
        <span class="n">delta_x</span><span class="p">,</span> <span class="n">new_lambda</span><span class="p">,</span> <span class="n">new_nu</span> <span class="o">=</span> <span class="n">solve_qp_subproblem</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">delta_x</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">tol</span><span class="p">:</span>
            <span class="k">break</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">delta_x</span>
        <span class="n">lambda_</span> <span class="o">=</span> <span class="n">new_lambda</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="n">new_nu</span>
        
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span>

<span class="c1"># Initial point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>

<span class="c1"># Solve using SQP</span>
<span class="n">x_opt</span><span class="p">,</span> <span class="n">lambda_opt</span><span class="p">,</span> <span class="n">nu_opt</span><span class="p">,</span> <span class="n">iterations</span> <span class="o">=</span> <span class="n">sqp</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal x: </span><span class="si">{</span><span class="n">x_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal lambda: </span><span class="si">{</span><span class="n">lambda_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal nu: </span><span class="si">{</span><span class="n">nu_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iterations: </span><span class="si">{</span><span class="n">iterations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualize the result</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create a mesh for the contour plot</span>
<span class="n">x1_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x1_range</span><span class="p">,</span> <span class="n">x2_range</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">f</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">x1_range</span><span class="p">]</span> <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">x2_range</span><span class="p">])</span>

<span class="c1"># Plot filled contours</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Objective Function Value&#39;</span><span class="p">)</span>

<span class="c1"># Plot the equality constraint</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x1_eq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">x2_eq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_eq</span><span class="p">,</span> <span class="n">x2_eq</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Equality Constraint&#39;</span><span class="p">)</span>

<span class="c1"># Plot the inequality constraint and shade the feasible region</span>
<span class="n">x1_ineq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2_ineq</span> <span class="o">=</span> <span class="n">x1_ineq</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_ineq</span><span class="p">,</span> <span class="n">x2_ineq</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Inequality Constraint&#39;</span><span class="p">)</span>

<span class="c1"># Shade the feasible region for the inequality constraint</span>
<span class="n">x2_lower</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x2_ineq</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x1_ineq</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">x2_lower</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hatch</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">/...&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Feasible Region&#39;</span><span class="p">)</span>

<span class="c1"># Plot the optimal and initial points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Optimal Point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Initial Point&#39;</span><span class="p">)</span>

<span class="c1"># Add labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;SQP for Inequality Constraints with CVXPY and JAX&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Set the axis limits explicitly</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Verify the result</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Equality constraint violation: </span><span class="si">{</span><span class="n">g</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inequality constraint violation: </span><span class="si">{</span><span class="n">h</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Objective function value: </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
<section id="the-arrow-hurwicz-uzawa-algorithm">
<h2>The Arrow-Hurwicz-Uzawa algorithm<a class="headerlink" href="#the-arrow-hurwicz-uzawa-algorithm" title="Link to this heading">#</a></h2>
<p>While the SQP method addresses constrained optimization problems by sequentially solving quadratic subproblems, an alternative approach emerges from viewing constrained optimization as a min-max problem. This perspective leads to a simpler algorithm, originally introduced by the Arrow-Hurwicz-Uzawa <span id="id3">[<a class="reference internal" href="bibliography.html#id10" title="Kenneth J Arrow, Leonid Hurwicz, and Hirofumi Uzawa. Studies in linear and non-linear programming. Stanford University Press, 1958.">3</a>]</span>. Consider the following general constrained optimization problem encompassing both equality and inequality constraints:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{\mathbf{x}} \quad &amp; f(\mathbf{x}) \\
\text{subject to} \quad &amp; \mathbf{g}(\mathbf{x}) \leq \mathbf{0} \\
&amp; \mathbf{h}(\mathbf{x}) = \mathbf{0}
\end{aligned}
\end{split}\]</div>
<p>Using the Lagrangian function <span class="math notranslate nohighlight">\(L(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu}) = f(\mathbf{x}) + \boldsymbol{\mu}^T \mathbf{g}(\mathbf{x}) + \boldsymbol{\lambda}^T \mathbf{h}(\mathbf{x})\)</span>, we can reformulate this problem as the following min-max problem:</p>
<div class="math notranslate nohighlight">
\[
\min_{\mathbf{x}} \max_{\boldsymbol{\lambda}, \boldsymbol{\mu} \geq 0} L(\mathbf{x}, \boldsymbol{\lambda}, \boldsymbol{\mu})
\]</div>
<p>The role of each component in this min-max structure can be understood as follows:</p>
<ol class="arabic simple">
<li><p>The outer minimization over <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> finds the feasible point that minimizes the objective function <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span>.</p></li>
<li><p>The maximization over <span class="math notranslate nohighlight">\(\boldsymbol{\mu} \geq 0\)</span> ensures that inequality constraints <span class="math notranslate nohighlight">\(\mathbf{g}(\mathbf{x}) \leq \mathbf{0}\)</span> are satisfied. If any inequality constraint is violated, the corresponding term in <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^T \mathbf{g}(\mathbf{x})\)</span> can be made arbitrarily large by choosing a large enough <span class="math notranslate nohighlight">\(\mu_i\)</span>.</p></li>
<li><p>The maximization over <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}\)</span> ensures that equality constraints <span class="math notranslate nohighlight">\(\mathbf{h}(\mathbf{x}) = \mathbf{0}\)</span> are satisfied.</p></li>
</ol>
<p>Using this observation, we can devise an algorithm which, like SQP, will update both the primal and dual variables at every step. But rather than using second-order optimization, we will simply use a first-order gradient update step: a descent step in the primal variable, and an ascent step in the dual one. The corresponding procedure, when implemented by gradient descent, is called Gradient Ascent Descent in the learning and optimization communities. In the case of equality constraints only, the algorithm looks like the following:</p>
<div class="proof algorithm admonition" id="ahuz-eq">
<p class="admonition-title"><span class="caption-number">Algorithm 50 </span> (Arrow-Hurwicz-Uzawa for equality constraints only)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Initial guess <span class="math notranslate nohighlight">\(\mathbf{x}^0\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^0\)</span>, step sizes <span class="math notranslate nohighlight">\(\alpha\)</span>, <span class="math notranslate nohighlight">\(\beta\)</span>
<strong>Output:</strong> Optimal <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^*\)</span></p>
<p>1: <strong>for</strong> <span class="math notranslate nohighlight">\(k = 0, 1, 2, \ldots\)</span> until convergence <strong>do</strong></p>
<p>2:     <span class="math notranslate nohighlight">\(\mathbf{x}^{k+1} = \mathbf{x}^k - \alpha \nabla_{\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k)\)</span>  <strong>(Primal update)</strong></p>
<p>3:     <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1} = \boldsymbol{\lambda}^k + \beta \nabla_{\boldsymbol{\lambda}} L(\mathbf{x}^{k+1}, \boldsymbol{\lambda}^k)\)</span>  <strong>(Dual update)</strong></p>
<p>4: <strong>end for</strong></p>
<p>5: <strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^k\)</span></p>
</section>
</div><p>Now to account for the fact that the Lagrange multiplier needs to be non-negative for inequality constraints, we can use our previous idea from projected gradient descent for bound constraints and consider a projection, or clipping step to ensure that this condition is satisfied throughout. In this case, the algorithm looks like the following:</p>
<div class="proof algorithm admonition" id="ahuz-full">
<p class="admonition-title"><span class="caption-number">Algorithm 51 </span> (Arrow-Hurwicz-Uzawa for equality and inequality constraints)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Initial guess <span class="math notranslate nohighlight">\(\mathbf{x}^0\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^0\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^0 \geq 0\)</span>, step sizes <span class="math notranslate nohighlight">\(\alpha\)</span>, <span class="math notranslate nohighlight">\(\beta\)</span>, <span class="math notranslate nohighlight">\(\gamma\)</span>
<strong>Output:</strong> Optimal <span class="math notranslate nohighlight">\(\mathbf{x}^*\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^*\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^*\)</span></p>
<p>1: <strong>for</strong> <span class="math notranslate nohighlight">\(k = 0, 1, 2, \ldots\)</span> until convergence <strong>do</strong></p>
<p>2:     <span class="math notranslate nohighlight">\(\mathbf{x}^{k+1} = \mathbf{x}^k - \alpha \nabla_{\mathbf{x}} L(\mathbf{x}^k, \boldsymbol{\lambda}^k, \boldsymbol{\mu}^k)\)</span>  <strong>(Primal update)</strong></p>
<p>3:     <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^{k+1} = \boldsymbol{\lambda}^k + \beta \, \nabla_{\boldsymbol{\lambda}} L(\mathbf{x}^{k+1}, \boldsymbol{\lambda}^k, \boldsymbol{\mu}^k)\)</span>  <strong>(Dual update for equality constraints)</strong></p>
<p>4:     <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^{k+1} = [\boldsymbol{\mu}^k + \gamma \nabla_{\boldsymbol{\mu}} L(\mathbf{x}^{k+1}, \boldsymbol{\lambda}^k, \boldsymbol{\mu}^k)]_+\)</span>  <strong>(Dual update with clipping for inequality constraints)</strong></p>
<p>5: <strong>end for</strong></p>
<p>6: <strong>return</strong> <span class="math notranslate nohighlight">\(\mathbf{x}^k\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\lambda}^k\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}^k\)</span></p>
</section>
</div><p>Here, <span class="math notranslate nohighlight">\([\cdot]_+\)</span> denotes the projection onto the non-negative orthant, ensuring that <span class="math notranslate nohighlight">\(\boldsymbol{\mu}\)</span> remains non-negative.</p>
<p>However, as it is widely known from the lessons of GAN (Generative Adversarial Network) training <span id="id4">[<a class="reference internal" href="bibliography.html#id11" title="Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems, volume 27. 2014.">17</a>]</span>, Gradient Descent Ascent (GDA) can fail to converge or suffer from instability. The Arrow-Hurwicz-Uzawa algorithm, also known as the first-order Lagrangian method, is known to converge only locally, in the vicinity of an optimal primal-dual pair.</p>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span><span class="p">,</span> <span class="n">jit</span><span class="p">,</span> <span class="n">value_and_grad</span>
<span class="kn">import</span> <span class="nn">optax</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Define the objective function and constraints</span>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>

<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">h</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]])</span>  <span class="c1"># Inequality constraint: x[1] &lt;= x[0]^2</span>

<span class="c1"># Define the Lagrangian</span>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">lagrangian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">g</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">h</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># Compute gradients of the Lagrangian</span>
<span class="n">grad_L_x</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">lagrangian</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">grad_L_lambda</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">lagrangian</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">grad_L_mu</span> <span class="o">=</span> <span class="n">jit</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">lagrangian</span><span class="p">,</span> <span class="n">argnums</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Define the Arrow-Hurwicz-Uzawa update step</span>
<span class="nd">@jit</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="n">carry</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">opt_state_x</span><span class="p">,</span> <span class="n">opt_state_lambda</span><span class="p">,</span> <span class="n">opt_state_mu</span> <span class="o">=</span> <span class="n">carry</span>
    
    <span class="c1"># Compute gradients</span>
    <span class="n">grad_x</span> <span class="o">=</span> <span class="n">grad_L_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">grad_lambda</span> <span class="o">=</span> <span class="n">grad_L_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    <span class="n">grad_mu</span> <span class="o">=</span> <span class="n">grad_L_mu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">)</span>
    
    <span class="c1"># Update primal variables (minimization)</span>
    <span class="n">updates_x</span><span class="p">,</span> <span class="n">opt_state_x</span> <span class="o">=</span> <span class="n">optimizer_x</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grad_x</span><span class="p">,</span> <span class="n">opt_state_x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">updates_x</span><span class="p">)</span>
    
    <span class="c1"># Update dual variables (maximization)</span>
    <span class="n">updates_lambda</span><span class="p">,</span> <span class="n">opt_state_lambda</span> <span class="o">=</span> <span class="n">optimizer_lambda</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grad_lambda</span><span class="p">,</span> <span class="n">opt_state_lambda</span><span class="p">)</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="o">-</span><span class="n">updates_lambda</span><span class="p">)</span>  <span class="c1"># Positive update for maximization</span>
    
    <span class="n">updates_mu</span><span class="p">,</span> <span class="n">opt_state_mu</span> <span class="o">=</span> <span class="n">optimizer_mu</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">grad_mu</span><span class="p">,</span> <span class="n">opt_state_mu</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">apply_updates</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="o">-</span><span class="n">updates_mu</span><span class="p">)</span>  <span class="c1"># Positive update for maximization</span>
    
    <span class="c1"># Project mu onto the non-negative orthant</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">opt_state_x</span><span class="p">,</span> <span class="n">opt_state_lambda</span><span class="p">,</span> <span class="n">opt_state_mu</span><span class="p">),</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">arrow_hurwicz_uzawa</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">,</span> <span class="n">mu0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
    <span class="c1"># Initialize optimizers</span>
    <span class="k">global</span> <span class="n">optimizer_x</span><span class="p">,</span> <span class="n">optimizer_lambda</span><span class="p">,</span> <span class="n">optimizer_mu</span>
    <span class="n">optimizer_x</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">optimizer_lambda</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">optimizer_mu</span> <span class="o">=</span> <span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    
    <span class="n">opt_state_x</span> <span class="o">=</span> <span class="n">optimizer_x</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
    <span class="n">opt_state_lambda</span> <span class="o">=</span> <span class="n">optimizer_lambda</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">lambda0</span><span class="p">)</span>
    <span class="n">opt_state_mu</span> <span class="o">=</span> <span class="n">optimizer_mu</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">mu0</span><span class="p">)</span>
    
    <span class="n">init_carry</span> <span class="o">=</span> <span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">,</span> <span class="n">mu0</span><span class="p">,</span> <span class="n">opt_state_x</span><span class="p">,</span> <span class="n">opt_state_lambda</span><span class="p">,</span> <span class="n">opt_state_mu</span><span class="p">)</span>
    
    <span class="c1"># Use jax.lax.scan for the optimization loop</span>
    <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">),</span> <span class="n">trajectory</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">scan</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">init_carry</span><span class="p">,</span> <span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_iter</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">trajectory</span>

<span class="c1"># Initial point</span>
<span class="n">x0</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="n">lambda0</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">mu0</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Solve using Arrow-Hurwicz-Uzawa</span>
<span class="n">x_opt</span><span class="p">,</span> <span class="n">lambda_opt</span><span class="p">,</span> <span class="n">mu_opt</span><span class="p">,</span> <span class="n">trajectory</span> <span class="o">=</span> <span class="n">arrow_hurwicz_uzawa</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">lambda0</span><span class="p">,</span> <span class="n">mu0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final x: </span><span class="si">{</span><span class="n">x_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final lambda: </span><span class="si">{</span><span class="n">lambda_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final mu: </span><span class="si">{</span><span class="n">mu_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualize the result</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="c1"># Create a mesh for the contour plot</span>
<span class="n">x1_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2_range</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X1</span><span class="p">,</span> <span class="n">X2</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x1_range</span><span class="p">,</span> <span class="n">x2_range</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">f</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">x1</span><span class="p">,</span> <span class="n">x2</span><span class="p">]))</span> <span class="k">for</span> <span class="n">x1</span> <span class="ow">in</span> <span class="n">x1_range</span><span class="p">]</span> <span class="k">for</span> <span class="n">x2</span> <span class="ow">in</span> <span class="n">x2_range</span><span class="p">])</span>

<span class="c1"># Plot filled contours</span>
<span class="n">contour</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">X2</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contour</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Objective Function Value&#39;</span><span class="p">)</span>

<span class="c1"># Plot the equality constraint</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x1_eq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">x2_eq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_eq</span><span class="p">,</span> <span class="n">x2_eq</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Equality Constraint&#39;</span><span class="p">)</span>

<span class="c1"># Plot the inequality constraint and shade the feasible region</span>
<span class="n">x1_ineq</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">x2_ineq</span> <span class="o">=</span> <span class="n">x1_ineq</span><span class="o">**</span><span class="mi">2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_ineq</span><span class="p">,</span> <span class="n">x2_ineq</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Inequality Constraint&#39;</span><span class="p">)</span>

<span class="c1"># Shade the feasible region for the inequality constraint</span>
<span class="n">x2_lower</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">x2_ineq</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x1_ineq</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">x2_lower</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">hatch</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\\</span><span class="s1">/...&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Feasible Region&#39;</span><span class="p">)</span>

<span class="c1"># Plot the optimal and initial points</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_opt</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_opt</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Final Point&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x0</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x0</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Initial Point&#39;</span><span class="p">)</span>

<span class="c1"># Plot the optimization trajectory using scatter plot</span>
<span class="n">scatter</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">trajectory</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trajectory</span><span class="p">)),</span> 
                      <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;cool&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">scatter</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Iteration&#39;</span><span class="p">)</span>

<span class="c1"># Add labels and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Arrow-Hurwicz-Uzawa Algorithm with JAX and Adam (Corrected Min/Max)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.05</span><span class="p">),</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Set the axis limits explicitly</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="c1"># Verify the result</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Equality constraint violation: </span><span class="si">{</span><span class="n">g</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inequality constraint violation: </span><span class="si">{</span><span class="n">h</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Objective function value: </span><span class="si">{</span><span class="n">f</span><span class="p">(</span><span class="n">x_opt</span><span class="p">)</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="projected-gradient-descent">
<h2>Projected Gradient Descent<a class="headerlink" href="#projected-gradient-descent" title="Link to this heading">#</a></h2>
<p>The Arrow-Hurwicz-Uzawa algorithm provided a way to handle constraints through dual variables and a primal-dual update scheme. Another commonly used approach for constrained optimization is <strong>Projected Gradient Descent (PGD)</strong>. The idea is simple: take a gradient descent step as if the problem were unconstrained, then project the result back onto the feasible set. Formally:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_{k+1} = \mathcal{P}_C\big(\mathbf{x}_k - \alpha \nabla f(\mathbf{x}_k)\big),
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal{P}_C\)</span> is the projection onto the feasible set <span class="math notranslate nohighlight">\(C\)</span>, <span class="math notranslate nohighlight">\(\alpha\)</span> is the step size, and <span class="math notranslate nohighlight">\(f(\mathbf{x})\)</span> is the objective function.</p>
<p>PGD is particularly effective when the projection is computationally cheap. A common example is <strong>box constraints</strong> (or bound constraints), where the feasible set is a hyperrectangle:</p>
<div class="math notranslate nohighlight">
\[
C = \{ \mathbf{x} \mid \mathbf{x}_{\mathrm{lb}} \leq \mathbf{x} \leq \mathbf{x}_{\mathrm{ub}} \}.
\]</div>
<p>In this case, the projection reduces to an element-wise clipping operation:</p>
<div class="math notranslate nohighlight">
\[
[\mathcal{P}_C(\mathbf{x})]_i = \max\big(\min([\mathbf{x}]_i, [\mathbf{x}_{\mathrm{ub}}]_i), [\mathbf{x}_{\mathrm{lb}}]_i\big).
\]</div>
<p>For bound-constrained problems, PGD is almost as easy to implement as standard gradient descent because the projection step is just a clipping operation. For more general constraints, however, the projection may require solving a separate optimization problem, which can be as hard as the original task. Here is the algorithm for a problem of the form:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\min_{\mathbf{x}} \quad &amp; f(\mathbf{x}) \\
\text{subject to} \quad &amp; \mathbf{x}_{\mathrm{lb}} \leq \mathbf{x} \leq \mathbf{x}_{\mathrm{ub}}.
\end{aligned}
\end{split}\]</div>
<div class="proof algorithm admonition" id="proj-grad-descent-bound-constraints">
<p class="admonition-title"><span class="caption-number">Algorithm 52 </span> (Projected Gradient Descent for Bound Constraints)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Input:</strong> Initial point <span class="math notranslate nohighlight">\(\mathbf{x}_0\)</span>, step size <span class="math notranslate nohighlight">\(\alpha\)</span>, bounds <span class="math notranslate nohighlight">\(\mathbf{x}_{\mathrm{lb}}, \mathbf{x}_{\mathrm{ub}}\)</span>,
maximum iterations <span class="math notranslate nohighlight">\(\max_\text{iter}\)</span>, tolerance <span class="math notranslate nohighlight">\(\varepsilon\)</span></p>
<ol class="arabic simple">
<li><p>Initialize <span class="math notranslate nohighlight">\(k = 0\)</span></p></li>
<li><p>While <span class="math notranslate nohighlight">\(k &lt; \max_\text{iter}\)</span> and not converged:</p>
<ol class="arabic simple">
<li><p>Compute gradient: <span class="math notranslate nohighlight">\(\mathbf{g}_k = \nabla f(\mathbf{x}_k)\)</span></p></li>
<li><p>Update: <span class="math notranslate nohighlight">\(\mathbf{x}_{k+1} = \text{clip}(\mathbf{x}_k - \alpha \mathbf{g}_k,\; \mathbf{x}_{\mathrm{lb}}, \mathbf{x}_{\mathrm{ub}})\)</span></p></li>
<li><p>Check convergence: if <span class="math notranslate nohighlight">\(\|\mathbf{x}_{k+1} - \mathbf{x}_k\| &lt; \varepsilon\)</span>, stop</p></li>
<li><p><span class="math notranslate nohighlight">\(k = k + 1\)</span></p></li>
</ol>
</li>
<li><p>Return <span class="math notranslate nohighlight">\(\mathbf{x}_k\)</span></p></li>
</ol>
</section>
</div><p>The clipping function is defined as:</p>
<div class="math notranslate nohighlight">
\[
\text{clip}(x, x_{\mathrm{lb}}, x_{\mathrm{ub}}) = \max\big(\min(x, x_{\mathrm{ub}}), x_{\mathrm{lb}}\big).
\]</div>
<p>Under mild conditions such as Lipschitz continuity of the gradient, PGD converges to a stationary point of the constrained problem. Its simplicity and low cost make it a common choice whenever the projection can be computed efficiently.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="appendix_ivps.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Solving Initial Value Problems</p>
      </div>
    </a>
    <a class="right-next"
       href="bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) conditions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lagrange-multiplier-theorem">Lagrange Multiplier Theorem</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-s-method">Newton’s Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#efficient-implementation-of-newton-s-method">Efficient Implementation of Newton’s Method</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-equality-constrained-programs-with-newton-s-method">Solving Equality Constrained Programs with Newton’s Method</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration">Demonstration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-sqp-approach-taylor-expansion-and-quadratic-approximation">The SQP Approach: Taylor Expansion and Quadratic Approximation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#connection-to-newton-s-method-in-the-equality-constrained-case">Connection to Newton’s Method in the Equality-Constrained Case</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sqp-for-inequality-constrained-optimization">SQP for Inequality-Constrained Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-with-jax-and-cvxpy">Demonstration with JAX and CVXPy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-arrow-hurwicz-uzawa-algorithm">The Arrow-Hurwicz-Uzawa algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#projected-gradient-descent">Projected Gradient Descent</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pierre-Luc Bacon
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>