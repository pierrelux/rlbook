
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Projection Methods for Functional Equations &#8212; Practical Reinforcement Learning: From Algorithms to Applications</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"bm": ["{\\boldsymbol #1}", 1]}, "processEscapes": true}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'projdp';</script>
    <script src="_static/iframe-modal.js?v=f72a1242"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Simulation-Based Approximate Dynamic Programming" href="simadp.html" />
    <link rel="prev" title="Smooth Bellman Optimality Equations" href="regmdp.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Practical Reinforcement Learning: From Algorithms to Applications</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Why This Book?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="modeling.html">Why Build a Model? For Whom?</a></li>

<li class="toctree-l1"><a class="reference internal" href="ssm.html">Dynamics Models for Decision Making</a></li>




<li class="toctree-l1"><a class="reference internal" href="simulation.html">Programs as Models</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Numerical Trajectory Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ocp.html">Discrete-Time Trajectory Optimization</a></li>


<li class="toctree-l1"><a class="reference internal" href="cocp.html">Trajectory Optimization in Continuous Time</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">From Trajectories to Policies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mpc.html">Model Predictive Control</a></li>




<li class="toctree-l1"><a class="reference internal" href="dp.html">Dynamic Programming</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Approximate Dynamic Programming</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="regmdp.html">Smooth Bellman Optimality Equations</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Projection Methods for Functional Equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="simadp.html">Simulation-Based Approximate Dynamic Programming</a></li>



<li class="toctree-l1"><a class="reference internal" href="cadp.html">Policy Parametrization Methods</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="appendix_examples.html">Example COCPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix_ivps.html">Solving Initial Value Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix_nlp.html">Nonlinear Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/edit/main/projdp.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/issues/new?title=Issue%20on%20page%20%2Fprojdp.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/projdp.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Projection Methods for Functional Equations</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-it-mean-for-a-residual-to-be-zero">What Does It Mean for a Residual to Be Zero?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-special-role-of-spectral-methods">The Special Role of Spectral Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-collocation">Orthogonal Collocation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-framework">The General Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-choose-a-finite-dimensional-approximation-space">Step 1: Choose a Finite-Dimensional Approximation Space</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-define-the-residual-function">Step 2: Define the Residual Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-choose-weighted-residual-conditions">Step 3: Choose Weighted Residual Conditions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#galerkin-method-test-against-the-basis">Galerkin Method: Test Against the Basis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#method-of-moments-test-against-monomials">Method of Moments: Test Against Monomials</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collocation-method-test-against-delta-functions">Collocation Method: Test Against Delta Functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#subdomain-method-test-against-indicator-functions">Subdomain Method: Test Against Indicator Functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#least-squares">Least Squares</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-solve-the-finite-dimensional-problem">Step 4: Solve the Finite-Dimensional Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-verify-the-solution">Step 5: Verify the Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-to-the-bellman-equation">Application to the Bellman Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collocation-for-the-bellman-equation">Collocation for the Bellman Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-collocation-system">Solving the Collocation System</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-1-function-iteration-successive-approximation">Method 1: Function Iteration (Successive Approximation)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-2-newton-s-method-with-the-envelope-theorem">Method 2: Newton’s Method with the Envelope Theorem</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-solution-methods">Comparison of Solution Methods</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-preserving-considerations">Shape-Preserving Considerations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monotone-projection-and-the-preservation-of-contraction">Monotone Projection and the Preservation of Contraction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monotone-approximators-and-stability">Monotone Approximators and Stability</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#monotonicity-implies-nonexpansiveness">Monotonicity Implies Nonexpansiveness</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preservation-of-contraction">Preservation of Contraction</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#averagers-in-discrete-state-problems">Averagers in Discrete-State Problems</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#which-approximation-operators-are-monotone">Which Approximation Operators Are Monotone?</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-implications">Practical Implications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-norms-and-extensions">Weighted Norms and Extensions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galerkin-projection-and-least-squares-temporal-difference">Galerkin Projection and Least Squares Temporal Difference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-projected-bellman-equations">The Projected Bellman Equations</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="projection-methods-for-functional-equations">
<h1>Projection Methods for Functional Equations<a class="headerlink" href="#projection-methods-for-functional-equations" title="Link to this heading">#</a></h1>
<p>The Bellman optimality equation <span class="math notranslate nohighlight">\(\mathrm{L}v = v\)</span> is a functional equation: an equation where the unknown is an entire function rather than a finite-dimensional vector. When the state space is continuous or very large, we cannot represent the value function exactly on a computer. We must instead work with finite-dimensional approximations. This motivates projection methods, a general framework for transforming infinite-dimensional problems into tractable finite-dimensional ones.</p>
<section id="what-does-it-mean-for-a-residual-to-be-zero">
<h2>What Does It Mean for a Residual to Be Zero?<a class="headerlink" href="#what-does-it-mean-for-a-residual-to-be-zero" title="Link to this heading">#</a></h2>
<p>Suppose we have found a candidate approximate solution <span class="math notranslate nohighlight">\(\hat{v}\)</span> to the Bellman equation. To verify it satisfies <span class="math notranslate nohighlight">\(\mathrm{L}\hat{v} = \hat{v}\)</span>, we compute the <strong>residual function</strong> <span class="math notranslate nohighlight">\(R(s) = \mathrm{L}\hat{v}(s) - \hat{v}(s)\)</span>. For a true solution, this residual should be the <strong>zero function</strong>: <span class="math notranslate nohighlight">\(R(s) = 0\)</span> for every state <span class="math notranslate nohighlight">\(s\)</span>. But what does it really mean for a function to equal zero?</p>
<p>In finite dimensions, a vector <span class="math notranslate nohighlight">\(\mathbf{r} \in \mathbb{R}^n\)</span> equals zero if and only if <span class="math notranslate nohighlight">\(\langle \mathbf{r}, \mathbf{y} \rangle = 0\)</span> for every vector <span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^n\)</span>. This follows because if <span class="math notranslate nohighlight">\(\mathbf{r} \neq \mathbf{0}\)</span>, we can always choose <span class="math notranslate nohighlight">\(\mathbf{y} = \mathbf{r}\)</span>, giving <span class="math notranslate nohighlight">\(\langle \mathbf{r}, \mathbf{r} \rangle = \|\mathbf{r}\|^2 &gt; 0\)</span>. Conversely, if <span class="math notranslate nohighlight">\(\mathbf{r} = \mathbf{0}\)</span>, then <span class="math notranslate nohighlight">\(\langle \mathbf{r}, \mathbf{y} \rangle = 0\)</span> trivially for all <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>.</p>
<p>Inner products can distinguish the zero vector from any nonzero vector: for any <span class="math notranslate nohighlight">\(\mathbf{r} \neq \mathbf{0}\)</span>, there exists some test vector <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> that “witnesses” the fact that <span class="math notranslate nohighlight">\(\mathbf{r}\)</span> is nonzero by producing <span class="math notranslate nohighlight">\(\langle \mathbf{r}, \mathbf{y} \rangle \neq 0\)</span>. This property, that we can tell apart (separate) different vectors by testing them with inner products, is what makes inner products so useful for verification.</p>
<p>The same principle extends to functions. A function <span class="math notranslate nohighlight">\(R\)</span> equals the zero function if and only if its “inner product” with every “test function” <span class="math notranslate nohighlight">\(p\)</span> vanishes:</p>
<div class="math notranslate nohighlight">
\[
R = 0 \quad \text{if and only if} \quad \langle R, p \rangle = \int_{\mathcal{S}} R(s) p(s) w(s) ds = 0 \quad \text{for all test functions } p,
\]</div>
<p>where <span class="math notranslate nohighlight">\(w(s)\)</span> is a weight function (often chosen to emphasize certain regions of the state space). Why does this work? For the same reason as in finite dimensions: if <span class="math notranslate nohighlight">\(R\)</span> is not the zero function, there must be some region where <span class="math notranslate nohighlight">\(R(s) \neq 0\)</span>. We can then choose a test function <span class="math notranslate nohighlight">\(p\)</span> that is nonzero in that same region (for instance, <span class="math notranslate nohighlight">\(p(s) = R(s)\)</span> itself), which will produce <span class="math notranslate nohighlight">\(\langle R, p \rangle = \int R(s) p(s) w(s) ds &gt; 0\)</span>, witnessing that <span class="math notranslate nohighlight">\(R\)</span> is nonzero. Conversely, if <span class="math notranslate nohighlight">\(R\)</span> is the zero function, then <span class="math notranslate nohighlight">\(\langle R, p \rangle = 0\)</span> for any test function <span class="math notranslate nohighlight">\(p\)</span>.</p>
<p>This ability to <strong>distinguish between different functions using inner products</strong> is a fundamental principle from functional analysis. Just as we can test a vector by taking inner products with other vectors, we can test a function by taking inner products with other functions.</p>
<div class="dropdown admonition">
<p class="admonition-title">Connection to Functional Analysis</p>
<p>The principle that “a function equals zero if and only if it has zero inner product with all test functions” is a consequence of the <strong>Hahn-Banach theorem</strong>, one of the cornerstones of functional analysis. The theorem guarantees that for any nonzero function <span class="math notranslate nohighlight">\(R\)</span> in a suitable function space, there exists a continuous linear functional (which can be represented as an inner product with some test function <span class="math notranslate nohighlight">\(p\)</span>) that produces a nonzero value when applied to <span class="math notranslate nohighlight">\(R\)</span>. This is often phrased as “the dual space separates points.”</p>
<p>While you don’t need to know the Hahn-Banach theorem to use projection methods, it provides the rigorous mathematical foundation ensuring that our inner product tests are theoretically sound. The constructive argument we gave above (choosing <span class="math notranslate nohighlight">\(p = R\)</span>) works in simple cases with well-behaved functions, but the Hahn-Banach theorem extends this guarantee to much more general settings.</p>
</div>
<p>Why is this useful? It transforms the pointwise condition “<span class="math notranslate nohighlight">\(R(s) = 0\)</span> for all <span class="math notranslate nohighlight">\(s\)</span>” (infinitely many conditions, one per state) into an equivalent condition about inner products. We still cannot test against <em>all</em> possible test functions, since there are infinitely many of those too. But the inner product perspective suggests a natural computational strategy: choose a finite collection of test functions <span class="math notranslate nohighlight">\(\{p_1, \ldots, p_n\}\)</span> and require</p>
<div class="math notranslate nohighlight">
\[
\langle R, p_i \rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This gives us exactly <span class="math notranslate nohighlight">\(n\)</span> conditions that we can actually compute. This approach defines what are called <strong>weighted residual methods</strong>: we make the residual “small” by requiring it to satisfy certain weighted integral conditions.</p>
<p>Within weighted residual methods, there are two main families:</p>
<p><strong>Projection methods</strong> (also called orthogonal projection methods) directly require the residual to have zero inner product with chosen test functions:</p>
<div class="math notranslate nohighlight">
\[
\langle R, p_i \rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>We are “projecting” the residual to be orthogonal to the span of the test functions. Different choices of test functions give different projection methods:</p>
<ul class="simple">
<li><p><strong>Galerkin</strong>: Test against the basis functions used to represent <span class="math notranslate nohighlight">\(\hat{v}\)</span>, so <span class="math notranslate nohighlight">\(p_i = \varphi_i\)</span></p></li>
<li><p><strong>Collocation</strong>: Test against delta functions <span class="math notranslate nohighlight">\(p_i = \delta(s - s_i)\)</span>, which reduces to pointwise evaluation <span class="math notranslate nohighlight">\(R(s_i) = 0\)</span></p></li>
<li><p><strong>Method of moments</strong>: Test against polynomials <span class="math notranslate nohighlight">\(p_i = s^{i-1}\)</span>, ensuring low-order moments of the residual vanish</p></li>
<li><p><strong>Subdomain method</strong>: Test against indicator functions <span class="math notranslate nohighlight">\(p_i = I_{D_i}\)</span> for subregions <span class="math notranslate nohighlight">\(D_i\)</span>, requiring zero average residual in each subdomain</p></li>
</ul>
<section id="the-special-role-of-spectral-methods">
<h3>The Special Role of Spectral Methods<a class="headerlink" href="#the-special-role-of-spectral-methods" title="Link to this heading">#</a></h3>
<p>You may encounter the term <strong>spectral methods</strong> in the literature. This doesn’t refer to a different choice of test functions, but rather to a choice of <strong>basis functions</strong> <span class="math notranslate nohighlight">\(\varphi_i\)</span>. Spectral methods use basis functions from families of orthogonal polynomials (like Chebyshev, Legendre, or Hermite polynomials) or trigonometric functions (Fourier series). The “spectral” name comes from the decomposition of the solution into these orthogonal components, analogous to decomposing a signal into frequency components.</p>
<p>What makes spectral bases special is their approximation properties: for smooth problems (functions with many continuous derivatives), spectral approximations achieve <strong>exponential convergence</strong>. As you add more basis functions, the approximation error decreases exponentially rather than polynomially. A function with <span class="math notranslate nohighlight">\(k\)</span> continuous derivatives approximated by piecewise polynomials of degree <span class="math notranslate nohighlight">\(p\)</span> has error <span class="math notranslate nohighlight">\(O(h^{p+1})\)</span> where <span class="math notranslate nohighlight">\(h\)</span> is the grid spacing. But the same function approximated by a spectral method with <span class="math notranslate nohighlight">\(n\)</span> terms has error that decreases like <span class="math notranslate nohighlight">\(O(e^{-cn})\)</span> for some constant <span class="math notranslate nohighlight">\(c &gt; 0\)</span>. This dramatic difference makes spectral methods extremely efficient for smooth problems.</p>
<p>Now, spectral bases can be combined with any projection method. When we use a spectral basis with <strong>Galerkin projection</strong> (testing against the basis functions themselves), we get a <strong>spectral Galerkin method</strong>. The orthogonality of the basis functions often simplifies the resulting linear systems. When we use a spectral basis with <strong>collocation</strong>, we get what’s often called a <strong>pseudospectral method</strong> or <strong>spectral collocation method</strong>.</p>
</section>
<section id="orthogonal-collocation">
<h3>Orthogonal Collocation<a class="headerlink" href="#orthogonal-collocation" title="Link to this heading">#</a></h3>
<p><strong>Orthogonal collocation</strong> exploits a useful connection between collocation and quadrature. The idea is to:</p>
<ol class="arabic simple">
<li><p>Choose basis functions from an orthogonal polynomial family (say, Chebyshev polynomials <span class="math notranslate nohighlight">\(T_0, T_1, \ldots, T_{n-1}\)</span>)</p></li>
<li><p>Choose collocation points at the <strong>zeros of the <span class="math notranslate nohighlight">\(n\)</span>-th polynomial</strong> in that family</p></li>
</ol>
<p>Why is this clever? Because these same points are also the optimal nodes for <strong>Gauss quadrature</strong> using the weight function associated with that polynomial family. For example, the zeros of the Chebyshev polynomial <span class="math notranslate nohighlight">\(T_n(s)\)</span> are also the Chebyshev-Gauss quadrature nodes. This means:</p>
<ul class="simple">
<li><p>We get the computational simplicity of collocation: the projection conditions are just <span class="math notranslate nohighlight">\(R(s_i) = 0\)</span> at the collocation points (no integrals to evaluate)</p></li>
<li><p>When we do need to compute integrals (say, inside the operator <span class="math notranslate nohighlight">\(\mathscr{N}\)</span> itself), we can use the collocation points as quadrature nodes and the resulting quadrature is <strong>exact</strong> for polynomials up to degree <span class="math notranslate nohighlight">\(2n-1\)</span></p></li>
<li><p>For smooth problems, we inherit the exponential convergence of spectral approximations</p></li>
</ul>
<p>This coordination between approximation and integration is why orthogonal collocation is so effective. You’ll sometimes see it called a “pseudospectral method,” though different authors use these terms with slight variations. The key point is that by carefully coordinating our choice of basis, test functions (collocation points), and quadrature nodes, we can achieve excellent accuracy with computational efficiency.</p>
<p>In summary, “spectral” describes the basis choice (orthogonal polynomials or Fourier), while “Galerkin,” “collocation,” etc. describe the projection choice (which test functions). Orthogonal collocation represents an optimal marriage of these choices for smooth problems.</p>
<p><strong>Least squares methods</strong> take a different approach: instead of requiring orthogonality to specific test functions, we minimize the overall size of the residual measured in a weighted norm:</p>
<div class="math notranslate nohighlight">
\[
\min_{a} \|R(\cdot; a)\|^2 = \min_{a} \int_{\mathcal{S}} R(s; a)^2 w(s) ds.
\]</div>
<p>This seeks the coefficients <span class="math notranslate nohighlight">\(a\)</span> that make the residual as small as possible in the least squares sense. The first-order optimality conditions for this minimization problem turn out to be equivalent to a projection method with test functions <span class="math notranslate nohighlight">\(p_i = \partial R / \partial a_i\)</span> (the derivatives of the residual with respect to the coefficients). So least squares can be viewed as a projection method with <em>data-dependent</em> test functions.</p>
<p>Both families aim to make the residual “close to zero,” but projection methods do this by requiring orthogonality to chosen directions, while least squares does this by directly minimizing the norm of the residual. The term “projection methods” as used in the approximate dynamic programming literature often refers to both families, since they share the same computational framework of restricting the search to a finite-dimensional subspace and solving for coefficients that satisfy certain residual conditions.</p>
<p>In summary, we have transformed the impossible task of verifying “<span class="math notranslate nohighlight">\(R(s) = 0\)</span> for all <span class="math notranslate nohighlight">\(s\)</span>” into a <strong>finite-dimensional</strong> problem: find coefficients <span class="math notranslate nohighlight">\(a = (a_1, \ldots, a_n)\)</span> in our approximation <span class="math notranslate nohighlight">\(\hat{v}(s) = \sum_{i=1}^n a_i \varphi_i(s)\)</span> such that either:</p>
<ul class="simple">
<li><p>The residual is orthogonal to <span class="math notranslate nohighlight">\(n\)</span> chosen test functions (projection methods), or</p></li>
<li><p>The residual has minimum norm (least squares methods)</p></li>
</ul>
<p>This is a major conceptual step forward: instead of infinitely many pointwise conditions, we have <span class="math notranslate nohighlight">\(n\)</span> conditions. However, these <span class="math notranslate nohighlight">\(n\)</span> conditions are not yet fully “feasible” computationally. Each projection condition <span class="math notranslate nohighlight">\(\langle R, p_i \rangle = \int_{\mathcal{S}} R(s) p_i(s) w(s) ds = 0\)</span> still involves an integral that may need to be approximated numerically.</p>
<p>The computational cost hierarchy. Different methods have different computational burdens:</p>
<ul class="simple">
<li><p><strong>Collocation</strong> is the cheapest: since <span class="math notranslate nohighlight">\(\langle R, \delta(\cdot - s_i) \rangle = R(s_i)\)</span>, we only evaluate the residual pointwise. No integration is needed in the projection conditions themselves.</p></li>
<li><p><strong>Orthogonal collocation</strong> shares this advantage (projection conditions are just pointwise evaluations), but adds a bonus: if integrals appear elsewhere, say inside the operator <span class="math notranslate nohighlight">\(\mathscr{N}\)</span>, the collocation points double as optimal quadrature nodes. This synergy between approximation and integration is particularly valuable for smooth problems.</p></li>
<li><p><strong>Galerkin methods</strong> require evaluating integrals <span class="math notranslate nohighlight">\(\int R(s) \varphi_i(s) w(s) ds\)</span> for each basis function. When using orthogonal polynomial bases (spectral Galerkin), these integrals can sometimes be simplified by orthogonality, but numerical quadrature is still typically needed.</p></li>
<li><p><strong>Method of moments and subdomain methods</strong> similarly require numerical quadrature to evaluate weighted integrals of the residual.</p></li>
<li><p><strong>Least squares</strong> requires computing <span class="math notranslate nohighlight">\(\int R(s)^2 w(s) ds\)</span>, which involves integrating the squared residual. This is potentially expensive, though the first-order conditions reduce this to a system similar to Galerkin.</p></li>
</ul>
<p>The general pattern: collocation methods avoid integration in the projection step by testing at points rather than against functions, while methods that test against smooth functions (Galerkin, moments, subdomain) must pay the computational cost of numerical integration.</p>
<p>The rest of this chapter develops this framework systematically, showing how to choose bases, select test functions, evaluate or approximate the necessary integrals, and solve the resulting finite-dimensional problems.</p>
</section>
</section>
<section id="the-general-framework">
<h2>The General Framework<a class="headerlink" href="#the-general-framework" title="Link to this heading">#</a></h2>
<p>Consider an operator equation of the form</p>
<div class="math notranslate nohighlight">
\[
\mathscr{N}(f) = 0,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathscr{N}: B_1 \to B_2\)</span> is a continuous operator between complete normed vector spaces <span class="math notranslate nohighlight">\(B_1\)</span> and <span class="math notranslate nohighlight">\(B_2\)</span>. For the Bellman equation, we have <span class="math notranslate nohighlight">\(\mathscr{N}(v) = \mathrm{L}v - v\)</span>, so that solving <span class="math notranslate nohighlight">\(\mathscr{N}(v) = 0\)</span> is equivalent to finding the fixed point <span class="math notranslate nohighlight">\(v = \mathrm{L}v\)</span>.</p>
<p>The projection method approach consists of several conceptual steps that transform this infinite-dimensional problem into a finite-dimensional one.</p>
<section id="step-1-choose-a-finite-dimensional-approximation-space">
<h3>Step 1: Choose a Finite-Dimensional Approximation Space<a class="headerlink" href="#step-1-choose-a-finite-dimensional-approximation-space" title="Link to this heading">#</a></h3>
<p>We begin by selecting a basis <span class="math notranslate nohighlight">\(\Phi = \{\varphi_1, \varphi_2, \ldots, \varphi_n\}\)</span> and approximating the unknown function as a linear combination:</p>
<div class="math notranslate nohighlight">
\[
\hat{f}(x) = \sum_{i=1}^n a_i \varphi_i(x).
\]</div>
<p>The choice of basis functions <span class="math notranslate nohighlight">\(\varphi_i\)</span> is problem-dependent. Common choices include:</p>
<ul class="simple">
<li><p><strong>Polynomials</strong>: For smooth problems, we might use Chebyshev polynomials or other orthogonal polynomial families</p></li>
<li><p><strong>Splines</strong>: For problems where we expect the solution to have regions of different smoothness</p></li>
<li><p><strong>Radial basis functions</strong>: For high-dimensional problems where tensor product methods become intractable</p></li>
</ul>
<p>The number of basis functions <span class="math notranslate nohighlight">\(n\)</span> determines the flexibility of our approximation. In practice, we start with small <span class="math notranslate nohighlight">\(n\)</span> and increase it until the approximation quality is satisfactory. The only unknowns now are the coefficients <span class="math notranslate nohighlight">\(a = (a_1, \ldots, a_n)\)</span>.</p>
<p>While the classical presentation of projection methods focuses on polynomial bases, the framework applies equally well to other function classes. Neural networks, for instance, can be viewed through this lens: a neural network <span class="math notranslate nohighlight">\(\hat{f}(x; \theta)\)</span> with parameters <span class="math notranslate nohighlight">\(\theta\)</span> defines a flexible function class, and many training procedures can be interpreted as projection methods with specific choices of test functions or residual norms. The distinction is that classical methods typically use predetermined basis functions with linear coefficients, while neural networks use adaptive nonlinear features. Throughout this chapter, we focus on the classical setting to develop the core concepts, but the principles extend naturally to modern function approximators.</p>
</section>
<section id="step-2-define-the-residual-function">
<h3>Step 2: Define the Residual Function<a class="headerlink" href="#step-2-define-the-residual-function" title="Link to this heading">#</a></h3>
<p>Since we are approximating <span class="math notranslate nohighlight">\(f\)</span> with <span class="math notranslate nohighlight">\(\hat{f}\)</span>, the operator <span class="math notranslate nohighlight">\(\mathscr{N}\)</span> will generally not vanish exactly. Instead, we obtain a <strong>residual function</strong>:</p>
<div class="math notranslate nohighlight">
\[
R(x; a) = \mathscr{N}(\hat{f}(\cdot; a))(x).
\]</div>
<p>This residual measures how far our candidate solution is from satisfying the equation at each point <span class="math notranslate nohighlight">\(x\)</span>. As we discussed in the introduction, we will assess whether this residual is “close to zero” by testing its inner products against chosen test functions.</p>
</section>
<section id="step-3-choose-weighted-residual-conditions">
<h3>Step 3: Choose Weighted Residual Conditions<a class="headerlink" href="#step-3-choose-weighted-residual-conditions" title="Link to this heading">#</a></h3>
<p>Having chosen our basis and defined the residual, we must decide how to make the residual “close to zero.” As discussed in the introduction, we can either:</p>
<ol class="arabic">
<li><p><strong>Use projection conditions</strong>: Select <span class="math notranslate nohighlight">\(n\)</span> test functions <span class="math notranslate nohighlight">\(\{p_1, \ldots, p_n\}\)</span> and require:</p>
<div class="math notranslate nohighlight">
\[
   \langle R(\cdot; a), p_i \rangle = \int_{\mathcal{S}} R(x; a) p_i(x) w(x) dx = 0, \quad i = 1, \ldots, n,
   \]</div>
<p>for some weight function <span class="math notranslate nohighlight">\(w(x)\)</span>. This yields <span class="math notranslate nohighlight">\(n\)</span> equations to determine the <span class="math notranslate nohighlight">\(n\)</span> coefficients in <span class="math notranslate nohighlight">\(a\)</span>.</p>
</li>
<li><p><strong>Use a least squares condition</strong>: Minimize the norm of the residual directly:</p>
<div class="math notranslate nohighlight">
\[
   \min_a \int_{\mathcal{S}} R(x; a)^2 w(x) dx.
   \]</div>
</li>
</ol>
<p>We begin by examining the main projection methods, distinguished entirely by their choice of test functions <span class="math notranslate nohighlight">\(p_i\)</span>, then discuss least squares as an alternative approach.</p>
<p>Let us examine the standard choices of test functions and what they tell us about the residual:</p>
<section id="galerkin-method-test-against-the-basis">
<h4>Galerkin Method: Test Against the Basis<a class="headerlink" href="#galerkin-method-test-against-the-basis" title="Link to this heading">#</a></h4>
<p>The Galerkin method chooses test functions <span class="math notranslate nohighlight">\(p_i = \varphi_i\)</span>, the same basis functions used to approximate <span class="math notranslate nohighlight">\(\hat{f}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\langle R(\cdot; a), \varphi_i \rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>To understand what this means, recall that in finite dimensions, two vectors are orthogonal when their inner product is zero. For functions, <span class="math notranslate nohighlight">\(\langle R, \varphi_i \rangle = \int R(x) \varphi_i(x) w(x) dx = 0\)</span> expresses the same concept: <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(\varphi_i\)</span> are orthogonal as functions. But there’s more to this than just testing against individual basis functions.</p>
<p>Consider our approximation space <span class="math notranslate nohighlight">\(\text{span}\{\varphi_1, \ldots, \varphi_n\}\)</span> as an <span class="math notranslate nohighlight">\(n\)</span>-dimensional subspace within the infinite-dimensional space of all functions. Any function <span class="math notranslate nohighlight">\(g\)</span> in this space can be written as <span class="math notranslate nohighlight">\(g = \sum_{i=1}^n c_i \varphi_i\)</span> for some coefficients <span class="math notranslate nohighlight">\(c_i\)</span>. If the residual <span class="math notranslate nohighlight">\(R\)</span> is orthogonal to all basis functions <span class="math notranslate nohighlight">\(\varphi_i\)</span>, then by linearity of the inner product, for any such function <span class="math notranslate nohighlight">\(g\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\langle R, g \rangle = \left\langle R, \sum_{i=1}^n c_i \varphi_i \right\rangle = \sum_{i=1}^n c_i \langle R, \varphi_i \rangle = 0.
\]</div>
<p>This shows that <span class="math notranslate nohighlight">\(R\)</span> is orthogonal to every function we can represent with our basis. The residual has “zero overlap” with our approximation space: we cannot express any part of it using our basis functions. In this sense, the residual is as “invisible” to our approximation as possible.</p>
<p>This condition is the defining property of optimality. By choosing our approximation <span class="math notranslate nohighlight">\(\hat{f}\)</span> so that the residual <span class="math notranslate nohighlight">\(R = \mathscr{N}(\hat{f})\)</span> is orthogonal to the entire approximation space, we ensure that <span class="math notranslate nohighlight">\(\hat{f}\)</span> is the orthogonal projection of the true solution onto <span class="math notranslate nohighlight">\(\text{span}{\varphi_1, \ldots, \varphi_n}\)</span>. Within this <span class="math notranslate nohighlight">\(n\)</span>-dimensional space, no better choice is possible: any other coefficients would yield a residual with a nonzero component inside the space, and therefore a larger norm.</p>
<p>The finite-dimensional analogy makes this concrete. Suppose you want to approximate a vector <span class="math notranslate nohighlight">\(\mathbf{v} \in \mathbb{R}^3\)</span> using only the <span class="math notranslate nohighlight">\(xy\)</span>-plane (a 2D subspace). The best approximation is to project <span class="math notranslate nohighlight">\(\mathbf{v}\)</span> onto the plane, giving <span class="math notranslate nohighlight">\(\hat{\mathbf{v}} = (v_1, v_2, 0)\)</span>. The error is <span class="math notranslate nohighlight">\(\mathbf{r} = \mathbf{v} - \hat{\mathbf{v}} = (0, 0, v_3)\)</span>, which points purely in the <span class="math notranslate nohighlight">\(z\)</span>-direction, orthogonal to the entire <span class="math notranslate nohighlight">\(xy\)</span>-plane. We see the Galerkin condition in action: the error is orthogonal to the approximation space.</p>
</section>
<section id="method-of-moments-test-against-monomials">
<h4>Method of Moments: Test Against Monomials<a class="headerlink" href="#method-of-moments-test-against-monomials" title="Link to this heading">#</a></h4>
<p>The method of moments, for problems on <span class="math notranslate nohighlight">\(D \subset \mathbb{R}\)</span>, chooses test functions <span class="math notranslate nohighlight">\(p_i(x) = x^{i-1}\)</span> for <span class="math notranslate nohighlight">\(i = 1, \ldots, n\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\langle R(\cdot; a), x^{i-1} \rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This requires the first <span class="math notranslate nohighlight">\(n\)</span> moments of the residual function to vanish, ensuring the residual is “balanced” in the sense that it has no systematic trend captured by low-order polynomials. The moments <span class="math notranslate nohighlight">\(\int x^k R(x; a) w(x) dx\)</span> measure weighted averages of the residual, with increasing powers of <span class="math notranslate nohighlight">\(x\)</span> giving more weight to larger values. Setting these to zero ensures the residual doesn’t grow systematically with <span class="math notranslate nohighlight">\(x\)</span>. This approach is particularly useful when <span class="math notranslate nohighlight">\(w(x)\)</span> is chosen as a probability measure, making the conditions natural moment restrictions familiar from statistics and econometrics.</p>
</section>
<section id="collocation-method-test-against-delta-functions">
<h4>Collocation Method: Test Against Delta Functions<a class="headerlink" href="#collocation-method-test-against-delta-functions" title="Link to this heading">#</a></h4>
<p>The collocation method chooses test functions <span class="math notranslate nohighlight">\(p_i(x) = \delta(x - x_i)\)</span>, the Dirac delta functions at points <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_n\}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\langle R(\cdot; a), \delta(\cdot - x_i) \rangle = R(x_i; a) = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This is projection against the most localized test functions possible: delta functions that “sample” the residual at specific points, requiring the residual to vanish exactly where we test it. When using orthogonal polynomials with collocation points at the zeros of the <span class="math notranslate nohighlight">\(n\)</span>-th polynomial, the Chebyshev interpolation theorem guarantees that forcing <span class="math notranslate nohighlight">\(R(x_i; a) = 0\)</span> at these specific points makes <span class="math notranslate nohighlight">\(R(x; a)\)</span> small everywhere. Using the zeros of orthogonal polynomials as collocation points produces well-conditioned systems and near-optimal interpolation error. The computational advantage is significant. Collocation avoids numerical integration entirely, requiring only pointwise evaluation of <span class="math notranslate nohighlight">\(R\)</span>.</p>
</section>
<section id="subdomain-method-test-against-indicator-functions">
<h4>Subdomain Method: Test Against Indicator Functions<a class="headerlink" href="#subdomain-method-test-against-indicator-functions" title="Link to this heading">#</a></h4>
<p>The subdomain method partitions the domain into <span class="math notranslate nohighlight">\(n\)</span> subregions <span class="math notranslate nohighlight">\(\{D_1, \ldots, D_n\}\)</span> and chooses test functions <span class="math notranslate nohighlight">\(p_i = I_{D_i}\)</span>, the indicator functions:</p>
<div class="math notranslate nohighlight">
\[
\langle R(\cdot; a), I_{D_i} \rangle = \int_{D_i} R(x; a) w(x) dx = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This requires the residual to have zero average over each subdomain, ensuring the approximation is good “on average” over each piece of the domain. This approach is particularly natural for finite element methods where the domain is divided into elements, ensuring local balance of the residual within each element.</p>
</section>
<section id="least-squares">
<h4>Least Squares<a class="headerlink" href="#least-squares" title="Link to this heading">#</a></h4>
<p>The least squares approach doesn’t fit the test function framework directly. Instead, we minimize:</p>
<div class="math notranslate nohighlight">
\[
\min_a \int_{\mathcal{S}} R(x; a)^2 w(x) dx = \min_a \langle R(\cdot; a), R(\cdot; a) \rangle.
\]</div>
<p>The first-order conditions for this minimization problem are:</p>
<div class="math notranslate nohighlight">
\[
\left\langle R(\cdot; a), \frac{\partial R(\cdot; a)}{\partial a_i} \right\rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>Thus least squares implicitly uses test functions <span class="math notranslate nohighlight">\(p_i = \partial R / \partial a_i\)</span>, the gradients of the residual with respect to parameters. Unlike other methods where test functions are chosen a priori, here they depend on the current guess for <span class="math notranslate nohighlight">\(a\)</span> and on the structure of our approximation.</p>
<p>We can now see the unifying structure of <strong>weighted residual methods</strong>: whether we use projection conditions or least squares minimization, all these methods follow the same template of restricting the search to an <span class="math notranslate nohighlight">\(n\)</span>-dimensional function space and imposing <span class="math notranslate nohighlight">\(n\)</span> conditions on the residual. For projection methods specifically, we pick <span class="math notranslate nohighlight">\(n\)</span> test functions and require <span class="math notranslate nohighlight">\(\langle R, p_i \rangle = 0\)</span>. They differ only in their philosophy about which test functions best detect whether the residual is “nearly zero.” Galerkin tests against the approximation basis itself (natural for orthogonal bases), the method of moments tests against monomials (ensuring polynomial balance), collocation tests against delta functions (pointwise satisfaction), subdomain tests against indicators (local average satisfaction), and least squares tests against residual gradients (global norm minimization). Each choice reflects different priorities: computational efficiency, theoretical optimality, ease of implementation, or sensitivity to errors in different regions of the domain.</p>
</section>
</section>
<section id="step-4-solve-the-finite-dimensional-problem">
<h3>Step 4: Solve the Finite-Dimensional Problem<a class="headerlink" href="#step-4-solve-the-finite-dimensional-problem" title="Link to this heading">#</a></h3>
<p>The projection conditions give us a system to solve for the coefficients <span class="math notranslate nohighlight">\(a\)</span>. For test function methods (Galerkin, collocation, moments, subdomain), we solve:</p>
<div class="math notranslate nohighlight">
\[
P_i(a) \equiv \langle R(\cdot; a), p_i \rangle = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This is a system of <span class="math notranslate nohighlight">\(n\)</span> (generally nonlinear) equations in <span class="math notranslate nohighlight">\(n\)</span> unknowns. For least squares, we solve the optimization problem <span class="math notranslate nohighlight">\(\min_a \langle R(\cdot; a), R(\cdot; a) \rangle\)</span>.</p>
<p>The <strong>conditioning</strong> of the system depends on the choice of test functions. The Jacobian matrix has entries:</p>
<div class="math notranslate nohighlight">
\[
J_{ij} = \frac{\partial P_i}{\partial a_j} = \left\langle \frac{\partial R(\cdot; a)}{\partial a_j}, p_i \right\rangle.
\]</div>
<p>When test functions are orthogonal (or nearly so), the Jacobian tends to be well-conditioned. This is why orthogonal polynomial bases are preferred in Galerkin methods: they produce Jacobians with controlled condition numbers.</p>
<p>The <strong>computational cost per iteration</strong> varies significantly:</p>
<ul class="simple">
<li><p><strong>Collocation</strong>: Cheapest to evaluate since <span class="math notranslate nohighlight">\(P_i(a) = R(x_i; a)\)</span> requires only pointwise evaluation (no integration). The Jacobian is also cheap: <span class="math notranslate nohighlight">\(J_{ij} = \frac{\partial R(x_i; a)}{\partial a_j}\)</span>.</p></li>
<li><p><strong>Galerkin and moments</strong>: More expensive due to integration. Computing <span class="math notranslate nohighlight">\(P_i(a) = \int R(x; a) p_i(x) w(x) dx\)</span> requires numerical quadrature. Each Jacobian entry requires integrating <span class="math notranslate nohighlight">\(\frac{\partial R}{\partial a_j} p_i\)</span>.</p></li>
<li><p><strong>Least squares</strong>: Most expensive when done via the objective function, which requires integrating <span class="math notranslate nohighlight">\(R^2\)</span>. However, the first-order conditions reduce it to a system like Galerkin, with test functions <span class="math notranslate nohighlight">\(p_i = \partial R / \partial a_i\)</span>.</p></li>
</ul>
<p>For methods requiring integration, the choice of quadrature rule should match the basis. Gaussian quadrature with nodes at orthogonal polynomial zeros is efficient. When combined with collocation at those same points, the quadrature is exact for polynomials up to a certain degree. This coordination between quadrature and collocation makes <strong>orthogonal collocation</strong> effective.</p>
<p>The choice of solver depends on whether the finite-dimensional approximation preserves the structural properties of the original infinite-dimensional problem. This matters for the Bellman equation, where the original operator <span class="math notranslate nohighlight">\(\mathrm{L}\)</span> is a contraction.</p>
<p><strong>Successive approximation</strong> (fixed-point iteration) is the natural choice when the original operator is a contraction, as it preserves the global convergence guarantees. However, the finite-dimensional approximation <span class="math notranslate nohighlight">\(\hat{\mathrm{L}}\)</span> may not inherit the contraction property of <span class="math notranslate nohighlight">\(\mathrm{L}\)</span>. The approximation can introduce spurious fixed points or destroy the contraction constant, leading to divergence or slow convergence. This is especially problematic when using high-order polynomial approximations, which can create artificial oscillations that destabilize the iteration.</p>
<p><strong>Newton’s method</strong> is often the default choice for projection methods because it doesn’t rely on the contraction property. Instead, it exploits the smoothness of the residual function. When the original problem is smooth and the approximation preserves this smoothness, Newton’s method provides quadratic convergence near the solution. However, Newton’s method requires good initial guesses and may converge to spurious solutions if the finite-dimensional problem has multiple fixed points that the original problem lacks.</p>
<p>The choice of basis and projection method affects which algorithm is most appropriate. For example:</p>
<ul class="simple">
<li><p><strong>Linear interpolation</strong> often preserves contraction properties, making successive approximation reliable</p></li>
<li><p><strong>High-order polynomials</strong> may destroy contraction but provide smooth approximations suitable for Newton’s method</p></li>
<li><p><strong>Shape-preserving splines</strong> can maintain both smoothness and structural properties</p></li>
</ul>
<p>In practice, which algorithm should we use? When the operator equation can be written as a fixed-point problem <span class="math notranslate nohighlight">\(f = \mathscr{T}f\)</span> and the operator <span class="math notranslate nohighlight">\(\mathscr{T}\)</span> is known to be a contraction, successive approximation is often the best starting point: it is computationally cheap and globally convergent. However, not all equations <span class="math notranslate nohighlight">\(\mathscr{N}(f) = 0\)</span> admit a natural fixed-point reformulation, and even when they do (e.g., <span class="math notranslate nohighlight">\(f = f - \alpha \mathscr{N}(f)\)</span> for some <span class="math notranslate nohighlight">\(\alpha &gt; 0\)</span>), the resulting operator may not be a contraction in the finite-dimensional approximation space. In such cases, Newton’s method becomes the primary option despite its requirement for good initial guesses and higher computational cost per iteration. A hybrid approach often works well: use successive approximation when applicable to generate an initial guess, then switch to Newton’s method for refinement.</p>
<p>Another consideration is the conditioning of the resulting system. Poorly chosen basis functions or collocation points can lead to nearly singular Jacobians, causing numerical instability. Orthogonal bases and carefully chosen collocation points (like Chebyshev nodes) are preferred because they tend to produce well-conditioned systems.</p>
</section>
<section id="step-5-verify-the-solution">
<h3>Step 5: Verify the Solution<a class="headerlink" href="#step-5-verify-the-solution" title="Link to this heading">#</a></h3>
<p>Once we have computed a candidate solution <span class="math notranslate nohighlight">\(\hat{f}\)</span>, we must verify its quality. Projection methods optimize <span class="math notranslate nohighlight">\(\hat{f}\)</span> with respect to specific criteria (specific test functions or collocation points), but we should check that the residual is small everywhere, including directions or points we did not optimize over.</p>
<p>Typical diagnostic checks include:</p>
<ul class="simple">
<li><p>Computing <span class="math notranslate nohighlight">\(\|R(\cdot; a)\|\)</span> using a more accurate quadrature rule than was used in the optimization</p></li>
<li><p>Evaluating <span class="math notranslate nohighlight">\(R(x; a)\)</span> at many points not used in the fitting process</p></li>
<li><p>If using Galerkin with the first <span class="math notranslate nohighlight">\(n\)</span> basis functions, checking orthogonality against higher-order basis functions</p></li>
</ul>
</section>
</section>
<section id="application-to-the-bellman-equation">
<h2>Application to the Bellman Equation<a class="headerlink" href="#application-to-the-bellman-equation" title="Link to this heading">#</a></h2>
<p>We now apply the projection method framework to the Bellman optimality equation. Recall that we seek a function <span class="math notranslate nohighlight">\(v\)</span> satisfying</p>
<div class="math notranslate nohighlight">
\[
v(s) = \mathrm{L}v(s) = \max_{a \in \mathcal{A}_s} \left\{ r(s,a) + \gamma \sum_{j \in \mathcal{S}} p(j|s,a) v(j) \right\}.
\]</div>
<p>Writing this as an operator equation <span class="math notranslate nohighlight">\(\mathscr{N}(v) = 0\)</span> with <span class="math notranslate nohighlight">\(\mathscr{N}(v) = \mathrm{L}v - v\)</span>, the residual function for a candidate approximation <span class="math notranslate nohighlight">\(\hat{v}(s) = \sum_{i=1}^n a_i \varphi_i(s)\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
R(s; a) = \mathrm{L}\hat{v}(s) - \hat{v}(s) = \max_{a \in \mathcal{A}_s} \left\{ r(s,a) + \gamma \sum_{j \in \mathcal{S}} p(j|s,a) \hat{v}(j) \right\} - \sum_{i=1}^n a_i \varphi_i(s).
\]</div>
<p>Any of the projection methods we discussed (Galerkin, method of moments, collocation, subdomain, or least squares) can be applied here. Each would give us <span class="math notranslate nohighlight">\(n\)</span> conditions to determine the <span class="math notranslate nohighlight">\(n\)</span> coefficients in our approximation. For instance:</p>
<ul class="simple">
<li><p><strong>Galerkin</strong> would require <span class="math notranslate nohighlight">\(\langle R(\cdot; a), \varphi_i \rangle = 0\)</span> for <span class="math notranslate nohighlight">\(i = 1, \ldots, n\)</span>, involving integration of the residual weighted by basis functions</p></li>
<li><p><strong>Method of moments</strong> would require <span class="math notranslate nohighlight">\(\langle R(\cdot; a), s^{i-1} \rangle = 0\)</span>, setting the first <span class="math notranslate nohighlight">\(n\)</span> moments of the residual to zero</p></li>
<li><p><strong>Collocation</strong> would require <span class="math notranslate nohighlight">\(R(s_i; a) = 0\)</span> at <span class="math notranslate nohighlight">\(n\)</span> chosen states, forcing the residual to vanish pointwise</p></li>
</ul>
<p>In practice, <strong>collocation is the most commonly used</strong> projection method for the Bellman equation. The reason is computational: collocation avoids the numerical integration required by Galerkin and method of moments. Since the Bellman operator already involves integration (or summation) over next states, adding another layer of integration for the projection conditions would be computationally expensive. Collocation sidesteps this by requiring the equation to hold exactly at specific points.</p>
<p>We focus on collocation in detail, though the principles extend to other projection methods.</p>
<section id="collocation-for-the-bellman-equation">
<h3>Collocation for the Bellman Equation<a class="headerlink" href="#collocation-for-the-bellman-equation" title="Link to this heading">#</a></h3>
<p>The collocation approach chooses <span class="math notranslate nohighlight">\(n\)</span> states <span class="math notranslate nohighlight">\(\{s_1, \ldots, s_n\}\)</span> (the collocation points) and requires:</p>
<div class="math notranslate nohighlight">
\[
R(s_i; a) = 0, \quad i = 1, \ldots, n.
\]</div>
<p>This gives us a system of <span class="math notranslate nohighlight">\(n\)</span> nonlinear equations in <span class="math notranslate nohighlight">\(n\)</span> unknowns:</p>
<div class="math notranslate nohighlight">
\[
\sum_{j=1}^n a_j \varphi_j(s_i) = \max_{a \in \mathcal{A}_{s_i}} \left\{ r(s_i,a) + \gamma \sum_{j \in \mathcal{S}} p(j|s_i,a) \hat{v}(j) \right\}, \quad i = 1, \ldots, n.
\]</div>
<p>The right-hand side requires evaluating the Bellman operator at the collocation points. For each collocation point <span class="math notranslate nohighlight">\(s_i\)</span>, we must:</p>
<ol class="arabic simple">
<li><p>For each action <span class="math notranslate nohighlight">\(a \in \mathcal{A}_{s_i}\)</span>, compute the expected continuation value <span class="math notranslate nohighlight">\(\sum_{j \in \mathcal{S}} p(j|s_i,a) \hat{v}(j)\)</span></p></li>
<li><p>Take the maximum over actions</p></li>
</ol>
<p>When the state space is continuous, the expectation involves integration, which typically requires numerical quadrature. When the state space is discrete but large, this is a straightforward (though potentially expensive) summation.</p>
<section id="solving-the-collocation-system">
<h4>Solving the Collocation System<a class="headerlink" href="#solving-the-collocation-system" title="Link to this heading">#</a></h4>
<p>To organize our thinking about solution methods, it helps to introduce the <strong>collocation function</strong> <span class="math notranslate nohighlight">\(v: \mathbb{R}^n \to \mathbb{R}^n\)</span>, which maps coefficient vectors to target values at the collocation points. Given a coefficient vector <span class="math notranslate nohighlight">\(a = (a_1, \ldots, a_n)\)</span>, the <span class="math notranslate nohighlight">\(i\)</span>-th component of <span class="math notranslate nohighlight">\(v(a)\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[
v_i(a) = \max_{u \in \mathcal{A}_{s_i}} \left\{ r(s_i, u) + \gamma \sum_{j \in \mathcal{S}} p(j|s_i, u) \sum_{\ell=1}^n a_\ell \varphi_\ell(j) \right\}.
\]</div>
<p>In words: <span class="math notranslate nohighlight">\(v_i(a)\)</span> is the value obtained by solving the Bellman maximization problem at collocation node <span class="math notranslate nohighlight">\(s_i\)</span>, using the approximation <span class="math notranslate nohighlight">\(\hat{v}(s; a) = \sum_{\ell=1}^n a_\ell \varphi_\ell(s)\)</span> in place of the true value function. The collocation function evaluates the <strong>right-hand side</strong> of the Bellman equation at all collocation points, given a current guess for the coefficients.</p>
<p>Let <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span> denote the <span class="math notranslate nohighlight">\(n \times n\)</span> <strong>collocation matrix</strong> with entries <span class="math notranslate nohighlight">\(\Phi_{ij} = \varphi_j(s_i)\)</span>. The <strong>left-hand side</strong> of the collocation equations is <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a\)</span>, which gives the values of <span class="math notranslate nohighlight">\(\hat{v}(s_i; a)\)</span> at the collocation points. The collocation equation requires these to match:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\Phi} a = v(a).
\]</div>
<p>This is the fixed-point problem we need to solve. We can approach it in two fundamentally different ways: as a <strong>fixed-point iteration</strong> (function iteration) or as a <strong>rootfinding problem</strong> (Newton’s method).</p>
</section>
</section>
<section id="method-1-function-iteration-successive-approximation">
<h3>Method 1: Function Iteration (Successive Approximation)<a class="headerlink" href="#method-1-function-iteration-successive-approximation" title="Link to this heading">#</a></h3>
<p>We can rewrite the collocation equation as <span class="math notranslate nohighlight">\(a = \boldsymbol{\Phi}^{-1} v(a)\)</span> (assuming <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span> is invertible, which holds when the basis functions are linearly independent at the collocation points). This suggests the <strong>function iteration</strong> scheme:</p>
<div class="math notranslate nohighlight">
\[
a^{(k+1)} = \boldsymbol{\Phi}^{-1} v(a^{(k)}).
\]</div>
<p>This iteration has an intuitive interpretation when we break it into two steps:</p>
<p><strong>Step 1 (Apply Bellman operator):</strong> For the current coefficient guess <span class="math notranslate nohighlight">\(a^{(k)}\)</span>, compute the Bellman operator values at all collocation points:</p>
<div class="math notranslate nohighlight">
\[
t_i^{(k)} = v_i(a^{(k)}) = \max_{u \in \mathcal{A}_{s_i}} \left\{ r(s_i, u) + \gamma \sum_{j \in \mathcal{S}} p(j|s_i, u) \sum_{\ell=1}^n a^{(k)}_\ell \varphi_\ell(j) \right\}, \quad i = 1, \ldots, n.
\]</div>
<p>We now have a vector of <strong>targets</strong> <span class="math notranslate nohighlight">\(t^{(k)} = (t_1^{(k)}, \ldots, t_n^{(k)}) = v(a^{(k)})\)</span>.</p>
<p><strong>Step 2 (Fit to targets):</strong> Find new coefficients <span class="math notranslate nohighlight">\(a^{(k+1)}\)</span> such that the approximation matches the targets at the collocation points:</p>
<div class="math notranslate nohighlight">
\[
\sum_{\ell=1}^n a^{(k+1)}_\ell \varphi_\ell(s_i) = t_i^{(k)}, \quad i = 1, \ldots, n.
\]</div>
<p>In matrix form: <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a^{(k+1)} = t^{(k)}\)</span>, which gives <span class="math notranslate nohighlight">\(a^{(k+1)} = \boldsymbol{\Phi}^{-1} t^{(k)} = \boldsymbol{\Phi}^{-1} v(a^{(k)})\)</span>.</p>
<p>This is <strong>parametric value iteration</strong> or <strong>projection-based value iteration</strong>: we iterate the Bellman operator in the finite-dimensional coefficient space, projecting back onto the span of the basis functions at each step. The method:</p>
<ul class="simple">
<li><p>Separates the nonlinear optimization (maximization in the Bellman operator) from the linear fitting problem</p></li>
<li><p>Is globally convergent when the finite-dimensional approximation preserves the contraction property</p></li>
<li><p>Requires only solving a linear system <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a^{(k+1)} = t^{(k)}\)</span> at each iteration</p></li>
</ul>
<div class="note admonition">
<p class="admonition-title">Handling Stochastic Expectations</p>
<p>When the model includes a continuous random variable (e.g., <span class="math notranslate nohighlight">\(s' = g(s, u, \epsilon)\)</span> where <span class="math notranslate nohighlight">\(\epsilon\)</span> is a shock), we must approximate the expectation using <strong>numerical quadrature</strong>. We replace the continuous <span class="math notranslate nohighlight">\(\epsilon\)</span> with a discrete approximation taking values <span class="math notranslate nohighlight">\(\{\epsilon_1, \ldots, \epsilon_m\}\)</span> with probabilities <span class="math notranslate nohighlight">\(\{w_1, \ldots, w_m\}\)</span>. The collocation function becomes:</p>
<div class="math notranslate nohighlight">
\[
v_i(a) = \max_{u \in \mathcal{A}_{s_i}} \left\{ r(s_i, u) + \gamma \sum_{k=1}^m w_k \sum_{\ell=1}^n a_\ell \varphi_\ell(g(s_i, u, \epsilon_k)) \right\}.
\]</div>
<p>Common quadrature schemes include Gauss-Hermite (for normal shocks), Gauss-Legendre (for uniform shocks), or sparse grids for high-dimensional shocks.</p>
</div>
</section>
<section id="method-2-newton-s-method-with-the-envelope-theorem">
<h3>Method 2: Newton’s Method with the Envelope Theorem<a class="headerlink" href="#method-2-newton-s-method-with-the-envelope-theorem" title="Link to this heading">#</a></h3>
<p>Alternatively, we can write the collocation equation as a <strong>rootfinding problem</strong>:</p>
<div class="math notranslate nohighlight">
\[
F(a) \equiv \boldsymbol{\Phi} a - v(a) = 0.
\]</div>
<p>Newton’s method for this system uses the update:</p>
<div class="math notranslate nohighlight">
\[
a^{(k+1)} = a^{(k)} - J_F(a^{(k)})^{-1} F(a^{(k)}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(J_F(a)\)</span> is the Jacobian of <span class="math notranslate nohighlight">\(F\)</span> at <span class="math notranslate nohighlight">\(a\)</span>. Since <span class="math notranslate nohighlight">\(J_F = \boldsymbol{\Phi} - J_v\)</span> where <span class="math notranslate nohighlight">\(J_v\)</span> is the Jacobian of the collocation function <span class="math notranslate nohighlight">\(v\)</span>, we can rewrite this as:</p>
<div class="math notranslate nohighlight">
\[
a^{(k+1)} = a^{(k)} - [\boldsymbol{\Phi} - J_v(a^{(k)})]^{-1} [\boldsymbol{\Phi} a^{(k)} - v(a^{(k)})].
\]</div>
<p>The main challenge now is computing the Jacobian <span class="math notranslate nohighlight">\(J_v(a)\)</span>. The <span class="math notranslate nohighlight">\((i,j)\)</span>-th entry is:</p>
<div class="math notranslate nohighlight">
\[
[J_v]_{ij} = \frac{\partial v_i}{\partial a_j}(a) = \frac{\partial}{\partial a_j} \left[ \max_{u \in \mathcal{A}_{s_i}} \left\{ r(s_i, u) + \gamma \sum_{k \in \mathcal{S}} p(k|s_i, u) \sum_{\ell=1}^n a_\ell \varphi_\ell(k) \right\} \right].
\]</div>
<p>At first glance, this appears problematic because the max operator is not differentiable. However, we can apply the <strong>Envelope Theorem</strong> to compute this derivative without dealing with the non-differentiability of the max operator.</p>
<div class="important admonition">
<p class="admonition-title">The Envelope Theorem</p>
<p><strong>Setup:</strong> Consider a smooth objective function <span class="math notranslate nohighlight">\(f(\mathbf{x}, \boldsymbol{\theta})\)</span> and define the optimal value:</p>
<div class="math notranslate nohighlight">
\[
v(\boldsymbol{\theta}) = \max_{\mathbf{x}} f(\mathbf{x}, \boldsymbol{\theta}).
\]</div>
<p>Let <span class="math notranslate nohighlight">\(\mathbf{x}(\boldsymbol{\theta})\)</span> denote the maximizer, satisfying the first-order condition:</p>
<div class="math notranslate nohighlight">
\[
\nabla_{\mathbf{x}} f(\mathbf{x}(\boldsymbol{\theta}), \boldsymbol{\theta}) = \mathbf{0}.
\]</div>
<p><strong>The Result:</strong> To find how the <strong>optimal value</strong> changes with <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, write <span class="math notranslate nohighlight">\(v(\boldsymbol{\theta}) = f(\mathbf{x}(\boldsymbol{\theta}), \boldsymbol{\theta})\)</span> and apply the chain rule:</p>
<div class="math notranslate nohighlight">
\[
\nabla_{\boldsymbol{\theta}} v(\boldsymbol{\theta}) = \underbrace{\nabla_{\boldsymbol{\theta}} f(\mathbf{x}(\boldsymbol{\theta}), \boldsymbol{\theta})}_{\text{direct effect}} + \underbrace{\nabla_{\mathbf{x}} f(\mathbf{x}(\boldsymbol{\theta}), \boldsymbol{\theta})^{\top}}_{\mathbf{0} \text{ at optimum}} \frac{\partial \mathbf{x}}{\partial \boldsymbol{\theta}}.
\]</div>
<p>Since <span class="math notranslate nohighlight">\(\nabla_{\mathbf{x}} f = \mathbf{0}\)</span> at the optimum, the second term vanishes:</p>
<div class="math notranslate nohighlight">
\[
\boxed{\nabla_{\boldsymbol{\theta}} v(\boldsymbol{\theta}) = \nabla_{\boldsymbol{\theta}} f(\mathbf{x}(\boldsymbol{\theta}), \boldsymbol{\theta})}.
\]</div>
<p>This results tells us that you can compute the derivative of the optimal value by treating the maximizer as constant. You don’t need to compute <span class="math notranslate nohighlight">\(\frac{\partial \mathbf{x}}{\partial \boldsymbol{\theta}}\)</span>.</p>
<p>In our Bellman collocation problem, <span class="math notranslate nohighlight">\(v_i(a) = \max_u \{r(s_i, u) + \gamma \mathbb{E}[\sum_\ell a_\ell \varphi_\ell(s')]\}\)</span>. To compute <span class="math notranslate nohighlight">\(\frac{\partial v_i}{\partial a_j}\)</span>, we don’t need to figure out how <span class="math notranslate nohighlight">\(u_i^*(a)\)</span> changes with <span class="math notranslate nohighlight">\(a\)</span>. We just evaluate the gradient at the optimal action:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial v_i}{\partial a_j}(a) = \gamma \sum_{s'} p(s'|s_i, u_i^*(a)) \varphi_j(s').
\]</div>
<p><strong>Important assumptions:</strong> <span class="math notranslate nohighlight">\(f\)</span> is smooth, the maximizer is unique and in the interior (or constraints are smooth with stable active sets), and the first-order condition holds.</p>
</div>
<p>Specifically, let <span class="math notranslate nohighlight">\(u_i^*(a)\)</span> denote the optimal action at collocation point <span class="math notranslate nohighlight">\(s_i\)</span> given coefficients <span class="math notranslate nohighlight">\(a\)</span>:</p>
<div class="math notranslate nohighlight">
\[
u_i^*(a) \in \operatorname{argmax}_{u \in \mathcal{A}_{s_i}} \left\{ r(s_i, u) + \gamma \sum_{k \in \mathcal{S}} p(k|s_i, u) \sum_{\ell=1}^n a_\ell \varphi_\ell(k) \right\}.
\]</div>
<p>By the Envelope Theorem, we can compute the derivative by treating <span class="math notranslate nohighlight">\(u_i^*\)</span> as constant:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial v_i}{\partial a_j}(a) = \gamma \sum_{k \in \mathcal{S}} p(k|s_i, u_i^*(a)) \varphi_j(k).
\]</div>
<p>This is simply the <strong>expected value of the <span class="math notranslate nohighlight">\(j\)</span>-th basis function at the next state</strong>, evaluated at the optimal action for the current coefficient vector.</p>
<div class="dropdown admonition">
<p class="admonition-title">Why the Envelope Theorem Works Here</p>
<p>The Envelope Theorem applies to value functions of optimization problems. For a problem <span class="math notranslate nohighlight">\(V(\theta) = \max_x f(x, \theta)\)</span>, the derivative with respect to the parameter <span class="math notranslate nohighlight">\(\theta\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
\frac{dV}{d\theta} = \frac{\partial f}{\partial \theta}(x^*(\theta), \theta),
\]</div>
<p>where <span class="math notranslate nohighlight">\(x^*(\theta)\)</span> is the optimal choice. We don’t need to account for <span class="math notranslate nohighlight">\(\frac{\partial x^*}{\partial \theta}\)</span> because at the optimum, the first-order condition <span class="math notranslate nohighlight">\(\frac{\partial f}{\partial x} = 0\)</span> makes that term vanish.</p>
<p>In our case, <span class="math notranslate nohighlight">\(v_i(a)\)</span> is the value of maximizing over actions <span class="math notranslate nohighlight">\(u\)</span>, with <span class="math notranslate nohighlight">\(a\)</span> playing the role of the parameter vector. The Envelope Theorem lets us compute <span class="math notranslate nohighlight">\(\frac{\partial v_i}{\partial a_j}\)</span> by differentiating the objective (the Bellman right-hand side) with respect to <span class="math notranslate nohighlight">\(a_j\)</span> while holding the optimal action <span class="math notranslate nohighlight">\(u_i^*\)</span> fixed. Since <span class="math notranslate nohighlight">\(a_j\)</span> only appears in the continuation value <span class="math notranslate nohighlight">\(\sum_{\ell} a_\ell \varphi_\ell(k)\)</span>, the derivative picks out the coefficient of <span class="math notranslate nohighlight">\(a_j\)</span>, which is the expected basis function value.</p>
<p>This approach is <strong>equivalent</strong> to the semi-smooth Newton method mentioned earlier: we’re computing a generalized Jacobian by treating the optimal action as locally constant. As we converge to the solution, the optimal actions stabilize, and Newton’s method achieves superlinear convergence.</p>
</div>
<p><strong>Newton’s method algorithm:</strong></p>
<ol class="arabic simple">
<li><p>Start with initial guess <span class="math notranslate nohighlight">\(a^{(0)}\)</span></p></li>
<li><p>For iteration <span class="math notranslate nohighlight">\(k = 0, 1, 2, \ldots\)</span>:</p>
<ul class="simple">
<li><p>Compute <span class="math notranslate nohighlight">\(v(a^{(k)})\)</span> and optimal actions <span class="math notranslate nohighlight">\(u_i^*(a^{(k)})\)</span> for all collocation points</p></li>
<li><p>Compute Jacobian entries: <span class="math notranslate nohighlight">\([J_v]_{ij} = \gamma \sum_{s' \in \mathcal{S}} p(s'|s_i, u_i^*(a^{(k)})) \varphi_j(s')\)</span></p></li>
<li><p>Update: <span class="math notranslate nohighlight">\(a^{(k+1)} = a^{(k)} - [\boldsymbol{\Phi} - J_v(a^{(k)})]^{-1} [\boldsymbol{\Phi} a^{(k)} - v(a^{(k)})]\)</span></p></li>
<li><p>Check convergence</p></li>
</ul>
</li>
</ol>
<p>This method offers <strong>quadratic convergence</strong> near the solution but requires a good initial guess. The Jacobian computation via the Envelope Theorem is typically cheaper than explicit semi-smooth calculus and has a clear economic interpretation: it tracks how the value propagates through the optimal decisions.</p>
<section id="comparison-of-solution-methods">
<h4>Comparison of Solution Methods<a class="headerlink" href="#comparison-of-solution-methods" title="Link to this heading">#</a></h4>
<p>We now have two approaches to solving the collocation fixed-point equation <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a = v(a)\)</span>:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Method</strong></p></th>
<th class="head text-left"><p><strong>Formulation</strong></p></th>
<th class="head text-left"><p><strong>Convergence</strong></p></th>
<th class="head text-left"><p><strong>Per-iteration cost</strong></p></th>
<th class="head text-left"><p><strong>Initial guess sensitivity</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Function iteration</strong></p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(a^{(k+1)} = \boldsymbol{\Phi}^{-1} v(a^{(k)})\)</span></p></td>
<td class="text-left"><p>Linear (when contraction holds)</p></td>
<td class="text-left"><p>Low (one linear solve)</p></td>
<td class="text-left"><p>Robust</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Newton’s method</strong></p></td>
<td class="text-left"><p><span class="math notranslate nohighlight">\(a^{(k+1)} = a^{(k)} - [\boldsymbol{\Phi} - J_v]^{-1}[\boldsymbol{\Phi} a^{(k)} - v(a^{(k)})]\)</span></p></td>
<td class="text-left"><p>Quadratic (near solution)</p></td>
<td class="text-left"><p>Moderate (Jacobian + linear solve)</p></td>
<td class="text-left"><p>Requires good initial guess</p></td>
</tr>
</tbody>
</table>
</div>
<p><strong>Function iteration</strong> exploits the fixed-point structure directly, treating the collocation problem as value iteration in coefficient space. When the finite-dimensional approximation preserves the contraction property of the Bellman operator, it converges globally from any initial guess. Each iteration is cheap: evaluate the Bellman operator at <span class="math notranslate nohighlight">\(n\)</span> points (the collocation nodes) and solve one linear system <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a^{(k+1)} = v(a^{(k)})\)</span>. However, convergence can be slow, especially when <span class="math notranslate nohighlight">\(\gamma\)</span> is close to 1.</p>
<p><strong>Newton’s method</strong> treats the problem as rootfinding, exploiting smoothness (via the Envelope Theorem) to achieve fast local convergence. Once close to the solution, Newton’s method typically converges in just a few iterations. The per-iteration cost is higher: in addition to evaluating <span class="math notranslate nohighlight">\(v(a^{(k)})\)</span>, we must compute the Jacobian <span class="math notranslate nohighlight">\(J_v(a^{(k)})\)</span>, which requires evaluating expected basis function values at all collocation points. However, Newton’s method is sensitive to initial conditions and may diverge or converge to spurious solutions when started far from the true fixed point.</p>
<div class="note admonition">
<p class="admonition-title">Connection to Policy Iteration</p>
<p>The Newton update <span class="math notranslate nohighlight">\(a^{(k+1)} = [\boldsymbol{\Phi} - J_v(a^{(k)})]^{-1} v(a^{(k)})\)</span> is equivalent to the <strong>policy iteration</strong> algorithm commonly used in discrete-state dynamic programming. To see this, note that at the optimal coefficients <span class="math notranslate nohighlight">\(a^*\)</span>, we have <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a^* = v(a^*)\)</span>. The Newton step finds the coefficients that would be optimal if the policy (the optimal actions at each collocation point) were held fixed at the current iteration’s policy. This connection explains why Newton’s method often converges rapidly: like policy iteration, it implicitly performs policy evaluation and policy improvement, which can converge in just a few iterations for well-behaved problems.</p>
</div>
<p><strong>Practical recommendations:</strong></p>
<ol class="arabic simple">
<li><p><strong>For problems with strong contraction</strong> (small <span class="math notranslate nohighlight">\(\gamma\)</span>, well-conditioned <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span>, shape-preserving bases): Start with function iteration. It’s simple, robust, and often converges adequately in 20-50 iterations.</p></li>
<li><p><strong>For problems with weak contraction</strong> (large <span class="math notranslate nohighlight">\(\gamma\)</span>, high-order polynomial bases): Use a <strong>hybrid approach</strong>:</p>
<ul class="simple">
<li><p>Run function iteration for 5-10 iterations to get into the basin of attraction</p></li>
<li><p>Switch to Newton’s method for fast convergence to high accuracy</p></li>
</ul>
</li>
<li><p><strong>For problems where contraction fails</strong> (non-monotone bases, approximation destroys contraction): Newton’s method may be necessary from the start, but requires careful initialization (e.g., from a coarser approximation).</p></li>
<li><p><strong>Quasi-Newton methods</strong> (like BFGS or Broyden) offer a middle ground: they approximate the Jacobian using function evaluations only, avoiding the Envelope Theorem calculation. This can be useful when computing <span class="math notranslate nohighlight">\(J_v\)</span> is expensive or when the Jacobian approximation is acceptable.</p></li>
</ol>
<p>The choice often depends on the application domain. In economic models where the value function is guaranteed to be concave and monotone, simple bases (linear interpolation, shape-preserving splines) combined with function iteration are reliable. In control problems with complex dynamics, high-order approximations combined with Newton’s method may be necessary for accuracy.</p>
</section>
</section>
<section id="shape-preserving-considerations">
<h3>Shape-Preserving Considerations<a class="headerlink" href="#shape-preserving-considerations" title="Link to this heading">#</a></h3>
<p>In dynamic programming, the value function typically has specific structural properties that we want our approximation to preserve. For instance:</p>
<ul class="simple">
<li><p><strong>Monotonicity</strong>: If having more of a resource is better, the value function should be increasing</p></li>
<li><p><strong>Concavity</strong>: Diminishing returns often imply concave value functions</p></li>
<li><p><strong>Boundedness</strong>: The value function is bounded when rewards are bounded</p></li>
</ul>
<p>Standard polynomial approximation does not automatically preserve these properties. A polynomial fit to increasing, concave data points can produce a function with non-monotonic or convex regions between the data points. This can destabilize the iterative algorithm: artificially high values at non-collocation points can lead to poor decisions in the maximization step, which feeds back into even worse approximations.</p>
<p><strong>Shape-preserving approximation methods</strong> address this issue. For one-dimensional problems, Schumaker’s shape-preserving quadratic splines maintain monotonicity and concavity while providing continuously differentiable approximations. For multidimensional problems, linear interpolation on simplices preserves monotonicity and convex combinations (though not concavity or smoothness).</p>
<p>The trade-off is between smoothness and shape preservation. Smooth approximations (high-order polynomials or splines) enable efficient optimization in the maximization step through gradient-based methods, but risk introducing spurious features. Simple approximations (linear interpolation) guarantee shape preservation but introduce kinks that complicate optimization and may produce discontinuous policies when the true policy is continuous.</p>
</section>
</section>
<section id="monotone-projection-and-the-preservation-of-contraction">
<h2>Monotone Projection and the Preservation of Contraction<a class="headerlink" href="#monotone-projection-and-the-preservation-of-contraction" title="Link to this heading">#</a></h2>
<p>The informal discussion of shape preservation hints at a deeper theoretical question: <strong>when does the function iteration method converge?</strong> Recall from our discussion of collocation that function iteration proceeds in two steps:</p>
<ol class="arabic simple">
<li><p>Apply the Bellman operator at collocation points: <span class="math notranslate nohighlight">\(t^{(k)} = v(a^{(k)})\)</span> where <span class="math notranslate nohighlight">\(t_i^{(k)} = \mathrm{L}\hat{v}^{(k)}(s_i)\)</span></p></li>
<li><p>Fit new coefficients to match these targets: <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} a^{(k+1)} = t^{(k)}\)</span>, giving <span class="math notranslate nohighlight">\(a^{(k+1)} = \boldsymbol{\Phi}^{-1} v(a^{(k)})\)</span></p></li>
</ol>
<p>We can reinterpret this iteration in <strong>function space</strong> rather than coefficient space. Let <span class="math notranslate nohighlight">\(A\)</span> be the <strong>projection operator</strong> that takes any function <span class="math notranslate nohighlight">\(f\)</span> and returns its approximation in <span class="math notranslate nohighlight">\(\text{span}\{\varphi_1, \ldots, \varphi_n\}\)</span>. For collocation, <span class="math notranslate nohighlight">\(A\)</span> is the interpolation operator: <span class="math notranslate nohighlight">\((Af)(s)\)</span> is the unique linear combination of basis functions that matches <span class="math notranslate nohighlight">\(f\)</span> at the collocation points. Then Step 2 can be written as: fit <span class="math notranslate nohighlight">\(\hat{v}^{(k+1)}\)</span> so that <span class="math notranslate nohighlight">\(\hat{v}^{(k+1)}(s_i) = \mathrm{L}\hat{v}^{(k)}(s_i)\)</span> for all collocation points, which means <span class="math notranslate nohighlight">\(\hat{v}^{(k+1)} = A(\mathrm{L}\hat{v}^{(k)})\)</span>.</p>
<p>In other words, function iteration is equivalent to <strong>projected value iteration in function space</strong>:</p>
<div class="math notranslate nohighlight">
\[
\hat{v}^{(k+1)} = A \mathrm{L} \hat{v}^{(k)}.
\]</div>
<p>We know that standard value iteration <span class="math notranslate nohighlight">\(v_{k+1} = \mathrm{L} v_k\)</span> converges because <span class="math notranslate nohighlight">\(\mathrm{L}\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction in the sup norm. But now we’re iterating with the <strong>composed operator</strong> <span class="math notranslate nohighlight">\(A\mathrm{L}\)</span> instead of <span class="math notranslate nohighlight">\(\mathrm{L}\)</span> alone.</p>
<p>This <span class="math notranslate nohighlight">\(A\mathrm{L}\)</span> structure is not specific to collocation. It is inherent in all projection methods. The general pattern is always the same: apply the Bellman operator to get a target function <span class="math notranslate nohighlight">\(\mathrm{L}\hat{v}^{(k)}\)</span>, then project it back onto our approximation space to get <span class="math notranslate nohighlight">\(\hat{v}^{(k+1)}\)</span>. The projection step defines an operator <span class="math notranslate nohighlight">\(A\)</span> that depends on our choice of test functions:</p>
<ul class="simple">
<li><p>For <strong>collocation</strong>, <span class="math notranslate nohighlight">\(A\)</span> interpolates values at collocation points</p></li>
<li><p>For <strong>Galerkin</strong>, <span class="math notranslate nohighlight">\(A\)</span> is orthogonal projection with respect to <span class="math notranslate nohighlight">\(\langle \cdot, \cdot \rangle_w\)</span></p></li>
<li><p>For <strong>least squares</strong>, <span class="math notranslate nohighlight">\(A\)</span> minimizes the weighted residual norm</p></li>
</ul>
<p>But regardless of which projection method we use, iteration takes the form <span class="math notranslate nohighlight">\(\hat{v}^{(k+1)} = A\mathrm{L}\hat{v}^{(k)}\)</span>.</p>
<p>The critical question is: <strong>does the composition <span class="math notranslate nohighlight">\(A \mathrm{L}\)</span> inherit the contraction property of <span class="math notranslate nohighlight">\(\mathrm{L}\)</span>?</strong> If not, the iteration may diverge, oscillate, or converge to a spurious fixed point even though the original problem is well-posed.</p>
<section id="monotone-approximators-and-stability">
<h3>Monotone Approximators and Stability<a class="headerlink" href="#monotone-approximators-and-stability" title="Link to this heading">#</a></h3>
<p>The answer turns out to depend on specific properties of the approximation operator <span class="math notranslate nohighlight">\(A\)</span>. This theory was developed independently across multiple research communities—computational economics (Judd 1992, 1996; Santos and Vigo-Aguiar 1998), economic dynamics (Stachurski 2009), and reinforcement learning (Gordon 1995, 1999)—arriving at essentially the same mathematical conditions.</p>
<section id="monotonicity-implies-nonexpansiveness">
<h4>Monotonicity Implies Nonexpansiveness<a class="headerlink" href="#monotonicity-implies-nonexpansiveness" title="Link to this heading">#</a></h4>
<p>It turns out that approximation operators satisfying simple structural properties automatically preserve contraction.</p>
<div class="proof proposition admonition" id="monotone-nonexpansive">
<p class="admonition-title"><span class="caption-number">Proposition 5 </span> (Monotone operators are nonexpansive (Stachurski))</p>
<section class="proposition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(A: B(\mathcal{S}) \to B(\mathcal{S})\)</span> be a linear operator on the space of bounded functions. If <span class="math notranslate nohighlight">\(A\)</span> satisfies:</p>
<ol class="arabic simple">
<li><p><strong>Monotonicity</strong>: <span class="math notranslate nohighlight">\(f \leq g\)</span> pointwise implies <span class="math notranslate nohighlight">\(Af \leq Ag\)</span></p></li>
<li><p><strong>Constant preservation</strong>: <span class="math notranslate nohighlight">\(A\mathbf{1} = \mathbf{1}\)</span> where <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is the constant function equal to <span class="math notranslate nohighlight">\(1\)</span></p></li>
</ol>
<p>Then <span class="math notranslate nohighlight">\(A\)</span> is nonexpansive in the sup norm: <span class="math notranslate nohighlight">\(\|Af - Ag\|_\infty \leq \|f - g\|_\infty\)</span> for all <span class="math notranslate nohighlight">\(f, g \in B(\mathcal{S})\)</span>.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Let <span class="math notranslate nohighlight">\(M = \|f - g\|_\infty\)</span>. Then <span class="math notranslate nohighlight">\(-M \leq f(s) - g(s) \leq M\)</span> for all <span class="math notranslate nohighlight">\(s\)</span>, which can be written as <span class="math notranslate nohighlight">\(g - M\mathbf{1} \leq f \leq g + M\mathbf{1}\)</span>. By monotonicity, <span class="math notranslate nohighlight">\(A(g - M\mathbf{1}) \leq Af \leq A(g + M\mathbf{1})\)</span>. By linearity and constant preservation, <span class="math notranslate nohighlight">\(Ag - M\mathbf{1} \leq Af \leq Ag + M\mathbf{1}\)</span>, which means <span class="math notranslate nohighlight">\(|Af(s) - Ag(s)| \leq M\)</span> for all <span class="math notranslate nohighlight">\(s\)</span>. Therefore <span class="math notranslate nohighlight">\(\|Af - Ag\|_\infty \leq \|f - g\|_\infty\)</span>.</p>
</div>
<p>This proposition shows that monotonicity and constant preservation automatically imply nonexpansiveness. There is no need to verify this separately. The intuition is that a monotone, constant-preserving operator acts like a weighted average that respects order structure and cannot amplify differences between functions.</p>
</section>
<section id="preservation-of-contraction">
<h4>Preservation of Contraction<a class="headerlink" href="#preservation-of-contraction" title="Link to this heading">#</a></h4>
<p>Combining nonexpansiveness with the contraction property of the Bellman operator yields the main stability result.</p>
<div class="proof theorem admonition" id="santos-vigo-aguiar-stability">
<p class="admonition-title"><span class="caption-number">Theorem 7 </span> (Stability of projected value iteration (Santos-Vigo-Aguiar))</p>
<section class="theorem-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(\mathrm{L}: B(\mathcal{S}) \to B(\mathcal{S})\)</span> be a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction on the space of bounded functions with respect to the sup norm. Let <span class="math notranslate nohighlight">\(A: B(\mathcal{S}) \to B(\mathcal{S})\)</span> be a linear approximation operator satisfying monotonicity and constant preservation.</p>
<p>Then the composed operator <span class="math notranslate nohighlight">\(A\mathrm{L}\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction, and projected value iteration <span class="math notranslate nohighlight">\(v_{k+1} = A\mathrm{L} v_k\)</span> converges globally to a unique fixed point <span class="math notranslate nohighlight">\(v_A \in \text{Range}(A)\)</span> with approximation error:</p>
<div class="math notranslate nohighlight">
\[
\|v_A - v^*\|_\infty \leq \frac{1}{1-\gamma} \|Av^* - v^*\|_\infty,
\]</div>
<p>where <span class="math notranslate nohighlight">\(v^*\)</span> is the true value function.</p>
</section>
</div><div class="proof admonition" id="proof">
<p>Proof. Since <span class="math notranslate nohighlight">\(\mathrm{L}\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction, we have <span class="math notranslate nohighlight">\(-\gamma\|f-g\|_\infty \leq \mathrm{L} f - \mathrm{L} g \leq \gamma\|f-g\|_\infty\)</span> pointwise. By monotonicity of <span class="math notranslate nohighlight">\(A\)</span>, <span class="math notranslate nohighlight">\(A(-\gamma\|f-g\|_\infty) \leq A(\mathrm{L} f - \mathrm{L} g) \leq A(\gamma\|f-g\|_\infty)\)</span>. By constant preservation, <span class="math notranslate nohighlight">\(-\gamma\|f-g\|_\infty \leq A(\mathrm{L} f - \mathrm{L} g) \leq \gamma\|f-g\|_\infty\)</span>, which implies <span class="math notranslate nohighlight">\(\|A\mathrm{L} f - A\mathrm{L} g\|_\infty \leq \gamma\|f-g\|_\infty\)</span>.</p>
<p>The error bound follows from fixed-point analysis: <span class="math notranslate nohighlight">\(v^* - v_A = (I - A\mathrm{L})^{-1}(v^* - Av^*)\)</span>, and since <span class="math notranslate nohighlight">\(A\mathrm{L}\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction, <span class="math notranslate nohighlight">\(\|(I - A\mathrm{L})^{-1}\| \leq (1-\gamma)^{-1}\)</span>.</p>
</div>
<p>This error bound tells us that the fixed-point error is controlled by how well <span class="math notranslate nohighlight">\(A\)</span> can represent <span class="math notranslate nohighlight">\(v^*\)</span>. If <span class="math notranslate nohighlight">\(v^* \in \text{Range}(A)\)</span>, then <span class="math notranslate nohighlight">\(Av^* = v^*\)</span> and the error vanishes. Otherwise, the error is proportional to the approximation error <span class="math notranslate nohighlight">\(\|Av^* - v^*\|_\infty\)</span>, amplified by the factor <span class="math notranslate nohighlight">\((1-\gamma)^{-1}\)</span>.</p>
</section>
<section id="averagers-in-discrete-state-problems">
<h4>Averagers in Discrete-State Problems<a class="headerlink" href="#averagers-in-discrete-state-problems" title="Link to this heading">#</a></h4>
<p>For discrete-state problems, the monotonicity conditions have a natural interpretation as <strong>averaging with nonnegative weights</strong>. This characterization was developed by Gordon in the context of reinforcement learning.</p>
<div class="proof definition admonition" id="gordon-averager">
<p class="admonition-title"><span class="caption-number">Definition 8 </span> (Averager (Gordon))</p>
<section class="definition-content" id="proof-content">
<p>An operator <span class="math notranslate nohighlight">\(A: \mathbb{R}^{|\mathcal{S}|} \to \mathbb{R}^{|\mathcal{S}|}\)</span> is an <strong>averager</strong> if <span class="math notranslate nohighlight">\(Av = Wv\)</span> where <span class="math notranslate nohighlight">\(W\)</span> is a <span class="math notranslate nohighlight">\(|\mathcal{S}| \times |\mathcal{S}|\)</span> stochastic matrix: <span class="math notranslate nohighlight">\(w_{ij} \geq 0\)</span> and <span class="math notranslate nohighlight">\(\sum_j w_{ij} = 1\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>.</p>
</section>
</div><p>Averagers automatically satisfy the monotonicity conditions: linearity follows from matrix multiplication, monotonicity follows from nonnegativity of entries, and constant preservation follows from row sums equaling one.</p>
<div class="proof theorem admonition" id="gordon-stability">
<p class="admonition-title"><span class="caption-number">Theorem 8 </span> (Stability with averagers (Gordon))</p>
<section class="theorem-content" id="proof-content">
<p>If <span class="math notranslate nohighlight">\(A\)</span> is an averager and <span class="math notranslate nohighlight">\(\mathrm{L}\)</span> is the Bellman operator (a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction), then <span class="math notranslate nohighlight">\(A\mathrm{L}\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction, and value iteration <span class="math notranslate nohighlight">\(v_{k+1} = A\mathrm{L} v_k\)</span> converges to a unique fixed point.</p>
</section>
</div><p>This specializes the Santos-Vigo-Aguiar theorem to discrete states, expressed in the probabilistic language of stochastic matrices. The stochastic matrix characterization connects to Markov chain theory: <span class="math notranslate nohighlight">\(Av\)</span> represents expected values after one transition, and the monotonicity property reflects the fact that expectations preserve order.</p>
<p><strong>Examples of averagers</strong> include state aggregation (averaging values within groups), K-nearest neighbors (averaging over nearest states), kernel smoothing with positive kernels, and multilinear interpolation on grids (barycentric weights are nonnegative and sum to one). <strong>Counterexamples</strong> include linear least squares regression (projection matrix may have negative entries) and high-order polynomial interpolation (Runge phenomenon produces negative weights).</p>
</section>
<section id="which-approximation-operators-are-monotone">
<h4>Which Approximation Operators Are Monotone?<a class="headerlink" href="#which-approximation-operators-are-monotone" title="Link to this heading">#</a></h4>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p><strong>Method</strong></p></th>
<th class="head text-left"><p><strong>Monotone?</strong></p></th>
<th class="head text-left"><p><strong>Notes</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Piecewise linear interpolation</p></td>
<td class="text-left"><p>Yes</p></td>
<td class="text-left"><p>Always an averager; guaranteed stability</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Multilinear interpolation (grid)</p></td>
<td class="text-left"><p>Yes</p></td>
<td class="text-left"><p>Barycentric weights are nonnegative and sum to one</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Shape-preserving splines (Schumaker)</p></td>
<td class="text-left"><p>Yes</p></td>
<td class="text-left"><p>Designed to maintain monotonicity</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>State aggregation</p></td>
<td class="text-left"><p>Yes</p></td>
<td class="text-left"><p>Exact averaging within groups</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Kernel smoothing (positive kernels)</p></td>
<td class="text-left"><p>Yes</p></td>
<td class="text-left"><p>If kernel integrates to one</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>High-order polynomial interpolation</p></td>
<td class="text-left"><p>No</p></td>
<td class="text-left"><p>Oscillations violate monotonicity (Runge phenomenon)</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Least squares projection (arbitrary basis)</p></td>
<td class="text-left"><p>No</p></td>
<td class="text-left"><p>Projection matrix may have negative entries</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Fourier/spectral methods</p></td>
<td class="text-left"><p>No</p></td>
<td class="text-left"><p>Not monotone-preserving in general</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Neural networks</p></td>
<td class="text-left"><p>No</p></td>
<td class="text-left"><p>Highly flexible but no monotonicity guarantees</p></td>
</tr>
</tbody>
</table>
</div>
<p>The distinction between “safe” (monotone) and “potentially unstable” (non-monotone) approximators provides rigorous foundation for the folk wisdom that linear interpolation is reliable while high-order polynomials can be dangerous for value iteration.</p>
</section>
</section>
<section id="practical-implications">
<h3>Practical Implications<a class="headerlink" href="#practical-implications" title="Link to this heading">#</a></h3>
<p><strong>When using successive approximation (fixed-point iteration):</strong></p>
<ul class="simple">
<li><p>Choose monotone approximators to guarantee convergence</p></li>
<li><p>Piecewise linear interpolation, state aggregation, and kernel methods with positive kernels are safe choices</p></li>
<li><p>High-order polynomials and least squares regression may fail to converge even when the Bellman operator is a strong contraction</p></li>
</ul>
<p><strong>When using rootfinding methods (Newton):</strong></p>
<ul class="simple">
<li><p>Monotonicity is not required for convergence</p></li>
<li><p>Can use smooth approximations (polynomials, splines, neural networks) for better approximation quality</p></li>
<li><p>Requires good initial guesses and well-conditioned systems</p></li>
<li><p>Stability depends on numerical properties of the Jacobian, not contraction preservation</p></li>
</ul>
<p><strong>Hybrid strategies:</strong></p>
<ol class="arabic simple">
<li><p>Use smooth approximation for policy representation, but monotone averager for value iteration</p></li>
<li><p>Regularize smooth approximations with monotonicity constraints (monotone neural networks)</p></li>
<li><p>Run a few iterations with a monotone method to generate initial guess, then switch to Newton’s method with smooth approximation</p></li>
<li><p>Solve projection equations directly (collocation with Newton) rather than iterating</p></li>
</ol>
<p>This explains observed differences across research communities: reinforcement learning (traditionally using iterative TD methods) emphasized averagers, while computational economics (using collocation with Newton solvers) was more comfortable with polynomial bases.</p>
</section>
<section id="weighted-norms-and-extensions">
<h3>Weighted Norms and Extensions<a class="headerlink" href="#weighted-norms-and-extensions" title="Link to this heading">#</a></h3>
<p>The monotone approximation theory provides complete characterization for contraction in the sup norm. Several important extensions remain active research areas:</p>
<p><strong>Weighted <span class="math notranslate nohighlight">\(L^2\)</span> norms</strong>: For policy evaluation with Galerkin projection, the relevant norm is <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span> where <span class="math notranslate nohighlight">\(\xi\)</span> is a state distribution. The contraction preservation condition becomes: <span class="math notranslate nohighlight">\(\xi\)</span> must be stationary under the policy’s transition operator. On-policy TD methods converge while off-policy methods can diverge because the weighting distribution must match the policy dynamics.</p>
<p><strong>Nonlinear approximation</strong>: Neural networks don’t fit the linear operator framework. Recent work on monotone and convex neural networks attempts to recover stability through architectural constraints, but a complete theory is still emerging.</p>
<p><strong>High-dimensional state spaces</strong>: Grid-based averagers become intractable due to curse of dimensionality. Understanding which non-averaging approximations provide acceptable stability-accuracy trade-offs is crucial for modern applications.</p>
<p><strong>Off-policy learning</strong>: The averager framework assumes on-policy evaluation. Off-policy methods require additional machinery (importance sampling, gradient corrections) to maintain stability, even with averaging operators.</p>
</section>
</section>
<section id="galerkin-projection-and-least-squares-temporal-difference">
<h2>Galerkin Projection and Least Squares Temporal Difference<a class="headerlink" href="#galerkin-projection-and-least-squares-temporal-difference" title="Link to this heading">#</a></h2>
<p>An important special case emerges when we apply Galerkin projection to the <strong>policy evaluation</strong> problem rather than the optimality problem. For a fixed policy <span class="math notranslate nohighlight">\(\pi\)</span>, the policy evaluation Bellman equation is:</p>
<div class="math notranslate nohighlight">
\[
v^\pi(s) = \mathrm{L}_\pi v^\pi(s) = r(s,\pi(s)) + \gamma \sum_{s' \in \mathcal{S}} p(s'|s,\pi(s)) v^\pi(s').
\]</div>
<p>This is a linear operator (no max), making the projection problem significantly simpler. Consider a linear function approximation <span class="math notranslate nohighlight">\(\hat{v}(s) = \boldsymbol{\varphi}(s)^\top \mathbf{a}\)</span> where <span class="math notranslate nohighlight">\(\boldsymbol{\varphi}(s) = [\varphi_1(s), \ldots, \varphi_n(s)]^\top\)</span> are basis functions and <span class="math notranslate nohighlight">\(\mathbf{a} = [a_1, \ldots, a_n]^\top\)</span> are coefficients to determine. The residual is:</p>
<div class="math notranslate nohighlight">
\[
R(s; \mathbf{a}) = \mathrm{L}_\pi \hat{v}(s) - \hat{v}(s) = r(s,\pi(s)) + \gamma \sum_{s'} p(s'|s,\pi(s)) \boldsymbol{\varphi}(s')^\top \mathbf{a} - \boldsymbol{\varphi}(s)^\top \mathbf{a}.
\]</div>
<p>The Galerkin projection requires the residual to be orthogonal to all basis functions with respect to some weighting:</p>
<div class="math notranslate nohighlight">
\[
\sum_{s \in \mathcal{S}} \xi(s) R(s; \mathbf{a}) \varphi_j(s) = 0, \quad j = 1, \ldots, n,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\xi(s)\)</span> is a distribution over states (often the stationary distribution under policy <span class="math notranslate nohighlight">\(\pi\)</span>, or uniform over visited states). Substituting the residual:</p>
<div class="math notranslate nohighlight">
\[
\sum_s \xi(s) \left[ r(s,\pi(s)) + \gamma \sum_{s'} p(s'|s,\pi(s)) \boldsymbol{\varphi}(s')^\top \mathbf{a} - \boldsymbol{\varphi}(s)^\top \mathbf{a} \right] \varphi_j(s) = 0.
\]</div>
<p>Rearranging and writing in matrix form, let <span class="math notranslate nohighlight">\(\boldsymbol{\Xi}\)</span> be a diagonal matrix with <span class="math notranslate nohighlight">\(\Xi_{ss} = \xi(s)\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}\)</span> be the <span class="math notranslate nohighlight">\(|\mathcal{S}| \times n\)</span> matrix with rows <span class="math notranslate nohighlight">\(\boldsymbol{\varphi}(s)^\top\)</span>, and <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> be the transition matrix under policy <span class="math notranslate nohighlight">\(\pi\)</span>. The Galerkin conditions become:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\Phi}^\top \boldsymbol{\Xi} (\mathbf{r}_\pi + \gamma \mathbf{P}_\pi \boldsymbol{\Phi} \mathbf{a} - \boldsymbol{\Phi} \mathbf{a}) = \mathbf{0}.
\]</div>
<p>Solving for <span class="math notranslate nohighlight">\(\mathbf{a}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\Phi}^\top \boldsymbol{\Xi} (\boldsymbol{\Phi} - \gamma \mathbf{P}_\pi \boldsymbol{\Phi}) \mathbf{a} = \boldsymbol{\Phi}^\top \boldsymbol{\Xi} \mathbf{r}_\pi.
\]</div>
<p>We have just derived the <strong>Least Squares Temporal Difference (LSTD)</strong> solution for policy evaluation. This shows that LSTD is Galerkin projection applied to the linear policy evaluation Bellman equation. The “least squares” name comes from the fact that this is the projection (in the weighted <span class="math notranslate nohighlight">\(\ell^2\)</span> sense) of the Bellman operator’s output onto the span of the basis functions.</p>
<p>The projection perspective makes clear an important aspect of approximate dynamic programming. The solution <span class="math notranslate nohighlight">\(\mathbf{a}\)</span> does not satisfy the true Bellman equation <span class="math notranslate nohighlight">\(v = \mathrm{L}_\pi v\)</span> (which is typically impossible within our finite-dimensional approximation space). Instead, it satisfies <span class="math notranslate nohighlight">\(\hat{v} = \Pi \mathrm{L}_\pi \hat{v}\)</span>, where <span class="math notranslate nohighlight">\(\Pi\)</span> is the projection operator onto <span class="math notranslate nohighlight">\(\text{span}\{\varphi_1, \ldots, \varphi_n\}\)</span>. We find the fixed point of the <em>projected</em> Bellman operator, not the Bellman operator itself. This is why approximation error persists even at convergence: the best we can do is find the value function whose Bellman operator output projects back onto itself.</p>
<section id="the-projected-bellman-equations">
<h3>The Projected Bellman Equations<a class="headerlink" href="#the-projected-bellman-equations" title="Link to this heading">#</a></h3>
<p>The LSTD solution gives a closed-form expression and connects to iterative algorithms developed in the next chapter. Understanding convergence of these methods requires analyzing when the projected Bellman operator <span class="math notranslate nohighlight">\(\Pi \mathrm{L}_\pi\)</span> is a contraction.</p>
<p><strong>Norms and projections.</strong> Fix a feature matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Phi} \in \mathbb{R}^{|\mathcal{S}| \times n}\)</span> with full column rank and a probability distribution <span class="math notranslate nohighlight">\(\xi\)</span> over states. Define the <span class="math notranslate nohighlight">\(\xi\)</span>-weighted inner product and norm by</p>
<div class="math notranslate nohighlight">
\[
\langle u, v \rangle_\xi := \sum_s \xi(s) u(s) v(s) = u^\top \boldsymbol{\Xi} v, \qquad \|v\|_\xi := \sqrt{v^\top \boldsymbol{\Xi} v},
\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\Xi} = \text{diag}(\xi)\)</span>. The orthogonal projection onto <span class="math notranslate nohighlight">\(\text{span}(\boldsymbol{\Phi})\)</span> with respect to <span class="math notranslate nohighlight">\(\langle \cdot, \cdot \rangle_\xi\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\Pi = \boldsymbol{\Phi}(\boldsymbol{\Phi}^\top \boldsymbol{\Xi} \boldsymbol{\Phi})^{-1} \boldsymbol{\Phi}^\top \boldsymbol{\Xi}.
\]</div>
<p>An operator <span class="math notranslate nohighlight">\(\mathrm{T}\)</span> is a <strong><span class="math notranslate nohighlight">\(\beta\)</span>-contraction</strong> in norm <span class="math notranslate nohighlight">\(\|\cdot\|\)</span> if <span class="math notranslate nohighlight">\(\|\mathrm{T}v - \mathrm{T}w\| \leq \beta \|v - w\|\)</span> for all <span class="math notranslate nohighlight">\(v, w\)</span> and some <span class="math notranslate nohighlight">\(\beta &lt; 1\)</span>. It is a <strong>non-expansion</strong> if the same holds with <span class="math notranslate nohighlight">\(\beta = 1\)</span>.</p>
<p><strong>Why <span class="math notranslate nohighlight">\(\Pi\)</span> is a non-expansion.</strong> This follows from the Pythagorean identity in weighted inner product spaces. For any <span class="math notranslate nohighlight">\(u \in \mathbb{R}^{|\mathcal{S}|}\)</span>, the projection <span class="math notranslate nohighlight">\(\Pi u\)</span> and the residual <span class="math notranslate nohighlight">\((I - \Pi)u\)</span> are <span class="math notranslate nohighlight">\(\xi\)</span>-orthogonal: <span class="math notranslate nohighlight">\(\langle \Pi u, (I-\Pi)u \rangle_\xi = 0\)</span>. Therefore,</p>
<div class="math notranslate nohighlight">
\[
\|u\|_\xi^2 = \|\Pi u\|_\xi^2 + \|(I-\Pi)u\|_\xi^2.
\]</div>
<p>Applying this to <span class="math notranslate nohighlight">\(u - v\)</span> gives</p>
<div class="math notranslate nohighlight">
\[
\|\Pi u - \Pi v\|_\xi^2 = \|\Pi(u-v)\|_\xi^2 \leq \|\Pi(u-v)\|_\xi^2 + \|(I-\Pi)(u-v)\|_\xi^2 = \|u - v\|_\xi^2,
\]</div>
<p>proving <span class="math notranslate nohighlight">\(\|\Pi u - \Pi v\|_\xi \leq \|u - v\|_\xi\)</span>.</p>
<p>When is <span class="math notranslate nohighlight">\(\mathrm{L}_\pi\)</span> a contraction in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span>? Write the policy evaluation operator as <span class="math notranslate nohighlight">\(\mathrm{L}_\pi v = r_\pi + \gamma \mathbf{P}_\pi v\)</span>, where <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> is the transition matrix under policy <span class="math notranslate nohighlight">\(\pi\)</span>. We know <span class="math notranslate nohighlight">\(\mathrm{L}_\pi\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction in <span class="math notranslate nohighlight">\(\|\cdot\|_\infty\)</span> from earlier chapters. However, whether it contracts in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span> depends on the relationship between <span class="math notranslate nohighlight">\(\xi\)</span> and <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span>.</p>
<p>We need to establish when the stochastic matrix <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> is non-expansive in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span>. Following Bertsekas (Lemma 6.3.1), suppose <span class="math notranslate nohighlight">\(\xi\)</span> is a <strong>steady-state probability vector</strong> for <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> with positive components, meaning:</p>
<div class="math notranslate nohighlight">
\[
\xi^\top \mathbf{P}_\pi = \xi^\top, \qquad \text{or equivalently,} \qquad \xi(s') = \sum_s \xi(s) p(s'|s,\pi(s)) \text{ for all } s'.
\]</div>
<p>Then for any <span class="math notranslate nohighlight">\(z \in \mathbb{R}^{|\mathcal{S}|}\)</span>, using the convexity of the square function (Jensen’s inequality):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\|\mathbf{P}_\pi z\|_\xi^2 &amp;= \sum_s \xi(s) \left(\sum_{s'} p(s'|s,\pi(s)) z(s')\right)^2 \\
&amp;\leq \sum_s \xi(s) \sum_{s'} p(s'|s,\pi(s)) z(s')^2 \\
&amp;= \sum_{s'} \left(\sum_s \xi(s) p(s'|s,\pi(s))\right) z(s')^2
\end{align*}
\end{split}\]</div>
<p>Using the defining property of steady-state probabilities <span class="math notranslate nohighlight">\(\sum_s \xi(s) p(s'|s,\pi(s)) = \xi(s')\)</span>:</p>
<div class="math notranslate nohighlight">
\[
= \sum_{s'} \xi(s') z(s')^2 = \|z\|_\xi^2.
\]</div>
<p>Therefore <span class="math notranslate nohighlight">\(\|\mathbf{P}_\pi z\|_\xi \leq \|z\|_\xi\)</span>, showing that <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> is non-expansive in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span>. Since <span class="math notranslate nohighlight">\(\|\mathrm{L}_\pi v - \mathrm{L}_\pi w\|_\xi = \gamma \|\mathbf{P}_\pi(v-w)\|_\xi\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\|\mathrm{L}_\pi v - \mathrm{L}_\pi w\|_\xi \leq \gamma \|v - w\|_\xi.
\]</div>
<p>Thus <span class="math notranslate nohighlight">\(\mathrm{L}_\pi\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span> when <span class="math notranslate nohighlight">\(\xi\)</span> is the steady-state distribution of <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<p><strong>Contraction of the composition.</strong> Combining our two results: <span class="math notranslate nohighlight">\(\Pi\)</span> is a non-expansion and (under stationarity) <span class="math notranslate nohighlight">\(\mathrm{L}_\pi\)</span> is a <span class="math notranslate nohighlight">\(\gamma\)</span>-contraction in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span>. Therefore,</p>
<div class="math notranslate nohighlight">
\[
\|\Pi \mathrm{L}_\pi v - \Pi \mathrm{L}_\pi w\|_\xi \leq \|\mathrm{L}_\pi v - \mathrm{L}_\pi w\|_\xi \leq \gamma \|v - w\|_\xi.
\]</div>
<p>By the Banach fixed-point theorem, <span class="math notranslate nohighlight">\(\Pi \mathrm{L}_\pi\)</span> has a unique fixed point in <span class="math notranslate nohighlight">\(\mathbb{R}^{|\mathcal{S}|}\)</span>, and iterates <span class="math notranslate nohighlight">\(v_{k+1} = \Pi \mathrm{L}_\pi v_k\)</span> converge to it from any <span class="math notranslate nohighlight">\(v_0\)</span>. This fixed point satisfies the <strong>projected Bellman equation</strong></p>
<div class="math notranslate nohighlight">
\[
v = \Pi(r_\pi + \gamma \mathbf{P}_\pi v), \qquad v \in \text{span}(\boldsymbol{\Phi}).
\]</div>
<p>Writing <span class="math notranslate nohighlight">\(v = \boldsymbol{\Phi} w\)</span> and left-multiplying by <span class="math notranslate nohighlight">\(\boldsymbol{\Phi}^\top \boldsymbol{\Xi}\)</span> yields the <strong>normal equations</strong></p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\Phi}^\top \boldsymbol{\Xi}(\boldsymbol{\Phi} - \gamma \mathbf{P}_\pi \boldsymbol{\Phi}) w = \boldsymbol{\Phi}^\top \boldsymbol{\Xi} r_\pi,
\]</div>
<p>which are precisely the LSTD equations we derived earlier. This result provides the theoretical foundation for temporal difference learning with linear function approximation: when learning on-policy (so <span class="math notranslate nohighlight">\(\xi\)</span> is stationary), convergence is guaranteed.</p>
<p><strong>Off-policy instability.</strong> When <span class="math notranslate nohighlight">\(\xi\)</span> is not stationary for <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> (as occurs when data come from a different behavior policy), the Jensen argument breaks down. The transition operator <span class="math notranslate nohighlight">\(\mathbf{P}_\pi\)</span> need not be non-expansive in <span class="math notranslate nohighlight">\(\|\cdot\|_\xi\)</span>, so <span class="math notranslate nohighlight">\(\Pi \mathrm{L}_\pi\)</span> may fail to be a contraction. This is the root cause of off-policy divergence phenomena in linear TD learning (e.g., Baird’s counterexample). Importance weighting and other corrections are designed to restore stability in this regime.</p>
<p>The linearity of the policy evaluation operator <span class="math notranslate nohighlight">\(\mathrm{L}_\pi\)</span> is what gives us the closed-form solution. We could apply Galerkin projection to the Bellman optimality equation <span class="math notranslate nohighlight">\(v^* = \mathrm{L} v^*\)</span>, setting up orthogonality conditions <span class="math notranslate nohighlight">\(\sum_s \xi(s) R(s; \mathbf{a}) \varphi_j(s) = 0\)</span>. The max operator makes these conditions nonlinear in <span class="math notranslate nohighlight">\(\mathbf{a}\)</span>, eliminating the closed form and requiring iterative solution. This brings us back to the successive approximation methods discussed earlier for collocation.</p>
<p>This framework of projection methods (choosing test functions, defining residuals, and solving finite-dimensional systems) provides the conceptual foundation for approximate dynamic programming. One question remains: how do we evaluate the expectations in the Bellman operator when we lack explicit transition probabilities or when the state space is too large for exact computation? The next chapter introduces Monte Carlo integration methods, connecting classical projection methods to simulation-based approximate dynamic programming and reinforcement learning.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="regmdp.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Smooth Bellman Optimality Equations</p>
      </div>
    </a>
    <a class="right-next"
       href="simadp.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Simulation-Based Approximate Dynamic Programming</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-does-it-mean-for-a-residual-to-be-zero">What Does It Mean for a Residual to Be Zero?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-special-role-of-spectral-methods">The Special Role of Spectral Methods</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-collocation">Orthogonal Collocation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-framework">The General Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-choose-a-finite-dimensional-approximation-space">Step 1: Choose a Finite-Dimensional Approximation Space</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-2-define-the-residual-function">Step 2: Define the Residual Function</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-choose-weighted-residual-conditions">Step 3: Choose Weighted Residual Conditions</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#galerkin-method-test-against-the-basis">Galerkin Method: Test Against the Basis</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#method-of-moments-test-against-monomials">Method of Moments: Test Against Monomials</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#collocation-method-test-against-delta-functions">Collocation Method: Test Against Delta Functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#subdomain-method-test-against-indicator-functions">Subdomain Method: Test Against Indicator Functions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#least-squares">Least Squares</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-solve-the-finite-dimensional-problem">Step 4: Solve the Finite-Dimensional Problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-verify-the-solution">Step 5: Verify the Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-to-the-bellman-equation">Application to the Bellman Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collocation-for-the-bellman-equation">Collocation for the Bellman Equation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-collocation-system">Solving the Collocation System</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-1-function-iteration-successive-approximation">Method 1: Function Iteration (Successive Approximation)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#method-2-newton-s-method-with-the-envelope-theorem">Method 2: Newton’s Method with the Envelope Theorem</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-solution-methods">Comparison of Solution Methods</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shape-preserving-considerations">Shape-Preserving Considerations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#monotone-projection-and-the-preservation-of-contraction">Monotone Projection and the Preservation of Contraction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#monotone-approximators-and-stability">Monotone Approximators and Stability</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#monotonicity-implies-nonexpansiveness">Monotonicity Implies Nonexpansiveness</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#preservation-of-contraction">Preservation of Contraction</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#averagers-in-discrete-state-problems">Averagers in Discrete-State Problems</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#which-approximation-operators-are-monotone">Which Approximation Operators Are Monotone?</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#practical-implications">Practical Implications</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#weighted-norms-and-extensions">Weighted Norms and Extensions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#galerkin-projection-and-least-squares-temporal-difference">Galerkin Projection and Least Squares Temporal Difference</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-projected-bellman-equations">The Projected Bellman Equations</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pierre-Luc Bacon
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>