
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; Practical Reinforcement Learning: From Algorithms to Applications</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=fd3f3429" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"bm": ["{\\boldsymbol #1}", 1]}, "processEscapes": true}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'judd';</script>
    <script src="_static/iframe-modal.js?v=f72a1242"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
  
    <p class="title logo__title">Practical Reinforcement Learning: From Algorithms to Applications</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Why This Book?
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="modeling.html">Why Build a Model? For Whom?</a></li>

<li class="toctree-l1"><a class="reference internal" href="ssm.html">Dynamics Models for Decision Making</a></li>




<li class="toctree-l1"><a class="reference internal" href="simulation.html">Programs as Models</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Numerical Trajectory Optimization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="ocp.html">Discrete-Time Trajectory Optimization</a></li>


<li class="toctree-l1"><a class="reference internal" href="cocp.html">Trajectory Optimization in Continuous Time</a></li>




</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">From Trajectories to Policies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="mpc.html">Model Predictive Control</a></li>




<li class="toctree-l1"><a class="reference internal" href="dp.html">Dynamic Programming</a></li>



</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Learning from Data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="adp.html">Approximate Dynamic Programming</a></li>






<li class="toctree-l1"><a class="reference internal" href="cadp.html">Policy Parametrization Methods</a></li>







</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="appendix_examples.html">Example COCPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix_ivps.html">Solving Initial Value Problems</a></li>
<li class="toctree-l1"><a class="reference internal" href="appendix_nlp.html">Nonlinear Programming</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/edit/main/judd.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/pierrelux/rlbook/issues/new?title=Issue%20on%20page%20%2Fjudd.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/judd.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><no title></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <p>\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{mathrsfs}
\geometry{margin=1in}</p>
<p>\title{Projection Methods for Functional Equations \ \large From Kenneth Judd’s \textit{Numerical Methods in Economics}}
\author{}
\date{}</p>
<p>\begin{document}</p>
<p>\maketitle</p>
<p>\section*{General Projection Approach}</p>
<p>Suppose that we want a solution to the operator equation
$<span class="math notranslate nohighlight">\(\mathscr{N}(f)=0,\)</span><span class="math notranslate nohighlight">\(
where \)</span>\mathscr{N}: B_1 \rightarrow B_2<span class="math notranslate nohighlight">\(, with \)</span>B_1<span class="math notranslate nohighlight">\( and \)</span>B_2<span class="math notranslate nohighlight">\( complete normed vector spaces of functions \)</span>f: D \subset \mathbb{R}^n \rightarrow \mathbb{R}^m<span class="math notranslate nohighlight">\(, and where \)</span>\mathscr{N}<span class="math notranslate nohighlight">\( is a continuous map. In our simple ordinary differential equation example (11.1.1), \)</span>D=[0, T]<span class="math notranslate nohighlight">\(, \)</span>f: D \rightarrow \mathbb{R}<span class="math notranslate nohighlight">\(, \)</span>\mathscr{N}=d / dt-I<span class="math notranslate nohighlight">\( where \)</span>I<span class="math notranslate nohighlight">\( is the identity operator, \)</span>B_1<span class="math notranslate nohighlight">\( is the space of \)</span>C^1<span class="math notranslate nohighlight">\( functions, and \)</span>B_2<span class="math notranslate nohighlight">\( is the space of \)</span>C^0<span class="math notranslate nohighlight">\( functions. In this example, \)</span>B_2<span class="math notranslate nohighlight">\( contained \)</span>B_1<span class="math notranslate nohighlight">\(, and both are contained in the space of measurable functions. More generally, \)</span>f<span class="math notranslate nohighlight">\( is a list of functions in the definition of equilibrium, such as decision rules, price functions, value functions, and conditional expectations functions, and the \)</span>\mathscr{N}$ operator expresses equilibrium conditions such as market clearing, Euler equations, Bellman and HJB equations, and rational expectations.</p>
<p>Since we are focused on describing the computational method, we will specify the topological details only to the extent implicit in the computational details. For example, we do not say exactly what norms and inner products are being implicitly used in the ODE and PDE examples in the previous sections. While these topological details are important, they lie far beyond the scope of this book. This may make some readers uncomfortable, particularly when we note that the topological aspects of many of our applications are not well-understood. Some comfort can be taken in the fact that we always check the validity of our solutions, and those checks may keep us from accepting projection method solutions in cases where the underlying functional analytic structure does not support the use of such methods. The reader can also see Zeidler (1986) and Krasnosel’ski\u{\i} and Zabreiko (1984) for serious discussions of those issues, and is encouraged to apply the methods there to economic problems.</p>
<p>The first step is to decide how to represent approximate solutions to <span class="math notranslate nohighlight">\(\mathscr{N}(f)=0\)</span>. One general way is to assume that our approximation, <span class="math notranslate nohighlight">\(\hat{f}\)</span>, is built up as a linear\footnote{Nonlinear combinations are also possible, but we stay with linear combinations here, since linear approximation theory is a much more developed theory than nonlinear approximation theory.} combination of simple functions from <span class="math notranslate nohighlight">\(B_1\)</span>. We will also need concepts of when two functions are close or far apart. Therefore, the first step is to choose bases and concepts of distance:</p>
<p>\paragraph{STEP 1} Choose a basis over <span class="math notranslate nohighlight">\(B_1\)</span>, <span class="math notranslate nohighlight">\(\Phi=\left\{\varphi_i\right\}_{i=1}^{\infty}\)</span> and a norm, <span class="math notranslate nohighlight">\(\|\cdot\|\)</span>. Similarly choose a basis over <span class="math notranslate nohighlight">\(B_2\)</span>, <span class="math notranslate nohighlight">\(\Psi=\left\{\psi_i\right\}_{i=1}^{\infty}\)</span> and an inner product, <span class="math notranslate nohighlight">\(\langle\cdot, \cdot\rangle_2\)</span> over <span class="math notranslate nohighlight">\(B_2\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(B_1\)</span> and <span class="math notranslate nohighlight">\(B_2\)</span> are subsets of another space, we will often use a basis of the larger space as the basis of <span class="math notranslate nohighlight">\(B_1\)</span> and an inner product norm of the larger space as the norm on <span class="math notranslate nohighlight">\(B_2\)</span>. Our approximation to the solution of <span class="math notranslate nohighlight">\(\mathscr{N}(f)=0\)</span> will be denoted <span class="math notranslate nohighlight">\(\hat{f}\)</span>; we next decide how many of these basis elements we will use.</p>
<p>\paragraph{STEP 2} Choose a degree of approximation, <span class="math notranslate nohighlight">\(n\)</span>, and define <span class="math notranslate nohighlight">\(\hat{f} \equiv \sum_{i=1}^n a_i \varphi_i(x)\)</span>.
\footnote{The convention is that the <span class="math notranslate nohighlight">\(\varphi_i\)</span> increase in “complexity” and “nonlinearity” as <span class="math notranslate nohighlight">\(i\)</span> increases, and that the first <span class="math notranslate nohighlight">\(n\)</span> elements are used. In the case of standard families of orthogonal polynomials, <span class="math notranslate nohighlight">\(\varphi_i\)</span> is the degree <span class="math notranslate nohighlight">\(i-1\)</span> polynomial.}</p>
<p>Step 1 lays down the structure of our approximation, and step 2 fixes the flexibility of the approximation. Once we have made these basic decisions, we begin our search for an approximate solution to (11.3.1). Since the only unknown part of the approximation is the vector <span class="math notranslate nohighlight">\(a\)</span>, we have reduced the original infinite-dimensional problem to a finite-dimensional one. If our diagnostic tests leave us dissatisfied with that approximation, we can return to step 2 and increase <span class="math notranslate nohighlight">\(n\)</span> in hopes of getting an improved approximation. If that fails, we can return to step 1 and begin again with a different basis.</p>
<p>Since the true solution <span class="math notranslate nohighlight">\(f\)</span> satisfies <span class="math notranslate nohighlight">\(\mathscr{N}(f)=0\)</span>, we will choose as our approximation some <span class="math notranslate nohighlight">\(\hat{f}\)</span> that makes <span class="math notranslate nohighlight">\(\mathscr{N}(\hat{f})\)</span> nearly equal to the zero function, where by near we refer to properties defined by the norm in <span class="math notranslate nohighlight">\(B_2,\|\cdot\|_2\)</span>, which corresponds to the inner product <span class="math notranslate nohighlight">\(\langle\cdot, \cdot\rangle_2\)</span>. Since <span class="math notranslate nohighlight">\(\hat{f}\)</span> is parameterized by <span class="math notranslate nohighlight">\(a\)</span>, the problem reduces to finding an <span class="math notranslate nohighlight">\(a\)</span> which makes <span class="math notranslate nohighlight">\(\mathscr{N}(\hat{f})\)</span> nearly zero. In many cases computing <span class="math notranslate nohighlight">\(\mathscr{N}(\hat{f})\)</span> is also challenging, such as when <span class="math notranslate nohighlight">\(\mathscr{N}(f)\)</span> involves integration of <span class="math notranslate nohighlight">\(f\)</span>; in those cases we need to approximate the <span class="math notranslate nohighlight">\(\mathscr{N}\)</span> operator.</p>
<p>\paragraph{STEP 3} Construct a computable approximation, <span class="math notranslate nohighlight">\(\hat{\mathscr{N}}\)</span>, to <span class="math notranslate nohighlight">\(\mathscr{N}\)</span>, and define the residual function
$<span class="math notranslate nohighlight">\(
R(x ; a) \equiv(\hat{\mathscr{N}}(\hat{f}(\cdot ; a))(x) .
\)</span><span class="math notranslate nohighlight">\(
Steps 2 and 3 transform an operation in an infinite-dimensional space into a computable finite-dimensional one. We need next to specify our notion of \)</span>\hat{f}<span class="math notranslate nohighlight">\( nearly solving \)</span>\mathscr{N}(f)=0$.</p>
<p>\paragraph{STEP 4} Either compute the norm of <span class="math notranslate nohighlight">\(R(\cdot ; a),\|R(\cdot ; a)\| \equiv\langle R(\cdot ; a), R(\cdot ; a)\rangle\)</span>, or choose a collection of <span class="math notranslate nohighlight">\(l\)</span> test functions in <span class="math notranslate nohighlight">\(B_2, p_i: D \rightarrow \mathbb{R}^m, i=1, \ldots, l\)</span>, and for each guess of <span class="math notranslate nohighlight">\(a\)</span> compute the <span class="math notranslate nohighlight">\(l\)</span> projections, <span class="math notranslate nohighlight">\(P_i(\cdot) \equiv\left\langle R(\cdot ; a), p_i(\cdot)\right\rangle\)</span>.</p>
<p>Step 4 creates the projections we will use. The choices made in step 4 generally give the projection method its name. Projection methods are also called “weighted residual methods,” since the criteria in step 4 weigh the residuals. Once we have chosen our criterion, we can determine the value of the unknown coefficients, <span class="math notranslate nohighlight">\(a\)</span>.</p>
<p>\paragraph{STEP 5} Find <span class="math notranslate nohighlight">\(a \in \mathbb{R}^n\)</span> that either minimizes <span class="math notranslate nohighlight">\(\|R(\cdot ; a)\|\)</span> or solves <span class="math notranslate nohighlight">\(P(a)=0\)</span>.
When we have our solution, <span class="math notranslate nohighlight">\(\hat{f}\)</span>, we are not done. It is only a candidate solution, and we must test the quality of our solution before accepting it.</p>
<p>\paragraph{STEP 6} Verify the quality of the candidate solution by approximating <span class="math notranslate nohighlight">\(\mathscr{N}(\hat{f})\)</span>.
We accomplish step 6 by computing the norm <span class="math notranslate nohighlight">\(\|\mathscr{N}(\hat{f})\|\)</span> and/or projections of <span class="math notranslate nohighlight">\(\mathscr{N}(\hat{f})\)</span> against test functions not used in step 4. If <span class="math notranslate nohighlight">\(\mathscr{N}\)</span> must be approximated, we should, if feasible, use a better approximation in step 6 than that constructed in step 3. Ideally all of these quantities will be zero; in practice, we choose target quantities for these diagnostics that imply that the deviations from zero are not economically significant.</p>
<p>This general algorithm breaks the numerical problem into several distinct steps. It points out the many distinct techniques of numerical analysis which are important. First, in steps 1 and 2 we choose the finite-dimensional space wherein we look for approximate solutions, hoping that within this set there is something “close” to the real solution. These steps require us to think seriously about approximation theory methods. Second, step 4 will involve numerical integration if we cannot explicitly compute the integrals that define the projections, and step 3 frequently involves numerical integration in economics applications. Third, step 5 is a third distinct numerical problem, involving the solution of a nonlinear set of simultaneous equations or the solution of a minimization problem. We will now consider each of these numerical problems in isolation.</p>
<p>\subsection*{Choice of Basis and Approximation Degree}
There are many criteria that the basis and inner product should satisfy. The full basis <span class="math notranslate nohighlight">\(\Phi\)</span> for the space of candidate solutions should be “rich,” flexible enough to approximate any function relevant to the problem. The best choice of <span class="math notranslate nohighlight">\(n\)</span> cannot be determined a priori. Generally, the only correct choice is <span class="math notranslate nohighlight">\(n=\infty\)</span>. If the choice of the basis is good, then larger <span class="math notranslate nohighlight">\(n\)</span> will yield better approximations. We are most interested, however, in the smallest <span class="math notranslate nohighlight">\(n\)</span> that yields an acceptable approximation. We initially begin with small <span class="math notranslate nohighlight">\(n\)</span> and increase <span class="math notranslate nohighlight">\(n\)</span> until some diagnostic indicates little is gained by continuing. Computational considerations also play a role in choosing a basis. The <span class="math notranslate nohighlight">\(\varphi_i\)</span> should be simple to compute, and all be similar in size to avoid scaling problems.</p>
<p>Of course, the number of basis elements needed will depend greatly on the basis being used; using a basis that is well-suited to a problem can greatly improve performance. Approximation theory, discussed in chapter 6, can be used to evaluate alternative bases because ultimately we are trying to approximate the solution <span class="math notranslate nohighlight">\(f\)</span> with a finite combination of simple known functions. The basis elements should look something like the solution so that only a few elements can give a good approximation. While asymptotic results such as the Stone-Weierstrass theorem may lull one into accepting polynomial approximations, practical success requires a basis where only a few elements will do the job. The individual terms should also be “different”; ideally they should be orthogonal with respect to the inner product <span class="math notranslate nohighlight">\(\langle\cdot, \cdot\rangle\)</span>. The reasons are essentially the same as why one wants uncorrelated explanatory variables in a regression. Nonorthogonal bases will reduce numerical accuracy just as multicollinear regressors enlarge confidence intervals. Algorithms that solve for the unknown coefficients <span class="math notranslate nohighlight">\(a\)</span> solve several linear systems of equations, and the accuracy of these solutions depends on the rows and columns not being collinear. Orthogonal bases will help avoid ill-conditioned matrices in these intermediate steps.</p>
<p>From chapter 6 we know that there are several possible bases. First, let us consider the ordinary polynomials, <span class="math notranslate nohighlight">\(\left\{1, x, x^2, x^3, \ldots\right\}\)</span>. If <span class="math notranslate nohighlight">\(B_1\)</span> is the set of bounded measurable functions on a compact set then the Stone-Weierstrass theorem assures us of their completeness in the <span class="math notranslate nohighlight">\(L_1\)</span> norm. However, they may not be a good choice since they are too similar. For example, they are all monotonically increasing and positive on <span class="math notranslate nohighlight">\(\mathbb{R}^{+}\)</span>, and they will not be orthogonal in any natural inner product on <span class="math notranslate nohighlight">\(\mathbb{R}^{+}\)</span>. They will also vary a great deal in size over most intervals <span class="math notranslate nohighlight">\(D\)</span>. The ordinary polynomials will sometimes be adequate, as they were in our simple examples, because we needed few terms to get a good solution.</p>
<p>These considerations do not mean that we cannot use ordinary polynomials, just that it is preferable to use polynomial bases that are orthonormal with respect to the inner product. A generally useful choice are systems of Chebyshev polynomials, which were discussed in chapter 6. Nonpolynomial alternatives include various sequences of trigonometric and exponential functions. The choice depends on the range, <span class="math notranslate nohighlight">\(D\)</span>, computational demands, and the expected shape of a solution. In physics, trigonometric bases such as <span class="math notranslate nohighlight">\(\{1, \sin x, \sin 2 x, \sin 3 x, \ldots\}\)</span> are often used, since solutions are often periodic, allowing for Fourier series techniques. In economic problems, however, it is better to use nontrigonometric bases, since solutions are generally not periodic and periodic approximations to nonperiodic functions require many terms.</p>
<p>We can use the full array of approximation methods discussed in chapter 6. Some families of projection methods are known by their method of approximation. Spectral methods use bases where each element is nonzero almost everywhere, such as in trigonometric bases and orthogonal polynomials. Finite element methods use bases where each element has small support, as discussed in section 6.13.</p>
<p>Most interesting problems in economics involve more than one state variable-physical versus human capital, capital stocks of oligopolistic competitors, wealth distribution across investor groups, and so on. The tensor product methods discussed in Chapter 6 build up multidimensional basis functions from simple one-dimensional basis functions. The curse of dimensionality, a problem that arises with tensor product bases, can be avoided by using the complete polynomials as a basis instead.</p>
<p>We are not limited to the conventional approaches described in chapter 6. If we have some reason to believe that a solution will look like some nonconventional functions, then we should try them. We may want to orthogonalize the family, and we may need to develop the corresponding Gaussian quadrature formulas, but all that is just a straightforward application of the methods discussed in chapters 6 and 7. This may be quite important in multidimensional problems because we will need to economize on basis elements. In chapter 15 we will discuss formal ways to generate good problem-specific bases. Even though we will focus here on using standard approximation methods, the ideas of projection methods generalize directly to more idiosyncratic choices.</p>
<p>\subsection*{Choice of Projection Conditions}
As we have seen in our examples, projection techniques include a variety of special methods. In general, we specify some inner product, <span class="math notranslate nohighlight">\(\langle\cdot, \cdot\rangle\)</span>, of <span class="math notranslate nohighlight">\(B_2\)</span>, and use <span class="math notranslate nohighlight">\(\langle\cdots\rangle\)</span> to measure the “size” of the residual function, <span class="math notranslate nohighlight">\(R\)</span>, or its projection against the test functions. We can use inner products of the form
$<span class="math notranslate nohighlight">\(
\langle f(x), g(x)\rangle \equiv \int_D f(x) g(x) w(x) d x
\)</span><span class="math notranslate nohighlight">\(
for some weighting function \)</span>w(x)$, but there is no reason why we are limited to them. In choosing the norm, one should consider exactly what kind of error should be small and find a norm that will be sensitive to the important errors. There are several ways to proceed.</p>
<p>The general least squares projection method computes the <span class="math notranslate nohighlight">\(L^2\)</span> norm of the residual function, namely <span class="math notranslate nohighlight">\(\langle R(x ; a), R(x ; a)\rangle\)</span>, and chooses <span class="math notranslate nohighlight">\(a\)</span> so as to minimize the “sum of squared residuals”:
$<span class="math notranslate nohighlight">\(
\min _a\langle R(x ; a), R(x ; a)\rangle .
\)</span><span class="math notranslate nohighlight">\(
We have thereby reduced the problem of solving a functional equation to solving a nonlinear minimization problem in \)</span>\mathbb{R}^n$, a more tractable problem. Of course, the standard difficulties will arise. For example, there may be local minima which are not global solutions. However, there is no reason for these problems to arise more often here than in any other context, such as maximum likelihood estimation, where minimization problems are solved numerically.</p>
<p>The least squares method is a direct implementation of the idea to make small the error of the approximation. In general, one could develop alternative implementations by using different norms. However, most projection techniques find a goodfitting approximation in less direct fashions. For these techniques the basic idea is that the true solution would have a zero residual error function; in particular, its projection in all directions is zero. Therefore one way to find the <span class="math notranslate nohighlight">\(n\)</span> components of <span class="math notranslate nohighlight">\(a\)</span> is to fix <span class="math notranslate nohighlight">\(n\)</span> projections and choose <span class="math notranslate nohighlight">\(a\)</span> so that the projection of the resulting residual function in each of those <span class="math notranslate nohighlight">\(n\)</span> directions is zero. Formally these methods find <span class="math notranslate nohighlight">\(a\)</span> such that <span class="math notranslate nohighlight">\(\left\langle R, p_i\right\rangle=0\)</span> for some specified collection of test functions, <span class="math notranslate nohighlight">\(p_i\)</span>. Different choices of the <span class="math notranslate nohighlight">\(p_i\)</span> defines different implementations of the projection method.</p>
<p>It is clear that the least squares and alternative implementations of projection ideas are similar since one way to solve the least squares approach is to solve the nonlinear set of equations generated by its first-order conditions, <span class="math notranslate nohighlight">\(\left\langle R, \partial R / \partial a_i\right\rangle=0\)</span>. Seeing the least squares method expressed as a system of projection equations gives us some indication why other methods may be better. The projection directions in the least squares case, the gradients of the residual function, could be highly correlated. Furthermore the projection directions depend on the guess for <span class="math notranslate nohighlight">\(a\)</span>. This lack of control over the implicit projection directions is not a good feature. Also in economic problems we may have a preference for approximations that have zero projections in certain directions, such as the average error in an Euler equation. Many of the alternative techniques will naturally include that condition.</p>
<p>One such alternative technique is the Galerkin method, also known as the BubnovGalerkin or Galerkin-Petrov method. In the Galerkin method we use the first <span class="math notranslate nohighlight">\(n\)</span> elements of the basis for the projection directions, where we are making the weak assumption that <span class="math notranslate nohighlight">\(\Phi\)</span>, our basis of <span class="math notranslate nohighlight">\(B_1\)</span>, lies in <span class="math notranslate nohighlight">\(B_2\)</span>. Therefore <span class="math notranslate nohighlight">\(a\)</span> is chosen to solve the following set of equations:
$<span class="math notranslate nohighlight">\(
P_i(a) \equiv\left\langle R(x ; a), \varphi_i(x)\right\rangle=0, \quad i=1, \ldots, n
\)</span>$
Notice that here we have reduced the problem of solving a differential equation to one of solving a set of nonlinear equations. In some cases the Galerkin projection equations are the first-order conditions to some minimization problem, as is often the case in linear problems from physics. When we have such an equivalence, the Galerkin method is also called the Rayleigh-Ritz method. This is not as likely to happen in economics problems because of nonlinearities.</p>
<p>The method of moments, subdomain, and collocation procedures can be applied to the general setting. If <span class="math notranslate nohighlight">\(D \subset \mathbb{R}\)</span>, then the method of moments chooses the first <span class="math notranslate nohighlight">\(n\)</span> polynomials for the projection directions; that is, we find <span class="math notranslate nohighlight">\(a\)</span> that solves the system
$<span class="math notranslate nohighlight">\(
P_i(a) \equiv\left\langle R(x ; a), x^{i-1}\right\rangle=0, \quad i=1, \ldots, n
\)</span><span class="math notranslate nohighlight">\(
If \)</span>D<span class="math notranslate nohighlight">\( is of higher dimension, then we project \)</span>R<span class="math notranslate nohighlight">\( against a sufficient number of loworder multivariate monomials. In the subdomain method the idea is to find an approximation that is good on average on a collection of subsets that cover the whole domain. More specifically, we choose \)</span>a<span class="math notranslate nohighlight">\( so that
\)</span><span class="math notranslate nohighlight">\(
P_i(a) \equiv\left\langle R(x ; a), I_{D_i}\right\rangle=0, \quad i=1, \ldots, n
\)</span><span class="math notranslate nohighlight">\(
where \)</span>\left{D_i\right}<em>{i=1}^n<span class="math notranslate nohighlight">\( is a sequence of intervals covering \)</span>D<span class="math notranslate nohighlight">\(, and \)</span>I</em>{D_i}<span class="math notranslate nohighlight">\( is the indicator function for \)</span>D_i$.</p>
<p>The collocation method chooses <span class="math notranslate nohighlight">\(a\)</span> so that the functional equation holds exactly at <span class="math notranslate nohighlight">\(n\)</span> fixed points. That is, we choose <span class="math notranslate nohighlight">\(a\)</span> to solve
$<span class="math notranslate nohighlight">\(
R\left(x_i ; a\right)=0, \quad i=1, \ldots, n
\)</span><span class="math notranslate nohighlight">\(
where \)</span>\left{x_i\right}_{i=1}^n<span class="math notranslate nohighlight">\( are \)</span>n<span class="math notranslate nohighlight">\( fixed points from \)</span>D<span class="math notranslate nohighlight">\(. This is a special case of the projection approach, since \)</span>R\left(x_i ; a\right)<span class="math notranslate nohighlight">\( equals \)</span>\left\langle R(x ; a), \delta\left(x-x_i\right)\right\rangle<span class="math notranslate nohighlight">\(, the projection of \)</span>R(x ; a)<span class="math notranslate nohighlight">\( against the Dirac delta function at \)</span>x_i$.</p>
<p>Orthogonal collocation is the method where the <span class="math notranslate nohighlight">\(x_i\)</span> are the <span class="math notranslate nohighlight">\(n\)</span> zeros of the <span class="math notranslate nohighlight">\(n\)</span>th orthogonal polynomial basis element and the basis elements are orthogonal with respect to the inner product. It is a particularly powerful application of projection ideas when used with a Chebyshev polynomial basis. This is not a surprise in light of the Chebyshev interpolation theorem. Suppose that <span class="math notranslate nohighlight">\(D=[-1,1]\)</span> and <span class="math notranslate nohighlight">\(R\left(x_i ; a\right)=0, i=1, \ldots, n\)</span>, where the <span class="math notranslate nohighlight">\(x_i\)</span> are the <span class="math notranslate nohighlight">\(n\)</span> zeros of <span class="math notranslate nohighlight">\(T_n\)</span>. As long as <span class="math notranslate nohighlight">\(R(x; a)\)</span> is smooth in <span class="math notranslate nohighlight">\(x\)</span>, the Chebyshev interpolation theorem says that these zero conditions force <span class="math notranslate nohighlight">\(R(x ; a)\)</span> to be close to zero for all <span class="math notranslate nohighlight">\(x \in[-1,1]\)</span>. The optimality of Chebyshev interpolation also says that if one is going to use collocation, these are the best possible points to use. Even after absorbing these considerations, it is not certain that even Chebyshev collocation is a reliable method. We will see below that its performance is surprisingly good.</p>
<p>Collocation can be used for bases other than orthogonal polynomials. Spline collocation methods use spline bases. The collocation points could be the spline nodes themselves or some other set of points, such as the midpoints of the spline mesh. The key objective is keeping the Jacobian of the collocation equation system well-conditioned.</p>
<p>\subsection*{Evaluation of Projections}
The meat of the problem is step 4, where the major computational task is the computation of those projections. The collocation method is fastest in this regard because it only uses the value of <span class="math notranslate nohighlight">\(R\)</span> at <span class="math notranslate nohighlight">\(n\)</span> points. More generally, the projections will involve integration. In some cases one may be able to explicitly perform the integration. This is generally possible for linear problems, and possible for special nonlinear problems. However, our experience with the economic applications below is that this will generally be impossible for nonlinear economic problems. We instead need to use quadrature techniques to compute the integrals associated with the evaluation of <span class="math notranslate nohighlight">\(\langle\cdot, \cdot\rangle\)</span>. A typical quadrature formula approximates <span class="math notranslate nohighlight">\(\int_a^b f(x) w(x) d x\)</span> with a finite sum <span class="math notranslate nohighlight">\(\sum_{i=1}^n \omega_i f\left(x_i\right)\)</span> where the <span class="math notranslate nohighlight">\(x_i\)</span> are the quadrature nodes and the <span class="math notranslate nohighlight">\(\omega_i\)</span> are the weights. Since these formulas also evaluate <span class="math notranslate nohighlight">\(R\)</span> at just a finite number of points, quadrature-based projection techniques are essentially weighted collocation methods. The advantage of quadrature formulas is that information at more points is used to compute a more accurate approximation of the projections.</p>
<p>\subsection*{Finding the Solution}
Step 5 uses either a minimization algorithm or a nonlinear algebraic equation solver. If the system <span class="math notranslate nohighlight">\(P(a)=0\)</span> is overidentified or if we are minimizing <span class="math notranslate nohighlight">\(\|R(\cdot ; a)\|\)</span>, we may invoke a nonlinear least squares algorithm. The nonlinear equations associated with Galerkin and other inner product methods can be solved by the variety of methods discussed in chapter 5. While fixed-point iteration appears to be popular in economics, Newton’s method and its refinements have often been successful. Homotopy methods can also be used if one has no good initial guesses.</p>
<p>\subsection*{Initial Guesses}
Good initial guesses are important since projection methods involve either a system of nonlinear equations or optimizing a nonlinear, possibly multimodal, objective. Fortunately this is generally not a big problem. Often there are degenerate cases for which we can find the solution, which in turn will be a good guess for the problem we want to solve. The perturbation methods discussed in chapters 13 and 14 often generate good initial guesses. In some problems there are problem-specific ways of generating good initial guesses.</p>
<p>There is one general approach which is often useful. The least squares approach may not be a good one to use for high-quality approximations. However, it may yield low-quality approximations relatively quickly, and, since the least squares method is an optimization method, convergence to a local extrema is ensured even if one has no good initial guess. Furthermore, by adding terms to the least squares objective, one can impose sensible restrictions on the coefficients to eliminate economically nonsensical extrema. These facts motivate a two-stage approach. First, one uses a least squares approach with a loose convergence criterion to quickly compute a low-quality approximation. Second, one uses this approximation as the initial guess for a projection method attempting to compute a higher-order approximation. With some luck the least squares solution will be a good initial guess for the second computation. If it is difficult to find good initial guesses, then one can use homotopy methods that are globally convergent.</p>
<p>\subsection*{Coordination among Steps 1-5}
We now see what is needed for efficiency. The key is to choose elements for the separate steps that work well together. We need basis functions that are easy to evaluate because they will be frequently evaluated. Any integration in steps 3 and 4 must be accurate but fast. Therefore we should use quadrature formulas that work well with the basis. The nonlinear equation solver in step 5 needs to be efficient and should be able to use all the information arising from step 4 calculations. Step 5 will typically use gradient information about the integrals of step 4. It is therefore important to do those gradient calculations quickly, doing them analytically when practical.</p>
<p>A particularly important interaction is that between the choice of a basis and the solution of the nonlinear problem in <span class="math notranslate nohighlight">\(\mathbb{R}^n\)</span>. Most methods for solving the system <span class="math notranslate nohighlight">\(P(a)=0\)</span> will use its Jacobian, <span class="math notranslate nohighlight">\(P_a(a)\)</span>. If this matrix is nearly singular near the solution, accuracy will be poor due to round-off error and convergence will be slow. Choosing an orthogonal basis, or nearly orthogonal basis (as is the case with B splines), will substantially reduce the likelihood of a poorly conditioned Jacobian, even in nonlinear problems.</p>
<p>Most methods used in numerical analysis of economic models fall within the general description for projection methods. We will see these connections below when we compare how various methods attack a common problem. The key fact is that the methods differ in their choices of basis, fitting criterion, and integration technique.</p>
<p>\subsection*{Evaluating a Solution}
As with operator equation methods in general, the projection algorithm does not automatically evaluate the quality of the candidate approximate solution. One of the advantages of the projection approach is the ease with which one can do the desired evaluation. The key observation is that we typically use an approximation to <span class="math notranslate nohighlight">\(\mathscr{N}, \hat{\mathscr{N}}\)</span>, when searching for the approximate solution, <span class="math notranslate nohighlight">\(\hat{f}\)</span>. For example, we use numerical integration methods to compute conditional expectations and to compute projections. To economize on computer time, we use the least amount of information possible to compute <span class="math notranslate nohighlight">\(\hat{f}\)</span>.</p>
<p>This is a risky but acceptable strategy, since we accept <span class="math notranslate nohighlight">\(\hat{f}\)</span> only after we strenuously test the candidate <span class="math notranslate nohighlight">\(\hat{f}\)</span>. Therefore we use better quadrature rules here to evaluate <span class="math notranslate nohighlight">\(\hat{f}\)</span>, and we check if <span class="math notranslate nohighlight">\(0=(\mathscr{N}(\hat{f}))(x)\)</span> at many points that were not used in the derivation of <span class="math notranslate nohighlight">\(\hat{f}\)</span>. We also use a finite number of test functions in constructing <span class="math notranslate nohighlight">\(\hat{f}\)</span>, leaving an infinite number of test functions that we can use to evaluate <span class="math notranslate nohighlight">\(\hat{f}\)</span>. While this discussion is abstract here, the actual implementation will be quite intuitive in actual applications.</p>
<p>\subsection*{Existence Problems}
Projection methods are useful ways to transform infinite-dimensional problems into finite-dimensional problems. However, these transformations present problems that we have not faced in previous methods-existence. In previous chapters we investigated methods that were more similar to the problem being analyzed. For example, in chapter 5 we examined nonlinear equations, where there is a solution to the numerical problem if and only if there is a solution to the original, pure problem. This can be different here. Sometimes the finite-dimensional problem generated by a projection method will not have a solution even when the original, pure problem does have a solution. Therefore, if one is having difficulty solving a projection equation system for a particular basis and particular <span class="math notranslate nohighlight">\(n\)</span>, the problem may go away just by trying another <span class="math notranslate nohighlight">\(n\)</span> or another basis. For well-behaved problems, choosing a sufficiently large <span class="math notranslate nohighlight">\(n\)</span> will work.</p>
<p>One way to ensure existence of a solution but gain some of the advantages of the projection methods is to construct a least squares objective from the projections. For example, in the case of the Galerkin method, one could solve the least squares problem
$<span class="math notranslate nohighlight">\(
\min _a \sum_{i=1}^n\left\langle R(x ; a), \varphi_i(x)\right\rangle^2 .
\)</span><span class="math notranslate nohighlight">\(
One could use an overidentification approach and solve the problem
\)</span><span class="math notranslate nohighlight">\(
\min _a \sum_{i=1}^m\left\langle R(x ; a), \varphi_i(x)\right\rangle^2
\)</span><span class="math notranslate nohighlight">\(
for some \)</span>m&gt;n$. These combinations of least squares and projection ideas are compromises. Existence of the finite-dimensional approximation is assured as long as the objectives are continuous, and optimization methods can be reliably used to find solutions.</p>
<p>In beginning a numerical analysis of a model, it is important to maintain flexibility as to which method to use. Since the projection methods are so similar, it is easy to change from one to another. Experimentation with several methods is the only way to find out which will be best.</p>
<p>\subsection*{Consistency}
When using numerical procedures, it is desirable to know something concerning the error of the solution. As we discussed in chapter 2, an important focus of theoretical numerical analysis is deriving error bounds and proving that methods are asymptotically valid. For example, we would like to know that the errors of a projection method go to zero as we enlarge the basis; this property is called consistency. There has been little work on proving that the algorithms used by economists are asymptotically valid.</p>
<p>The absence of convergence theorems does not invalidate the projection approach. The compute and verify approach will help avoid bad approximations. Even if we had a consistent method, we would have to develop a stopping criterion for <span class="math notranslate nohighlight">\(n\)</span>, the degree of the approximation, which itself would be a verification procedure. This is in keeping with our philosophy that a convergence theorem is not necessary for a procedure to be useful nor do convergence theorems make any particular result more reliable. In practice, we must use a method which stops at some finite point, and any candidate solution produced by any method must be tested before it is accepted.</p>
<p>\newpage
\section*{Numerical Dynamic Programming}
\subsection*{12.7 Continuous Methods for Continuous-State Problems}</p>
<p>Most of the methods examined so far either assume that there were only a finite number of states, or approximate a continuous state with a finite set of values. These methods are reliable in that they will solve the problem, or will approach the solution as the discretization is made finer. However, discretization becomes impractical as one moves to larger problems. In this section we introduce a parametric approach due to Bellman et al. (1963).</p>
<p>We don’t use discretization to solve linear-quadratic problems because we know the functional form of the solution. This allows us to focus on finding the appropriate coefficients. Linear-quadratic problems do not suffer a curse of dimensionality since the number of unknown coefficients do not grow exponentially in the dimension. Even though most dynamic programming problems do not have a useful functional form, we can still use the functional form approach by exploiting approximation ideas from chapter 6.</p>
<p>Recall the basic Bellman equation:</p>
<div class="math notranslate nohighlight">
\[
V(x)=\max _{u \in D(x)} \pi(u, x)+\beta E\left\{V\left(x^{+}\right) \mid x, u\right\} \equiv(T V)(x) .
\]</div>
<p>The unknown here is the function <span class="math notranslate nohighlight">\(V\)</span>. Discretization methods essentially approximate <span class="math notranslate nohighlight">\(V\)</span> with a step function, since it implicitly treats any state between <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_{i+1}\)</span> as either <span class="math notranslate nohighlight">\(x_i\)</span> or <span class="math notranslate nohighlight">\(x_{i-1}\)</span>. Chapter 6 presented better methods to approximate continuous functions. We apply those ideas here.</p>
<p>We assume that the payoff, motion, and value functions are all continuous functions of their arguments. The basic idea is that it should be better to approximate the continuous-value function with continuous functions and put no restrictions on the states and controls other than those mandated by the problem. Since the computer cannot model the entire space of continuous functions, we focus on a finitely parameterizable collection of functions,</p>
<div class="math notranslate nohighlight">
\[
V(x)=\hat{V}(x ; a) .
\]</div>
<p>The functional form <span class="math notranslate nohighlight">\(\hat{V}\)</span> may be a linear combination of polynomials, or it may represent a rational function or neural network representation with parameters <span class="math notranslate nohighlight">\(a \in R^m\)</span>, or it may be some other parameterization specially designed for the problem.</p>
<p>Once we fix the functional form, we focus on finding coefficients <span class="math notranslate nohighlight">\(a \in R^m\)</span> such that <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> “approximately” satisfies the Bellman equation. Solving the Bellman equation, (12.7.1), means finding the fixed point of <span class="math notranslate nohighlight">\(T\)</span>, but that is the pure mathematical problem. The basic task for a numerical procedure is to replace <span class="math notranslate nohighlight">\(T\)</span>, an operator mapping continuous functions to continuous functions, with a finite-dimensional approximation, <span class="math notranslate nohighlight">\(\hat{T}\)</span>, which maps the set of functions of the form <span class="math notranslate nohighlight">\(\hat{V}\)</span> into itself. If done properly, the fixed point of <span class="math notranslate nohighlight">\(\dot{T}\)</span> should be close to the fixed point of <span class="math notranslate nohighlight">\(T\)</span>.</p>
<p>The construction of <span class="math notranslate nohighlight">\(\hat{T}\)</span> relies on three critical steps. First, we choose some parameterization scheme <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> with <span class="math notranslate nohighlight">\(a \in R^m\)</span>, and <span class="math notranslate nohighlight">\(n\)</span> points in the state space,</p>
<div class="math notranslate nohighlight">
\[
X=\left\{x_1, x_2, \ldots, x_n\right\},
\]</div>
<p>where <span class="math notranslate nohighlight">\(n \geq m\)</span>. Second, we then evaluate <span class="math notranslate nohighlight">\(v_i=(T \hat{V})\left(x_i\right)\)</span> at each <span class="math notranslate nohighlight">\(x_i \in X\)</span> : we refer to this as the maximization step. The maximization step gives us values <span class="math notranslate nohighlight">\(v_i\)</span> which are points on the function <span class="math notranslate nohighlight">\(T \hat{V}\)</span>. We next use the information about <span class="math notranslate nohighlight">\(T \hat{V}\)</span> contained in the <span class="math notranslate nohighlight">\(v_i, i=1, \ldots, m\)</span>, to find an <span class="math notranslate nohighlight">\(a \in R^m\)</span> such that <span class="math notranslate nohighlight">\(\dot{V}(x: a)\)</span> best fits the <span class="math notranslate nohighlight">\(\left(v_i, x_i\right), i=1 \ldots, n\)</span>, data; we call this the fitting step. The fitting step can be an unweighted nonlinear least squares procedure as in</p>
<div class="math notranslate nohighlight">
\[
\min _{a \in R^m} \sum_{i=1}^n\left(\hat{V}\left(x_i ; a\right)-v_i\right)^2
\]</div>
<p>or any other appropriate approximation scheme. This fitting step produces a new value function defined on all states <span class="math notranslate nohighlight">\(x\)</span>. The parameteric dynamic programming algorithm is outlined in algorithm 12.5.</p>
<p>\subsection*{Algorithm 12.5 Parametric Dynamic Programming with Value Function Iteration}
Objective: Solve the Bellman equation, (12.7.1),
Initialization. Choose functional form for <span class="math notranslate nohighlight">\(\dot{V}(x ; a)\)</span>, and choose the approximation grid, <span class="math notranslate nohighlight">\(X=\left\{x_1, \ldots, x_n\right\}\)</span>. Make initial guess <span class="math notranslate nohighlight">\(\hat{V}\left(x: a^0\right)\)</span>, and choose stopping criterion <span class="math notranslate nohighlight">\(\varepsilon&gt;0\)</span>.
Step 1. Maximization step: Compute <span class="math notranslate nohighlight">\(y_j=\left(T \dot{V}\left(\because a^i\right)\right)\left(x_j\right)\)</span> for <span class="math notranslate nohighlight">\(x_j \in X\)</span>.
Step 2. Fitting step: Using the appropriate approximation method. compute the <span class="math notranslate nohighlight">\(a^{i+1} \in R^m\)</span> such that <span class="math notranslate nohighlight">\(\hat{V}\left(x ; a^{i+1}\right)\)</span> approximates the <span class="math notranslate nohighlight">\(\left(v_i, x_i\right)\)</span> data.
Step 3. If <span class="math notranslate nohighlight">\(\left\|\hat{V}\left(x ; a^i\right)-\hat{V}\left(x ; a^{i+1}\right)\right\|&lt;\varepsilon\)</span>, stop; else go to step 1.</p>
<p>Steps 1 and 2 in algorithm 12.5 constitute a mapping <span class="math notranslate nohighlight">\(\hat{T}\)</span> taking <span class="math notranslate nohighlight">\(\hat{V}\)</span>, corresponding to a parameter vector <span class="math notranslate nohighlight">\(a\)</span>, to another function <span class="math notranslate nohighlight">\(\hat{T} \hat{V}\)</span> corresponding to another coefficient vector, <span class="math notranslate nohighlight">\(a^{\prime} . \dot{T}\)</span> is therefore a mapping in the space of coefficients, a subspace of <span class="math notranslate nohighlight">\(R^m\)</span>.</p>
<p>Algorithm 12.5 presents the general idea; we now examine the numerical details. Rewrite (12.7.1) as</p>
<div class="math notranslate nohighlight">
\[
V(x)=\max _{u \in D(x)} \pi(u, x)+\beta \int V\left(x^{+}\right) d F\left(x^{+} \mid x, u\right),
\]</div>
<p>where <span class="math notranslate nohighlight">\(F\left(x^{+} \mid x, u\right)\)</span> is the distribution of the future state <span class="math notranslate nohighlight">\(x^{+}\)</span>conditional on the current state and control. The maximization steps compute</p>
<div class="math notranslate nohighlight">
\[
v_j=\max _{u \in D\left(x_j\right)} \pi\left(u, x_j\right)+\beta \int \hat{V}\left(x^{+} ; a\right) d F\left(x^{+} \mid x_j, u\right), \quad x_j \in X .
\]</div>
<p>With the <span class="math notranslate nohighlight">\(v_j\)</span> values for the grid <span class="math notranslate nohighlight">\(X\)</span>, we next compute a new value function approximation <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> which fits the new <span class="math notranslate nohighlight">\(v_j\)</span> values at the <span class="math notranslate nohighlight">\(x_j \in X\)</span>.</p>
<p>These expressions make clear the three kinds of problems we need to handle. The first type of numerical problem is evaluating the integral <span class="math notranslate nohighlight">\(\int \hat{V}\left(x^{+}\right) d F\left(x^{+} \mid x, u\right)\)</span>. This would usually require numerical quadrature. If the integrand is smooth in <span class="math notranslate nohighlight">\(x^{+}\)</span>for fixed <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(u\)</span>, a Gaussian approach is suggested. Less well-behaved integrals would require low-order Newton-Cotes formulas. High-dimensional integrands would require a monomial, Monte Carlo, or quasi-Monte Carlo method.</p>
<p>The second type of numerical problem appearing in (12.7.4) is the optimization problem, (12.7.5). If the objective in (12.7.5) is smooth in <span class="math notranslate nohighlight">\(u\)</span>, we could use faster methods such as Newton’s method. It is important to choose an approximation scheme <span class="math notranslate nohighlight">\(\hat{V}\)</span> which preserves any smoothness properties of the problem.</p>
<p>Third, given the <span class="math notranslate nohighlight">\(v_i\)</span> estimates of the <span class="math notranslate nohighlight">\((T \hat{V})\left(x_i\right)\)</span> values, we need to compute the new coefficients in <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span>. The appropriate approximation procedure depends on the nature of <span class="math notranslate nohighlight">\(V\)</span>. If we expect <span class="math notranslate nohighlight">\(V\)</span> to be a smooth function, then orthogonal polynomial procedures may be appropriate. Otherwise, splines may be advisable. We will see below that these considerations are particularly important here.</p>
<p>There is substantial interaction across the three problems. Smooth interpolation schemes allow us to use Newton’s method in the maximization step. They also make it easier to evaluate the integral in (12.7.5). Since the integral in (12.7.5) is costly to evaluate, we may want to use different rules when computing the gradients and Hessian, using the observation that low-quality gradient and Hessian approximations often suffice.</p>
<p>While algorithm 12.5 looks sensible, there are several questions concerning its value. First, convergence is not assured since <span class="math notranslate nohighlight">\(\bar{T}\)</span> may not be a contraction map; in</p>
<p>fact, we will see that it may be quite ill-behaved. The key detail is the choice of the approximation scheme incorporated in <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> and the grid <span class="math notranslate nohighlight">\(X\)</span>. The discussion below will focus on the behavior of this algorithm for various choices of these elements.</p>
<p>We should emphasize that we can still use some of the techniques developed for the finite-state case. Algorithm 12.5 presents only value iteration, but we could also implement policy iteration. Many other procedures are not so easily adapted for this approach. The Gauss-Scidel ideas, particularly the upwind methods, do not have obvious counterparts consistent with the parametric approach in general. This leaves open the possibility that the finite-state approach may dominate the functional approximation approach for some problems because of the applicability of GaussSeidel acceleration ideas.
12.8 Parametric Approximations and Simulation Methods</p>
<p>The main idea of parametric dynamic programming methods is to parameterize the critical functions and find some parameter choice which generates a good approximation. One direct and simple implementation of that idea is to parameterize the control law, <span class="math notranslate nohighlight">\(\hat{U}(x ; a)\)</span>, and through simulation find that coefficient choice. <span class="math notranslate nohighlight">\(a\)</span>. which generates the greatest value. In this section we will discuss a simple application of that approach.</p>
<p>Consider again the stochastic growth problem:</p>
<div class="math notranslate nohighlight">
\[
V(k)=\max _c u(c)+\beta E\{V(k-c+\theta f(k-c)) \mid k, c\},
\]</div>
<p>where the <span class="math notranslate nohighlight">\(\theta\)</span> are i.i.d. productivity shocks affecting the net output function <span class="math notranslate nohighlight">\(f\)</span> : this is a special case of (12.1.20). For smooth concave problems we know that the true policy and value functions, <span class="math notranslate nohighlight">\(C(k)\)</span> and <span class="math notranslate nohighlight">\(V(k)\)</span>, are smooth functions. increasing in <span class="math notranslate nohighlight">\(k\)</span>. In this section we will use a simple simulation approach to solve the stochastic growth problem (12.8.1).</p>
<p>Instead of parameterizing <span class="math notranslate nohighlight">\(C(k)\)</span>, we parameterize the savings function. <span class="math notranslate nohighlight">\(S(k) \equiv k-C(k)\)</span>. We know that <span class="math notranslate nohighlight">\(S\)</span> is increasing but that <span class="math notranslate nohighlight">\(S\left(k_1\right)-S\left(k_2\right) \leq k_1-k_2\)</span> for <span class="math notranslate nohighlight">\(k_1 \geq k_2\)</span>; these properties allow us to examine a simple class of rules. We will examine linear rules; hence <span class="math notranslate nohighlight">\(\hat{S}(k)=a+b k\)</span> for coefficients <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> where <span class="math notranslate nohighlight">\(b \in(0,1)\)</span>. We will use simulation to approximate the value of a savings rule. Suppose that <span class="math notranslate nohighlight">\(\theta_t, t=1, \ldots, T\)</span> is a sequence of productivity shocks. Then, for a given initial value of <span class="math notranslate nohighlight">\(k_0\)</span>, the resulting paths for <span class="math notranslate nohighlight">\(c_t\)</span> and <span class="math notranslate nohighlight">\(k_t\)</span> are given by <span class="math notranslate nohighlight">\(c_t=k_t-\dot{S}\left(k_t\right)\)</span> and <span class="math notranslate nohighlight">\(k_{t+1}=\dot{S}\left(k_t\right)+\theta_t f\left(\dot{S}\left(k_t\right)\right)\)</span>, and the realized discounted utility is
$<span class="math notranslate nohighlight">\(
W(\theta ; \hat{S})=\sum_{t=0}^T \beta^t u\left(c_t\right)
\)</span>$</p>
<p>We can do this for several <span class="math notranslate nohighlight">\(\theta_t\)</span> sequences. Let <span class="math notranslate nohighlight">\(\theta^t\)</span> be the <span class="math notranslate nohighlight">\(i\)</span> th sequence drawn and let <span class="math notranslate nohighlight">\(c_t^{\prime}\)</span> be the resulting consumption when we compute (12.8.2). The value of a rule <span class="math notranslate nohighlight">\(\hat{S}(k)\)</span> beginning at <span class="math notranslate nohighlight">\(k_0\)</span> is <span class="math notranslate nohighlight">\(V\left(k_0 ; \hat{S}\right)=E\{W(\theta ; \hat{S})\}\)</span>, which can be approximated by the sum</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{N} \sum_{j=1}^N W\left(\theta^j ; \hat{S}\right)=\frac{1}{N} \sum_{j=1}^N \sum_{t=0}^T \beta^t u\left(c_t^{\prime}\right)
\]</div>
<p>Note that (12.8.3) is essentially an integral over the space of <span class="math notranslate nohighlight">\(\theta\)</span> series. A literal “simulation” approach would construct each <span class="math notranslate nohighlight">\(\theta\)</span> by a sequence of i.i.d. draws.</p>
<p>This value of <span class="math notranslate nohighlight">\(W(\theta ; S)\)</span> depends on the initial capital stock <span class="math notranslate nohighlight">\(k_0\)</span>, the particular realization of <span class="math notranslate nohighlight">\(\theta_t, t=1, \ldots, T\)</span>, and the choices for <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>. The use of several <span class="math notranslate nohighlight">\(\theta\)</span> realizations makes the average in (12.8.3) less sensitive to the particular realizations used.</p>
<p>Once we have a way to approximate <span class="math notranslate nohighlight">\(V\left(k_0 ; \hat{S}\right)\)</span> for a linear rule <span class="math notranslate nohighlight">\(\hat{S}\)</span> parameterized by <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span>, we optimize over <span class="math notranslate nohighlight">\(a\)</span> and <span class="math notranslate nohighlight">\(b\)</span> to approximate the optimal linear <span class="math notranslate nohighlight">\(\hat{S}(k)\)</span> rule. Since <span class="math notranslate nohighlight">\(k_0\)</span> is the initial capital stock in our definition of <span class="math notranslate nohighlight">\(V\left(k_0 ; \hat{S}\right)\)</span>, this approximation depends on <span class="math notranslate nohighlight">\(k_0\)</span>, whereas the optimal rule does not. To reduce the sensitivity of the chosen <span class="math notranslate nohighlight">\(S\)</span> rule to <span class="math notranslate nohighlight">\(k_0\)</span>, we should choose <span class="math notranslate nohighlight">\(k_0\)</span> to be close to the “average” capital stock.</p>
<p>This sounds easy but one can run into problems. Our procedure does not impose any restriction on <span class="math notranslate nohighlight">\(\hat{S}(k)\)</span>. In particular, <span class="math notranslate nohighlight">\(\hat{S}(k)\)</span> could be negative at some <span class="math notranslate nohighlight">\(k\)</span>, or consumption <span class="math notranslate nohighlight">\(k-\hat{S}(k)\)</span> could be negative, with either possibility causing problems because <span class="math notranslate nohighlight">\(f\)</span> and <span class="math notranslate nohighlight">\(u\)</span> are usually defined only for positive arguments. To deal with this problem, one should constrain the linear approximation, implying that <span class="math notranslate nohighlight">\(\hat{S}(k)= \min [\max [0, a+b k], k]\)</span>, or choose some transformation that avoids this possibility. The true rule may not be linear; in that case we could use a more flexible specification for <span class="math notranslate nohighlight">\(\hat{S}\)</span>.</p>
<p>The simulation approach is not efficient for smooth problems like (12.8.1) where we can exploit the continuity and concavity properties of the solution. However, more complex dynamic programming problems involving constraints, several dimensions, and/or integer variables may be approximately solved by simulation strategies. The key idea is to parameterize a family of control laws, use simulation to evaluate them, and choose the best. See Smith (1990) for an application of these ideas.</p>
<p>\subsection*{12.9 Shape-Preserving Methods}</p>
<p>The parametric approach to dynamic programming is promising but can fail if we are not careful. To illustrate this, consider the problem (12.5.1) with a very concave utility function. In figure 12.2, we display the results of a typical value function iteration. Suppose that we have chosen <span class="math notranslate nohighlight">\(x_i, i=1, \ldots, 5\)</span>, for the nodes of the approximation and that we computed <span class="math notranslate nohighlight">\(v_1, v_2, v_3, v_4\)</span>, and <span class="math notranslate nohighlight">\(v_5\)</span> as in figure 12.2 . These five points appear to be consistent with an increasing and concave and value function. However, applying interpolation to these data to fit <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> may produce a curve, neither concave nor monotone increasing, such as <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> in figure 12.2. Even worse is that the maximum of <span class="math notranslate nohighlight">\(\hat{V}(x ; a)\)</span> is a point between <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span>, and even exceeds the maximum <span class="math notranslate nohighlight">\(v_1\)</span> values.</p>
<p>While these internodal fluctuations are consistent with the approximation theory of chapter 6 , they can wreck havoc with dynamic programming. For example, suppose that the true <span class="math notranslate nohighlight">\(V\)</span> is increasing and concave but that at some iteration <span class="math notranslate nohighlight">\(\hat{V}\)</span> looks like <span class="math notranslate nohighlight">\(\hat{V}\)</span> in figure 12.2. In the next iteration, <span class="math notranslate nohighlight">\(x_M\)</span> will be considered a very desirable state, and controls will be chosen to push the state towards <span class="math notranslate nohighlight">\(x_M\)</span>. The artificially high value of <span class="math notranslate nohighlight">\(\hat{V}\left(x_M\right)\)</span> will lead to artificially high values for <span class="math notranslate nohighlight">\(\hat{V}\left(x_2\right)\)</span> and <span class="math notranslate nohighlight">\(\hat{V}\left(x_3\right)\)</span> in the next maximization step. The errors at <span class="math notranslate nohighlight">\(x_2\)</span> and <span class="math notranslate nohighlight">\(x_3\)</span> could interact with the values computed elsewhere to produce even worse internodal oscillations at the next fitting stage. Once this process begins, it can feed on itself and destabilize the value iteration procedure.</p>
<p>The problem here is the absence of shape-preservation in the algorithm. Shapepreservation is valuable property, particularly in concave problems. If <span class="math notranslate nohighlight">\(\hat{V}\)</span> and <span class="math notranslate nohighlight">\(\pi(x, u)\)</span> are concave in <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(u\)</span>, the maximization step is a concave problem; hence the global maximum is the unique local maximum and easy to find. Furthermore <span class="math notranslate nohighlight">\(T\)</span> is a shapepreserving operator; that is, if <span class="math notranslate nohighlight">\(\pi(x, u)\)</span> and the conditional expectation is concave in <span class="math notranslate nohighlight">\((x, u)\)</span> for concave <span class="math notranslate nohighlight">\(V\)</span>, then <span class="math notranslate nohighlight">\(T V\)</span> is concave if <span class="math notranslate nohighlight">\(V\)</span> is concave. Therefore, if <span class="math notranslate nohighlight">\(\hat{V}\)</span> is concave</p>
<p>in <span class="math notranslate nohighlight">\(x\)</span>, then the <span class="math notranslate nohighlight">\((T \hat{V})\left(x_i\right)\)</span> points will be concave, and a shape-preserving scheme will cause <span class="math notranslate nohighlight">\((\hat{T} \hat{V})(x)\)</span> to be a concave function of <span class="math notranslate nohighlight">\(x\)</span>. Approximation methods should match the shape properties of the approximated objects.</p>
<p>This does not mean that we can’t use the polynomial methods. In some instances these problems do not arise. For example, if <span class="math notranslate nohighlight">\(V(x)\)</span> is <span class="math notranslate nohighlight">\(C^{\infty}\)</span> with well-behaved highorder derivatives, then orthogonal polynomial approximation is a good approximation choice, and there is less chance of these problems arising.</p>
<p>However, we still want to find more reliable procedures. Following is a discussion of methods that avoid these problems by design. The key idea is the use of shapepreserving approximation methods. Discretization methods will preserve shape and avoid these problems. More promising are the shape-preserving methods discussed in chapter 6.</p>
<p>\subsection*{Linear Interpolation}
For one-dimensional problems disruptive internodal oscillations can be avoided by the simplest of all interpolation schemes-linear interpolation. Furthermore, as discussed in chapter 6 , linear interpolation is shape-preserving. Therefore, if the <span class="math notranslate nohighlight">\(v_i\)</span> points are increasing and concave, so will be the interpolating function.</p>
<p>The problem with linear interpolation is that it makes the maximization step less efficient. The kinks in a linear interpolant will generally produce kinks in the objective of the maximization step, forcing us to use slower optimization algorithms. Kinks in the value function may cause the approximate policy function to be discontinuous, an unappealing property if the true policy function is continuous. Using linear interpolation is a costly way of preserving shape.</p>
<p>\subsection*{Multilinear Interpolation Methods}
In multidimensional problems there are a couple of easy well-behaved approximation schemes which one can use. First, one could use the multilinear or simplicial interpolation methods discussed in chapter 6. The DYGAM package discussed in Dantzig et al. (1974) used multilinear interpolation. These methods eliminates problematic internodal oscillations since <span class="math notranslate nohighlight">\(\hat{V}\)</span> at each point in the interior of a box is a convex combination of the values at the vertices. The fact that the interpolation scheme is monotone in the interpolation data means that <span class="math notranslate nohighlight">\(\hat{T}\)</span> is monotone. Furthermore <span class="math notranslate nohighlight">\(\hat{T}\)</span> inherits the contraction properties of <span class="math notranslate nohighlight">\(T\)</span>. Multilinear interpolation is costly to compute; a less costly alternative is multidimensional simplicial interpolation, as discussed in chapter 6.</p>
<p>Unfortunately, multilinear and simplicial interpolation have the same problems of one-dimensional linear interpolation and more. First, they preserve positivity and monotonicity but not concavity. Second, they also produce kinks in the value function and discontinuities in the policy function. These problems can be ameliorated by cutting the state space into small boxes, but only at substantial cost.</p>
<p>\subsection*{Schumaker Shape-Preserving Splines}
For one-dimensional dynamic programming problems with smooth concave payoff and transition functions and concave <span class="math notranslate nohighlight">\(C^1\)</span> solutions, the Schumaker quadratic shapepreserving spline procedure will produce <span class="math notranslate nohighlight">\(C^1\)</span> approximations of the value function and continuous policy functions. The objective in the maximization step will always be concave and <span class="math notranslate nohighlight">\(C^{\prime}\)</span>, allowing us to use a rapid scheme such as Newton’s method. We can also use a small number of approximation nodes since we do not need to worry about disruptive internodal fluctuations.</p>
<p>Judd and Solnick (1994) apply Shumaker’s quadratic splines to the single good, deterministic optimal growth problem, (12.5.1). They found that the resulting approximations were very good, substantially dominating other methods. For example, the shape-preserving method using 12 nodes did as well as linear interpolation using 120 nodes and the discrete-state approximation using 1,200 points.</p>
<p>Shape-preserving Hermite interpolation is particularly valuable. In this approach, after one computes the value function at a node, one also uses the envelope theorem to compute the slope of the value function at essentially zero computational cost. This slope information can be used along with the level information in the Schumaker shape preserving scheme to arrive at an even better, but still stable. approximation of value function iteration. Examples in Judd and Solnick indicate that shape-preserving Hermite interpolation will produce highly accurate solutions using few approximation nodes.</p>
<p>\end{document}</p>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="simple visible nav section-nav flex-column">
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Pierre-Luc Bacon
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>