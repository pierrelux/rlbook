<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Bibliography - Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data</title><meta property="og:title" content="Bibliography - Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data"/><meta name="generator" content="mystmd"/><meta name="description" content="A graduate-level introduction to reinforcement learning as a framework for modeling, optimization, and control, connecting dynamic models, data, and applications beyond standard benchmarks."/><meta property="og:description" content="A graduate-level introduction to reinforcement learning as a framework for modeling, optimization, and control, connecting dynamic models, data, and applications beyond standard benchmarks."/><meta name="keywords" content=""/><link rel="stylesheet" href="/rlbook/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/rlbook/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/rlbook/favicon.ico"/><link rel="stylesheet" href="/rlbook/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/rlbook/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">RL &amp; Control</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">âŒ˜</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"><div class="relative" data-headlessui-state=""><div><button class="flex text-sm bg-transparent rounded-full focus:outline-none" id="headlessui-menu-button-:Rr4op:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open Menu</span><div class="flex items-center text-stone-200 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="p-1"><path fill-rule="evenodd" d="M10.5 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z" clip-rule="evenodd"></path></svg></div></button></div></div></div><div class="hidden sm:block"><a href="https://github.com/pierrelux/rlbook" target="_blank" rel="noopener noreferrer" class="inline-block px-4 py-2 mx-1 mt-0 leading-none border rounded text-md border-stone-700 dark:border-white text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 hover:bg-neutral-100">View on GitHub</a></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/rlbook/">Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Modeling" class="block break-words rounded py-2 grow cursor-pointer">Modeling</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Numerical Trajectory Optimization" class="block break-words rounded py-2 grow cursor-pointer">Numerical Trajectory Optimization</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="From Trajectories to Policies" class="block break-words rounded py-2 grow cursor-pointer">From Trajectories to Policies</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Approximate Dynamic Programming" class="block break-words rounded py-2 grow cursor-pointer">Approximate Dynamic Programming</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Appendix" class="block break-words rounded py-2 grow cursor-pointer">Appendix</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1mp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1mp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="References" class="block break-words rounded py-2 grow cursor-pointer">References</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1up8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1up8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/pierrelux/rlbook" title="GitHub Repository: pierrelux/rlbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><a href="https://github.com/pierrelux/rlbook/edit/main/bibliography.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Bibliography</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78top:" data-state="closed">Pierre-Luc Bacon</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><span></span><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/rlbook/appendix-nlp"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Appendix</div>Nonlinear Programming</div></div></a></div></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/rlbook/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-XWET6RJ7.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/rlbook/build/root-ZJOPFBMV.js"/><link rel="modulepreload" href="/rlbook/build/_shared/chunk-NFM2H3KQ.js"/><link rel="modulepreload" href="/rlbook/build/routes/$-CQPS5IOR.js"/><script>window.__remixContext = {"url":"/bibliography","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.3","options":{"logo_text":"RL \u0026 Control"},"nav":[],"actions":[{"title":"View on GitHub","url":"https://github.com/pierrelux/rlbook","internal":false,"static":false}],"projects":[{"bibliography":["/Users/pierre-luc.bacon/Documents/rlbook/references.bib"],"math":{"\\Proj":{"macro":"\\mathsf{P}"},"\\Residual":{"macro":"\\mathsf{N}"},"\\Contraction":{"macro":"\\mathsf{T}"},"\\Bellman":{"macro":"\\mathsf{L}"},"\\BellmanPi":{"macro":"\\mathsf{L}_\\pi"}},"exports":[{"format":"pdf","filename":"book.pdf","url":"/rlbook/build/book-bceca6481db041911b084ebd03cc1269.pdf"}],"title":"Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data","description":"A graduate-level introduction to reinforcement learning as a framework for modeling, optimization, and control, connecting dynamic models, data, and applications beyond standard benchmarks.","authors":[{"nameParsed":{"literal":"Pierre-Luc Bacon","given":"Pierre-Luc","family":"Bacon"},"name":"Pierre-Luc Bacon","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/pierrelux/rlbook","id":"3c112bb5-93ac-429f-8216-c0b9947c00d4","toc":[{"file":"intro.md"},{"children":[{"file":"modeling.md"},{"file":"ssm.md"},{"file":"simulation.md"}],"title":"Modeling"},{"children":[{"file":"ocp.md"},{"file":"cocp.md"}],"title":"Numerical Trajectory Optimization"},{"children":[{"file":"mpc.md"},{"file":"dp.md"}],"title":"From Trajectories to Policies"},{"children":[{"file":"regmdp.md"},{"file":"projdp.md"},{"file":"simadp.md"},{"file":"cadp.md"}],"title":"Approximate Dynamic Programming"},{"children":[{"file":"appendix_examples.md"},{"file":"appendix_ivps.md"},{"file":"appendix_nlp.md"}],"title":"Appendix"},{"children":[{"file":"bibliography.md"}],"title":"References"}],"index":"index","pages":[{"level":1,"title":"Modeling"},{"slug":"modeling","title":"Why Build a Model? For Whom?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ssm","title":"Dynamics Models for Decision Making","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simulation","title":"Programs as Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Numerical Trajectory Optimization"},{"slug":"ocp","title":"Discrete-Time Trajectory Optimization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cocp","title":"Trajectory Optimization in Continuous Time","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"From Trajectories to Policies"},{"slug":"mpc","title":"Model Predictive Control","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"dp","title":"Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Approximate Dynamic Programming"},{"slug":"regmdp","title":"Smooth Bellman Optimality Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projdp","title":"Weighted Residual Methods for Functional Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simadp","title":"Simulation-Based Approximate Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cadp","title":"Policy Parametrization Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Appendix"},{"slug":"appendix-examples","title":"Example COCPs","description":"","date":"","thumbnail":"/rlbook/build/heat_exchanger-acfdd83b1501b4c220f686fe21df7820.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-ivps","title":"Solving Initial Value Problems","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-nlp","title":"Nonlinear Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"References"},{"slug":"bibliography","title":"Bibliography","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3102","MODE":"static","BASE_URL":"/rlbook"},"routes/$":{"config":{"version":2,"myst":"1.6.3","options":{"logo_text":"RL \u0026 Control"},"nav":[],"actions":[{"title":"View on GitHub","url":"https://github.com/pierrelux/rlbook","internal":false,"static":false}],"projects":[{"bibliography":["/Users/pierre-luc.bacon/Documents/rlbook/references.bib"],"math":{"\\Proj":{"macro":"\\mathsf{P}"},"\\Residual":{"macro":"\\mathsf{N}"},"\\Contraction":{"macro":"\\mathsf{T}"},"\\Bellman":{"macro":"\\mathsf{L}"},"\\BellmanPi":{"macro":"\\mathsf{L}_\\pi"}},"exports":[{"format":"pdf","filename":"book.pdf","url":"/rlbook/build/book-bceca6481db041911b084ebd03cc1269.pdf"}],"title":"Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data","description":"A graduate-level introduction to reinforcement learning as a framework for modeling, optimization, and control, connecting dynamic models, data, and applications beyond standard benchmarks.","authors":[{"nameParsed":{"literal":"Pierre-Luc Bacon","given":"Pierre-Luc","family":"Bacon"},"name":"Pierre-Luc Bacon","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/pierrelux/rlbook","id":"3c112bb5-93ac-429f-8216-c0b9947c00d4","toc":[{"file":"intro.md"},{"children":[{"file":"modeling.md"},{"file":"ssm.md"},{"file":"simulation.md"}],"title":"Modeling"},{"children":[{"file":"ocp.md"},{"file":"cocp.md"}],"title":"Numerical Trajectory Optimization"},{"children":[{"file":"mpc.md"},{"file":"dp.md"}],"title":"From Trajectories to Policies"},{"children":[{"file":"regmdp.md"},{"file":"projdp.md"},{"file":"simadp.md"},{"file":"cadp.md"}],"title":"Approximate Dynamic Programming"},{"children":[{"file":"appendix_examples.md"},{"file":"appendix_ivps.md"},{"file":"appendix_nlp.md"}],"title":"Appendix"},{"children":[{"file":"bibliography.md"}],"title":"References"}],"index":"index","pages":[{"level":1,"title":"Modeling"},{"slug":"modeling","title":"Why Build a Model? For Whom?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ssm","title":"Dynamics Models for Decision Making","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simulation","title":"Programs as Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Numerical Trajectory Optimization"},{"slug":"ocp","title":"Discrete-Time Trajectory Optimization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cocp","title":"Trajectory Optimization in Continuous Time","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"From Trajectories to Policies"},{"slug":"mpc","title":"Model Predictive Control","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"dp","title":"Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Approximate Dynamic Programming"},{"slug":"regmdp","title":"Smooth Bellman Optimality Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projdp","title":"Weighted Residual Methods for Functional Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simadp","title":"Simulation-Based Approximate Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cadp","title":"Policy Parametrization Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Appendix"},{"slug":"appendix-examples","title":"Example COCPs","description":"","date":"","thumbnail":"/rlbook/build/heat_exchanger-acfdd83b1501b4c220f686fe21df7820.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-ivps","title":"Solving Initial Value Problems","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-nlp","title":"Nonlinear Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"References"},{"slug":"bibliography","title":"Bibliography","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":2,"kind":"Notebook","sha256":"3f8b6d25b7f7f55e5a40f4be5082b039665a19073f69fa148ffde5dfc9e46de2","slug":"bibliography","location":"/bibliography.md","dependencies":[],"frontmatter":{"title":"Bibliography","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.16.3"}},"content_includes_title":false,"authors":[{"nameParsed":{"literal":"Pierre-Luc Bacon","given":"Pierre-Luc","family":"Bacon"},"name":"Pierre-Luc Bacon","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/pierrelux/rlbook","math":{"\\Proj":{"macro":"\\mathsf{P}"},"\\Residual":{"macro":"\\mathsf{N}"},"\\Contraction":{"macro":"\\mathsf{T}"},"\\Bellman":{"macro":"\\mathsf{L}"},"\\BellmanPi":{"macro":"\\mathsf{L}_\\pi"}},"numbering":{"title":{"offset":1}},"source_url":"https://github.com/pierrelux/rlbook/blob/main/bibliography.md","edit_url":"https://github.com/pierrelux/rlbook/edit/main/bibliography.md","exports":[{"format":"md","filename":"bibliography.md","url":"/rlbook/build/bibliography-8547a53ea2606df734f5bf0fc338fb44.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"bibliography","key":"U4kKLs6Npf"}],"key":"KIdUYaqNpS"}],"key":"JN3dQ6tODS"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Nonlinear Programming","url":"/appendix-nlp","group":"Appendix"}}},"domain":"http://localhost:3002"},"project":{"bibliography":["/Users/pierre-luc.bacon/Documents/rlbook/references.bib"],"math":{"\\Proj":{"macro":"\\mathsf{P}"},"\\Residual":{"macro":"\\mathsf{N}"},"\\Contraction":{"macro":"\\mathsf{T}"},"\\Bellman":{"macro":"\\mathsf{L}"},"\\BellmanPi":{"macro":"\\mathsf{L}_\\pi"}},"exports":[{"format":"pdf","filename":"book.pdf","url":"/rlbook/build/book-bceca6481db041911b084ebd03cc1269.pdf"}],"title":"Reinforcement Learning Beyond the Agent Loop: Models, Control, and Data","description":"A graduate-level introduction to reinforcement learning as a framework for modeling, optimization, and control, connecting dynamic models, data, and applications beyond standard benchmarks.","authors":[{"nameParsed":{"literal":"Pierre-Luc Bacon","given":"Pierre-Luc","family":"Bacon"},"name":"Pierre-Luc Bacon","id":"contributors-myst-generated-uid-0"}],"github":"https://github.com/pierrelux/rlbook","id":"3c112bb5-93ac-429f-8216-c0b9947c00d4","toc":[{"file":"intro.md"},{"children":[{"file":"modeling.md"},{"file":"ssm.md"},{"file":"simulation.md"}],"title":"Modeling"},{"children":[{"file":"ocp.md"},{"file":"cocp.md"}],"title":"Numerical Trajectory Optimization"},{"children":[{"file":"mpc.md"},{"file":"dp.md"}],"title":"From Trajectories to Policies"},{"children":[{"file":"regmdp.md"},{"file":"projdp.md"},{"file":"simadp.md"},{"file":"cadp.md"}],"title":"Approximate Dynamic Programming"},{"children":[{"file":"appendix_examples.md"},{"file":"appendix_ivps.md"},{"file":"appendix_nlp.md"}],"title":"Appendix"},{"children":[{"file":"bibliography.md"}],"title":"References"}],"index":"index","pages":[{"level":1,"title":"Modeling"},{"slug":"modeling","title":"Why Build a Model? For Whom?","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"ssm","title":"Dynamics Models for Decision Making","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simulation","title":"Programs as Models","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Numerical Trajectory Optimization"},{"slug":"ocp","title":"Discrete-Time Trajectory Optimization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cocp","title":"Trajectory Optimization in Continuous Time","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"From Trajectories to Policies"},{"slug":"mpc","title":"Model Predictive Control","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"dp","title":"Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Approximate Dynamic Programming"},{"slug":"regmdp","title":"Smooth Bellman Optimality Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"projdp","title":"Weighted Residual Methods for Functional Equations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"simadp","title":"Simulation-Based Approximate Dynamic Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cadp","title":"Policy Parametrization Methods","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Appendix"},{"slug":"appendix-examples","title":"Example COCPs","description":"","date":"","thumbnail":"/rlbook/build/heat_exchanger-acfdd83b1501b4c220f686fe21df7820.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-ivps","title":"Solving Initial Value Problems","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"appendix-nlp","title":"Nonlinear Programming","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"References"},{"slug":"bibliography","title":"Bibliography","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/rlbook/build/manifest-ED236704.js";
import * as route0 from "/rlbook/build/root-ZJOPFBMV.js";
import * as route1 from "/rlbook/build/routes/$-CQPS5IOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/rlbook/build/entry.client-UNPC4GT3.js");</script></body></html>